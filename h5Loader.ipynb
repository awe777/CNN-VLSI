{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import tensorflow.python.keras as keras\n",
    "from keras.layers import Input, Layer, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add, Lambda\n",
    "from keras.models import Model, load_model, model_from_json, clone_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import os\n",
    "K.clear_session()\n",
    "'''\n",
    "# file h5 dibuat dengan convert.py dari https://github.com/awe777/keras-yolo3\n",
    "model0 = load_model(\"yolov3_tiny.h5\")   # dibuat dari kode sebelum fork\n",
    "model1 = load_model(\"yolov3_tiny_.h5\")  # dibuat dari kode setelah diubah di fork pribadi\n",
    "print(model0.to_json() == model1.to_json())\n",
    "print(model.summary())\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom layer classes successfully defined\n"
     ]
    }
   ],
   "source": [
    "def roundingAlgo(x):\n",
    "    return K.round(x)\n",
    "\n",
    "class RoundQinf_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundQinf_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundQinf_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return roundingAlgo(X * 16) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundQinf_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 4096) + 524288) % 1048576) - 524288) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundQx_8minusx(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundQx_8minusx, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundQx_8minusx, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        pow_2_to_expplus8 = 2 ** (8 + (K.log(K.abs(X)) / math.log(2)) // 1)\n",
    "        return roundingAlgo(X * pow_2_to_expplus8) / (pow_2_to_expplus8 * 1.0)\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundQx_8minusx, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 128) % 256) - 128) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_0(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_0, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_0, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return ((roundingAlgo(X) + 128) % 256) - 128\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_0, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 2048) % 4096) - 2048) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ11_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ11_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ11_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 32768) % 65536) - 32768) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ11_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class Identity(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(Identity, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class IdentityFinalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IdentityFinalLayer, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(IdentityFinalLayer, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "\n",
    "print(\"Custom layer classes successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customObjects = {\n",
    "    'Identity': Identity,\n",
    "    'RoundQinf_4': RoundQinf_4,\n",
    "    'RoundOverflowQ3_4': RoundOverflowQ3_4,\n",
    "    'RoundQx_8minusx': RoundQx_8minusx,\n",
    "    'RoundOverflowQ7_12': RoundOverflowQ7_12,\n",
    "    'RoundOverflowQ7_0': RoundOverflowQ7_0,\n",
    "    'RoundOverflowQ7_4': RoundOverflowQ7_4,\n",
    "    'RoundOverflowQ11_4': RoundOverflowQ11_4,\n",
    "    'IdentityFinalLayer': IdentityFinalLayer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_dir, input_shape):\n",
    "    # from PIL import Image\n",
    "    # import numpy as np\n",
    "    image_data = 0\n",
    "    h, w = input_shape\n",
    "    try:\n",
    "        image = Image.open(image_dir)\n",
    "        iw, ih = image.size\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image = image.resize((nw,nh), Image.BICUBIC)\n",
    "        new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "        new_image.paste(image, (dx, dy))\n",
    "        image_data = np.array(new_image)/255.\n",
    "        return image_data\n",
    "    except:\n",
    "        return None\n",
    "# TO DO: implement yolo_head in order to get human-understandable result from model output\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "tinyYolo_anchors = get_anchors(\"../CNN-VLSI/tiny_yolo_anchors.txt\")\n",
    "\n",
    "def yolo_head_nonLoss(feats, anchors, num_classes, input_shape):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]), [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]), [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, 'float32') # K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # edited by instructions in https://stackoverflow.com/questions/57558476/training-a-keras-model-yields-multiple-optimizer-errors\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[...,::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[...,::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
    "    '''Get corrected boxes'''\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
    "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
    "    new_shape = K.round(image_shape * K.min(input_shape/image_shape))\n",
    "    offset = (input_shape-new_shape)/2./input_shape\n",
    "    scale = input_shape/new_shape\n",
    "    box_yx = (box_yx - offset) * scale\n",
    "    box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes =  K.concatenate([\n",
    "        box_mins[..., 0:1],  # y_min\n",
    "        box_mins[..., 1:2],  # x_min\n",
    "        box_maxes[..., 0:1],  # y_max\n",
    "        box_maxes[..., 1:2]  # x_max\n",
    "    ])\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    boxes *= K.concatenate([image_shape, image_shape])\n",
    "    return boxes\n",
    "\n",
    "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
    "    '''Process Conv layer output'''\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_head_nonLoss(feats,\n",
    "        anchors, num_classes, input_shape)\n",
    "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
    "    boxes = K.reshape(boxes, [-1, 4])\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
    "    return boxes, box_scores\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              image_shape,\n",
    "              max_boxes=20,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
    "    num_layers = len(yolo_outputs)\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]] # default setting\n",
    "    input_shape = K.shape(yolo_outputs[0])[1:3] * 32\n",
    "    boxes = []\n",
    "    box_scores = []\n",
    "    for l in range(num_layers):\n",
    "        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],\n",
    "            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)\n",
    "        boxes.append(_boxes)\n",
    "        box_scores.append(_box_scores)\n",
    "    boxes = K.concatenate(boxes, axis=0)\n",
    "    box_scores = K.concatenate(box_scores, axis=0)\n",
    "#     print(\"Box tensor:\", boxes.shape)\n",
    "#     print(K.get_value(boxes))\n",
    "#     print(\"Box score tensor:\", box_scores.shape)\n",
    "#     print(K.get_value(box_scores))\n",
    "#     print(\"class index of maximum prob value:\", K.argmax(box_scores, axis=1).shape)\n",
    "#     print(K.get_value(K.argmax(box_scores, axis=1)))\n",
    "#     print(\"maximum prob value: \",K.max(box_scores, axis=1).shape)\n",
    "#     print(K.get_value(K.max(box_scores, axis=1)))\n",
    "#     print(\"maximum prob mask: \", (K.max(box_scores, axis=1) >= score_threshold).shape)\n",
    "#     print(K.get_value(K.max(box_scores, axis=1) >= score_threshold)) # 0.027))\n",
    "#     print()\n",
    "#     print(\"index of highest maximum prob value:\",K.get_value(K.argmax(K.max(box_scores, axis=1))))\n",
    "#     print(\"highest maximum prob value:\", K.get_value(K.max(box_scores)))\n",
    "#     print(\"class index:\", K.get_value(K.argmax(box_scores, axis=1))[K.get_value(K.argmax(K.max(box_scores, axis=1)))])\n",
    "#     print(\"raw coordinates:\", K.get_value(boxes)[K.get_value(K.argmax(K.max(box_scores, axis=1)))])\n",
    "#     print(\"class index:\", K.get_value(box_scores)[K.get_value(K.argmax(K.max(box_scores, axis=1)))])\n",
    "    boxes_dummy = []\n",
    "    scores_dummy = []\n",
    "    classes_dummy = []\n",
    "    scoremask_dummy = K.get_value(K.max(box_scores, axis=1) >= score_threshold)\n",
    "    for i in range(scoremask_dummy.size):\n",
    "        if scoremask_dummy[i]:\n",
    "            boxes_dummy.append(K.get_value(boxes)[i].tolist())\n",
    "            scores_dummy.append(K.get_value(K.max(box_scores, axis=1))[i].tolist())\n",
    "            classes_dummy.append(K.get_value(K.argmax(box_scores, axis=1))[i].tolist())\n",
    "    ''' # toggle to utilize either hacky solution with working classes output or IOU result-cutting solution with non-working classes output\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    mask = box_scores >= score_threshold\n",
    "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
    "    for c in range(num_classes):\n",
    "        # TODO: use keras backend instead of tf.\n",
    "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
    "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
    "        nms_index = tf.image.non_max_suppression(\n",
    "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "        class_boxes = K.gather(class_boxes, nms_index)\n",
    "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
    "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes_ = K.concatenate(boxes_, axis=0)\n",
    "    scores_ = K.concatenate(scores_, axis=0)\n",
    "    classes_ = K.concatenate(classes_, axis=0)\n",
    "    '''\n",
    "    boxes_ = boxes_dummy\n",
    "    scores_ = scores_dummy\n",
    "    classes_ = classes_dummy\n",
    "    '''\n",
    "    # '''\n",
    "\n",
    "    return boxes_, scores_, classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading successful\n",
      "Model weight loading attempt successful\n"
     ]
    }
   ],
   "source": [
    "loadedModel = None\n",
    "try:\n",
    "    # '''\n",
    "    with open(\"./saved_models/model_0_inferenceModel.json\", \"r\") as jsonFile:\n",
    "        jsonRead = jsonFile.read()\n",
    "        # NOTE: this *will* take time, may cause OOM warnings\n",
    "        loadedModel = model_from_json(jsonRead, custom_objects=customObjects)\n",
    "        copyLoadModel = clone_model(loadedModel)\n",
    "        loadedModel = copyLoadModel\n",
    "        del copyLoadModel\n",
    "    # '''\n",
    "    print(\"Model loading successful\")\n",
    "    ''' # toggle comment to utilize by-name model (h5 and json are based on same model)\n",
    "    loadedModel.load_weights(\"./saved_models/model_0_trainModel.h5\", by_name=True, skip_mismatch=True)\n",
    "    ''' # or not (e.g. h5 from model_0, json from other)\n",
    "    loadedModel.load_weights(\"./saved_models/model_0_trainModel.h5\", by_name=False)    \n",
    "    # '''   \n",
    "    print(\"Model weight loading attempt successful\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load model/weight data:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 448, 3)\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Found 10 objects\n",
      "Obj 0\n",
      "Top, Left, Bottom, Right:  [48.164066314697266, 90.10779571533203, 366.4306335449219, 226.00790405273438]\n",
      "Prob: 0.8104715347290039\n",
      "Class: 0\n",
      "Obj 1\n",
      "Top, Left, Bottom, Right:  [47.188331604003906, 89.52362060546875, 365.5296630859375, 251.63427734375]\n",
      "Prob: 0.9394147396087646\n",
      "Class: 0\n",
      "Obj 2\n",
      "Top, Left, Bottom, Right:  [-11.830097198486328, 162.49073791503906, 417.1883544921875, 379.5888366699219]\n",
      "Prob: 0.808731198310852\n",
      "Class: 0\n",
      "Obj 3\n",
      "Top, Left, Bottom, Right:  [-10.848766326904297, 220.68942260742188, 417.3911437988281, 378.7641906738281]\n",
      "Prob: 0.8323299288749695\n",
      "Class: 0\n",
      "Obj 4\n",
      "Top, Left, Bottom, Right:  [11.502105712890625, 97.61204528808594, 458.6062316894531, 220.61135864257812]\n",
      "Prob: 0.9854548573493958\n",
      "Class: 0\n",
      "Obj 5\n",
      "Top, Left, Bottom, Right:  [3.9349899291992188, 95.25910949707031, 464.533935546875, 246.5352783203125]\n",
      "Prob: 0.9910253882408142\n",
      "Class: 0\n",
      "Obj 6\n",
      "Top, Left, Bottom, Right:  [9.286354064941406, 163.23150634765625, 461.9895324707031, 379.10028076171875]\n",
      "Prob: 0.7577266097068787\n",
      "Class: 0\n",
      "Obj 7\n",
      "Top, Left, Bottom, Right:  [32.89677429199219, 222.99533081054688, 438.84893798828125, 376.73785400390625]\n",
      "Prob: 0.8346235752105713\n",
      "Class: 0\n",
      "Obj 8\n",
      "Top, Left, Bottom, Right:  [108.29051208496094, 91.08155822753906, 428.4381408691406, 226.1217041015625]\n",
      "Prob: 0.9209972620010376\n",
      "Class: 0\n",
      "Obj 9\n",
      "Top, Left, Bottom, Right:  [92.4862060546875, 88.21308135986328, 442.4716796875, 255.94247436523438]\n",
      "Prob: 0.8659836053848267\n",
      "Class: 0\n",
      "Completed inference\n"
     ]
    }
   ],
   "source": [
    "if loadedModel is not None:\n",
    "#     image_directory = \"./test2017/000000000202.jpg\"\n",
    "    image_directory = \"./test2017/000000000890.jpg\"\n",
    "#     image_directory = \"./test2017/000000000171.jpg\"\n",
    "#     image_directory = \"./test2017/000000001371.jpg\"\n",
    "#     image_directory = \"./test2017/000000000647.jpg\"\n",
    "#     image_directory = \"./train2017/000000376608.jpg\"\n",
    "#     image_directory = \"./train2017/000000000036.jpg\"\n",
    "#     image_directory = \"./train2017/000000000394.jpg\"\n",
    "\n",
    "    image_data = []\n",
    "    prepImage = prepare_image(image_directory, (448,448))\n",
    "    print(prepImage.shape)\n",
    "    image_data = np.expand_dims(prepImage,axis=0)\n",
    "    processed_model_output = yolo_eval(\n",
    "        yolo_outputs = loadedModel.predict(\n",
    "            x = image_data,\n",
    "            verbose=1,\n",
    "            steps=1\n",
    "        ),\n",
    "        anchors=tinyYolo_anchors,\n",
    "        num_classes=80,\n",
    "        image_shape=(448,448),\n",
    "        max_boxes=20,\n",
    "        score_threshold=0.7,\n",
    "        iou_threshold=0.5\n",
    "    )\n",
    "    print(\"Found\", len(processed_model_output[0]), \"objects\")\n",
    "    for i in range(len(processed_model_output[0])):\n",
    "        print(\"Obj\", i)\n",
    "        print(\"Top, Left, Bottom, Right: \", processed_model_output[0][i])\n",
    "        print(\"Prob:\", processed_model_output[1][i])\n",
    "        print(\"Class:\", processed_model_output[2][i])\n",
    "print(\"Completed inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
