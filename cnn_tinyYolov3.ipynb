{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version 2.1.0\n",
      "Keras is running on tensorflow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "from PIL import Image\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Layer, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add, Lambda\n",
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint, Callback, EarlyStopping\n",
    "import keras.backend as K\n",
    "import os\n",
    "K.clear_session()\n",
    "K.set_floatx('float32')\n",
    "print(\"Running Tensorflow version\", tf.__version__)\n",
    "print(\"Keras is running on\", K.backend(), \"backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom layer classes successfully defined\n"
     ]
    }
   ],
   "source": [
    "# problem with model with rounding \n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # first one that works with model_1 & model_2 \n",
    "    # problem - this rounding function is slow: model_2 = 3 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # in addition, off by half with integer inputs (lower than actual value, e.g. floor(2) ≈ 1.5, floor(2.01) ≈ 2)\n",
    "    # source: https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#Continuity_and_series_expansions\n",
    "    if True:\n",
    "        result = x - 0.5\n",
    "        for p in range(1, 7):\n",
    "            result = result + K.sin(x * p * 2 * math.pi) / (p * math.pi)\n",
    "    return result\n",
    "# '''\n",
    "'''     \n",
    "def roundingAlgo(x):\n",
    "    # second one that works with model_2 \n",
    "    # problem - this rounding function is slower than first working algo: model_2 = 4,2 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # source: self\n",
    "    return x - x % 1\n",
    "# '''\n",
    "# '''\n",
    "def roundingAlgo(x): \n",
    "    # simplification of the first algo loop by simplifying the expression for range(1,7)\n",
    "    # problem - rounding function is still slow = 2,5 hours / epoch\n",
    "    # all non-speed problem of first algo still applies\n",
    "    result = x - 0.5\n",
    "    resultCos = K.cos(2 * math.pi * x)\n",
    "    return result + K.sin(2 * math.pi * x) * (1 + resultCos) * (13 + 2 * resultCos - 18 * K.pow(resultCos, 2) - 32 * K.pow(resultCos, 3) + 80 * K.pow(resultCos, 4)) / 15\n",
    "# '''\n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # made to fool the engine to have a gradient\n",
    "    return 0 * x + K.round(x)\n",
    "# '''\n",
    "\n",
    "\n",
    "# check https://github.com/keras-team/keras/issues/2218\n",
    "# check https://github.com/keras-team/keras/issues/2221\n",
    "# https://www.tensorflow.org/api_docs/python/tf/custom_gradient\n",
    "class RoundClampQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 4096), -524288, 524287) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 4096) + 524288) % 1048576) - 524288) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundClampQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 16), -128, 127) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 128) % 256) - 128) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class Identity(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(Identity, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class IdentityFinalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IdentityFinalLayer, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(IdentityFinalLayer, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "    \n",
    "def DBL(previousLayer, layerFilter, kernelSize=(3, 3), roundingFunction=Identity, name=None):\n",
    "    placeholder = \"\"\n",
    "    if name is not None:\n",
    "        placeholder = str(name)\n",
    "    else:\n",
    "        placeholder = str(time.time_ns())\n",
    "    return roundingFunction(name=\"ThirdRound_\"+placeholder, dtype=K.floatx())(\n",
    "        LeakyReLU(alpha=0.1, dtype=K.floatx())(\n",
    "            roundingFunction(name=\"SecondRound_\"+placeholder, dtype=K.floatx())(\n",
    "                BatchNormalization(name=\"BatchNorm_\"+placeholder, dtype=K.floatx())(\n",
    "                    roundingFunction(name=\"FirstRound_\"+placeholder, dtype=K.floatx())(\n",
    "                        Conv2D(filters=layerFilter, kernel_size=kernelSize, padding='same', use_bias=False, kernel_regularizer=l2(5e-4), name=\"Conv2D_\"+placeholder, dtype=K.floatx())(\n",
    "                            previousLayer\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "print(\"Custom layer classes successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class classification is 80\n"
     ]
    }
   ],
   "source": [
    "classificationClass = 80\n",
    "\n",
    "print(\"Number of class classification is\", classificationClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target data generator successfully defined\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''\n",
    "    random preprocessing for real-time data augmentation \n",
    "    \n",
    "    random=True induces image processing (better data accuracy with cost of cycles)\n",
    "    '''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "print(\"Target data generator successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diambil dari https://github.com/qqwweee/keras-yolo3\n",
    "'''\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 qqwweee\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    "\n",
    "image_size = (448,448)\n",
    "image_height, image_width = image_size\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "tinyYolo_anchors = get_anchors(\"../CNN-VLSI/tiny_yolo_anchors.txt\")\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # edited by instructions in https://stackoverflow.com/questions/57558476/training-a-keras-model-yields-multiple-optimizer-errors\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[...,::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[...,::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l], anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1] + 1e-10)\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data is 117266\n",
      "# of validation data is 4952\n"
     ]
    }
   ],
   "source": [
    "with open(\"../CNN-VLSI/train.txt\") as trainText:\n",
    "    train_annotation_lines = trainText.readlines()\n",
    "with open(\"../CNN-VLSI/val.txt\") as valText:\n",
    "    val_annotation_lines = valText.readlines()\n",
    "lenTrain = len(train_annotation_lines)\n",
    "print(\"# of training data is\", lenTrain)\n",
    "lenVal = len(val_annotation_lines)\n",
    "print(\"# of validation data is\", lenVal)\n",
    "np.random.shuffle(train_annotation_lines)\n",
    "np.random.shuffle(val_annotation_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 does no rounding (float32 operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, None, None, 3)\n",
      "Branch split from main branch - following branch 0\n",
      "Branch split from branch 0 - following branch 0,0\n",
      "Branch merge from branch 1 and branch 0,0\n",
      "Model output 1 shape: (None, None, None, 255)\n",
      "\n",
      "Branch split from branch 0 - following branch 0,1\n",
      "Model output 0 shape: (None, None, None, 255)\n",
      "\n",
      "Weight load attempt success for model_0\n",
      "Loaded model is successfully re-saved\n",
      "Model model_0 compilation complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_0 = None\n",
    "# '''\n",
    "model_0_input = Input(shape=(None, None, 3), name=\"model_0_inputLayer\")\n",
    "# model_0_pointer = model_0_input\n",
    "print(\"Input shape:\", model_0_input.shape) # 448 x 448 x 3\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_input, layerFilter=16, name=\"model_0_layer0_branch\") \n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 448 x 448 x 16\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 16\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=32, name=\"model_0_layer1_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 32\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 32\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=64, name=\"model_0_layer2_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 64\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 64\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=128, name=\"model_0_layer3_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 128\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=256, name=\"model_0_layer4_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_0_branch0\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer5_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_0_branch0)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=1024, name=\"model_0_layer6_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 1024\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_0_layer7_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_0_branch0 (14 x 14 x 256), following model_0_branch00\n",
    "model_0_branch00 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_0_layer8_branch00\")\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 128\n",
    "model_0_branch00 = UpSampling2D()(model_0_branch00)\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_0_branch1 (unchanged from model_0_startBranch) and model_0_branch00\n",
    "model_0_mergedBranch = Concatenate()([model_0_startBranch, model_0_branch00])\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 384\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=256, name=\"model_0_layer9_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layerA_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_0_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_0_mergedBranch = IdentityFinalLayer(name=\"model_0_outputLayer_1\")(model_0_mergedBranch)\n",
    "print() # OUTPUT = model_0_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_0_branch01\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer8_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layer9_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "print(\"Model output 0 shape:\", model_0_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_0_branch01 = IdentityFinalLayer(name=\"model_0_outputLayer_0\")(model_0_branch01)\n",
    "print() # OUTPUT = model_0_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_0_actual = Model(inputs=model_0_input, outputs=[model_0_branch01, model_0_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_0_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_0_actual.to_json())\n",
    "\n",
    "try:\n",
    "    model_0_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny-model_0.h5\", by_name=True, skip_mismatch=True)\n",
    "#     model_0_actual.load_weights(\"./saved_models/model_0_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_0\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_0:\", e)\n",
    "try:\n",
    "    model_0_actual.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_0 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_0 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_0_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_0', arguments=setArgs_model_0)([*model_0_actual.output, *y_true_model_0])\n",
    "\n",
    "model_0 = Model([model_0_actual.input, *y_true_model_0], model_0_loss)\n",
    "\n",
    "# model_0_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_0 adalah pendekatan sehingga output model_0 sedekat mungkin dengan 0 (model_0 ≈ model_0_actual - y_true)\n",
    "model_0_learnRate = 1e-2\n",
    "model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_0 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 approximates Q7.12 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = None\n",
    "'''\n",
    "model_1_input = Input(shape=(None, None, 3), name=\"model_1_inputLayer\")\n",
    "# model_1_pointer = model_1_input\n",
    "print(\"Input shape:\", model_1_input.shape) # 448 x 448 x 3\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_input, layerFilter=16, name=\"model_1_layer0_branch\") \n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 448 x 448 x 16\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 16\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=32, name=\"model_1_layer1_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 32\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 32\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=64, name=\"model_1_layer2_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 64\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 64\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=128, name=\"model_1_layer3_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 128\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=256, name=\"model_1_layer4_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_1_branch0\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer5_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_1_branch0)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=1024, name=\"model_1_layer6_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 1024\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_1_layer7_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_1_branch0 (14 x 14 x 256), following model_1_branch00\n",
    "model_1_branch00 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_1_layer8_branch00\")\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 128\n",
    "model_1_branch00 = UpSampling2D()(model_1_branch00)\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_1_branch1 (unchanged from model_1_startBranch) and model_1_branch00\n",
    "model_1_mergedBranch = Concatenate()([model_1_startBranch, model_1_branch00])\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 384\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=256, name=\"model_1_layer9_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layerA_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_1_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_1_mergedBranch = IdentityFinalLayer(name=\"model_1_outputLayer_1\")(model_1_mergedBranch)\n",
    "print() # OUTPUT = model_1_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_1_branch01\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer8_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layer9_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "print(\"Model output 0 shape:\", model_1_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_1_branch01 = IdentityFinalLayer(name=\"model_1_outputLayer_0\")(model_1_branch01)\n",
    "print() # OUTPUT = model_1_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_1_actual = Model(inputs=model_1_input, outputs=[model_1_branch01, model_1_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_1_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_1_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_1_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_1_actual.load_weights(\"./saved_models/model_1_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_1\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_1:\", e)\n",
    "try:\n",
    "    model_1_actual.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_1 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_1 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_1_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_1', arguments=setArgs_model_1)([*model_1_actual.output, *y_true_model_1])\n",
    "\n",
    "model_1 = Model([model_1_actual.input, *y_true_model_1], model_1_loss)\n",
    "\n",
    "# model_1_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_1 adalah pendekatan sehingga output model_1 sedekat mungkin dengan 0 (model_1 ≈ model_1_actual - y_true)\n",
    "model_1_learnRate = 1e-2\n",
    "model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_1 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 approximates Q7.12 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = None\n",
    "'''\n",
    "model_2_input = Input(shape=(None, None, 3), name=\"model_2_inputLayer\")\n",
    "# model_2_pointer = model_2_input\n",
    "print(\"Input shape:\", model_2_input.shape) # 448 x 448 x 3\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_input, layerFilter=16, name=\"model_2_layer0_branch\") \n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 448 x 448 x 16\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 16\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=32, name=\"model_2_layer1_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 32\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 32\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=64, name=\"model_2_layer2_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 64\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 64\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=128, name=\"model_2_layer3_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 128\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=256, name=\"model_2_layer4_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_2_branch0\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer5_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_2_branch0)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=1024, name=\"model_2_layer6_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 1024\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_2_layer7_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_2_branch0 (14 x 14 x 256), following model_2_branch00\n",
    "model_2_branch00 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_2_layer8_branch00\")\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 128\n",
    "model_2_branch00 = UpSampling2D()(model_2_branch00)\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_2_branch1 (unchanged from model_2_startBranch) and model_2_branch00\n",
    "model_2_mergedBranch = Concatenate()([model_2_startBranch, model_2_branch00])\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 384\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=256, name=\"model_2_layer9_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layerA_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_2_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_2_mergedBranch = IdentityFinalLayer(name=\"model_2_outputLayer_1\")(model_2_mergedBranch)\n",
    "print() # OUTPUT = model_2_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_2_branch01\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer8_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layer9_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "print(\"Model output 0 shape:\", model_2_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_2_branch01 = IdentityFinalLayer(name=\"model_2_outputLayer_0\")(model_2_branch01)\n",
    "print() # OUTPUT = model_2_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_2_actual = Model(inputs=model_2_input, outputs=[model_2_branch01, model_2_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_2_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_2_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_2_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_2_actual.load_weights(\"./saved_models/model_2_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_2\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_2:\", e)\n",
    "try:\n",
    "    model_2_actual.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_2 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_2 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_2_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_2', arguments=setArgs_model_2)([*model_2_actual.output, *y_true_model_2])\n",
    "\n",
    "model_2 = Model([model_2_actual.input, *y_true_model_2], model_2_loss)\n",
    "\n",
    "# model_2_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_2 adalah pendekatan sehingga output model_2 sedekat mungkin dengan 0 (model_2 ≈ model_2_actual - y_true)\n",
    "model_2_learnRate = 1e-2\n",
    "model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_2 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 approximates Q3.4 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = None\n",
    "'''\n",
    "model_3_input = Input(shape=(None, None, 3), name=\"model_3_inputLayer\")\n",
    "# model_3_pointer = model_3_input\n",
    "print(\"Input shape:\", model_3_input.shape) # 448 x 448 x 3\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_input, layerFilter=16, name=\"model_3_layer0_branch\") \n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 448 x 448 x 16\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 16\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=32, name=\"model_3_layer1_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 32\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 32\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=64, name=\"model_3_layer2_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 64\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 64\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=128, name=\"model_3_layer3_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 128\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=256, name=\"model_3_layer4_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_3_branch0\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer5_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_3_branch0)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=1024, name=\"model_3_layer6_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 1024\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_3_layer7_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_3_branch0 (14 x 14 x 256), following model_3_branch00\n",
    "model_3_branch00 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_3_layer8_branch00\")\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 128\n",
    "model_3_branch00 = UpSampling2D()(model_3_branch00)\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_3_branch1 (unchanged from model_3_startBranch) and model_3_branch00\n",
    "model_3_mergedBranch = Concatenate()([model_3_startBranch, model_3_branch00])\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 384\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=256, name=\"model_3_layer9_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layerA_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_3_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_3_mergedBranch = IdentityFinalLayer(name=\"model_3_outputLayer_1\")(model_3_mergedBranch)\n",
    "print() # OUTPUT = model_3_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_3_branch01\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer8_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layer9_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "print(\"Model output 0 shape:\", model_3_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_3_branch01 = IdentityFinalLayer(name=\"model_3_outputLayer_0\")(model_3_branch01)\n",
    "print() # OUTPUT = model_3_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_3_actual = Model(inputs=model_3_input, outputs=[model_3_branch01, model_3_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_3_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_3_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_3_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_3_actual.load_weights(\"./saved_models/model_3_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_3\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_3:\", e)\n",
    "try:\n",
    "    model_3_actual.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_3 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_3 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_3_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_3', arguments=setArgs_model_3)([*model_3_actual.output, *y_true_model_3])\n",
    "\n",
    "model_3 = Model([model_3_actual.input, *y_true_model_3], model_3_loss)\n",
    "\n",
    "# model_3_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_3 adalah pendekatan sehingga output model_3 sedekat mungkin dengan 0 (model_3 ≈ model_3_actual - y_true)\n",
    "model_3_learnRate = 1e-2\n",
    "model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_3 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 approximates Q3.4 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = None\n",
    "'''\n",
    "model_4_input = Input(shape=(None, None, 3), name=\"model_4_inputLayer\")\n",
    "# model_4_pointer = model_4_input\n",
    "print(\"Input shape:\", model_4_input.shape) # 448 x 448 x 3\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_input, layerFilter=16, name=\"model_4_layer0_branch\") \n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 448 x 448 x 16\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 16\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=32, name=\"model_4_layer1_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 32\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 32\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=64, name=\"model_4_layer2_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 64\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 64\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=128, name=\"model_4_layer3_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 128\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=256, name=\"model_4_layer4_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_4_branch0\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer5_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_4_branch0)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=1024, name=\"model_4_layer6_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 1024\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_4_layer7_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_4_branch0 (14 x 14 x 256), following model_4_branch00\n",
    "model_4_branch00 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_4_layer8_branch00\")\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 128\n",
    "model_4_branch00 = UpSampling2D()(model_4_branch00)\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_4_branch1 (unchanged from model_4_startBranch) and model_4_branch00\n",
    "model_4_mergedBranch = Concatenate()([model_4_startBranch, model_4_branch00])\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 384\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=256, name=\"model_4_layer9_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layerA_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_4_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_4_mergedBranch = IdentityFinalLayer(name=\"model_4_outputLayer_1\")(model_4_mergedBranch)\n",
    "print() # OUTPUT = model_4_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_4_branch01\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer8_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layer9_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "print(\"Model output 0 shape:\", model_4_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_4_branch01 = IdentityFinalLayer(name=\"model_4_outputLayer_0\")(model_4_branch01)\n",
    "print() # OUTPUT = model_4_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_4_actual = Model(inputs=model_4_input, outputs=[model_4_branch01, model_4_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_4_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_4_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_4_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny-model_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_4_actual.load_weights(\"./saved_models/model_4_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_4\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_4:\", e)\n",
    "try:\n",
    "    model_4_actual.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_4 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_4 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_4_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_4', arguments=setArgs_model_4)([*model_4_actual.output, *y_true_model_4])\n",
    "\n",
    "model_4 = Model([model_4_actual.input, *y_true_model_4], model_4_loss)\n",
    "\n",
    "# model_4_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_4 adalah pendekatan sehingga output model_4 sedekat mungkin dengan 0 (model_4 ≈ model_4_actual - y_true)\n",
    "model_4_learnRate = 1e-3\n",
    "model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_4 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_0 is not None:\n",
    "    with open(\"./saved_models/model_0_summary.txt\", \"wt\") as textFile:\n",
    "        model_0.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_1 is not None:\n",
    "    with open(\"./saved_models/model_1_summary.txt\", \"wt\") as textFile:\n",
    "        model_1.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_2 is not None:\n",
    "    with open(\"./saved_models/model_2_summary.txt\", \"wt\") as textFile:\n",
    "        model_2.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_3 is not None:\n",
    "    with open(\"./saved_models/model_3_summary.txt\", \"wt\") as textFile:\n",
    "        model_3.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_4 is not None:\n",
    "    with open(\"./saved_models/model_4_summary.txt\", \"wt\") as textFile:\n",
    "        model_4.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "trainingBatchSize = 1\n",
    "epochSplit = 1047 \n",
    "# because high split = more work saved; 117266 mod 499 = 1 <= less image lost for (416,416)\n",
    "# 117266 mod 1047 = 2 <= due to high loss of (448,448)\n",
    "train_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=train_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "val_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=val_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "minimumLR = 1e-4\n",
    "decayChance = 0.50\n",
    "class BestValueRecorder(Callback):\n",
    "    def __init__(self, filepath, monitorValidation=False, mode='min', verbose=1, instanceModelCheckpointLoss=None, instanceModelCheckpointVal=None):\n",
    "        super(BestValueRecorder, self).__init__()\n",
    "        self.lookOnVal = monitorValidation\n",
    "        self.verbose = verbose\n",
    "        if mode not in ['min', 'max']:\n",
    "            mode = 'min'\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.MCLossValue = np.Inf\n",
    "            self.MCValLossValue = np.Inf\n",
    "        else:\n",
    "            self.monitor_op = np.greater\n",
    "            self.MCLossValue = -np.Inf\n",
    "            self.MCValLossValue = -np.Inf\n",
    "        self.filepath = filepath\n",
    "        try:\n",
    "            with open(self.filepath, 'rt') as jsonFile:\n",
    "                bestValueList = json.loads(jsonFile.read())\n",
    "                self.MCLossValue =  bestValueList[0]\n",
    "                if self.lookOnVal:\n",
    "                    self.MCValLossValue = bestValueList[1]\n",
    "        except Exception as e:\n",
    "            print(\"Failed to open JSON file:\", e)\n",
    "        if instanceModelCheckpointLoss is not None:\n",
    "            instanceModelCheckpointLoss.best = self.MCLossValue\n",
    "        if instanceModelCheckpointVal is not None and monitorValidation:\n",
    "            instanceModelCheckpointVal.best = self.MCValLossValue\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        currentLoss = logs.get('loss')\n",
    "        newChange = False\n",
    "        if currentLoss is not None and self.monitor_op(currentLoss, self.MCLossValue):\n",
    "            self.MCLossValue = currentLoss\n",
    "            newChange = True\n",
    "        if self.lookOnVal:\n",
    "            currentValLoss = logs.get('val_loss')\n",
    "            if currentValLoss is not None and self.monitor_op(currentValLoss, self.MCValLossValue):\n",
    "                self.MCValLossValue = currentValLoss\n",
    "                newChange = True\n",
    "        if newChange:\n",
    "            try:\n",
    "                with open(self.filepath, 'wt') as jsonFile:\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Saving best loss value:\", [self.MCLossValue, self.MCValLossValue])\n",
    "                    jsonFile.write(json.dumps([self.MCLossValue, self.MCValLossValue]))\n",
    "            except Exception as e:\n",
    "                print(\"Failed to open JSON file:\", e)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to open JSON file: [Errno 2] No such file or directory: './saved_models/model_0_bestValue.json'\n",
      "Time 0.000997781753540039\n",
      "Super-epoch 1 - learn rate: 0.01 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 32s - loss: 2301.0102 - val_loss: 894.0676\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 894.06757, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [2301.01023210798, 894.0675659179688]\n",
      "Epoch 2/1047\n",
      " - 25s - loss: 2142.7837 - val_loss: 2365.2607\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00002: loss improved from inf to 2142.78371, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [2142.783708844866, 894.0675659179688]\n",
      "Epoch 3/1047\n",
      " - 27s - loss: 2026.5820 - val_loss: 1862.9827\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [2026.5819778442383, 894.0675659179688]\n",
      "Epoch 4/1047\n",
      " - 27s - loss: 1978.0873 - val_loss: 2855.9595\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00004: loss improved from 2142.78371 to 1978.08729, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1978.0872944423131, 894.0675659179688]\n",
      "Epoch 5/1047\n",
      " - 26s - loss: 1912.8413 - val_loss: 1973.5316\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1912.8412780761719, 894.0675659179688]\n",
      "Epoch 6/1047\n",
      " - 24s - loss: 1821.2097 - val_loss: 1730.5250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00006: loss improved from 1978.08729 to 1821.20972, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1821.2097200666155, 894.0675659179688]\n",
      "Epoch 7/1047\n",
      " - 23s - loss: 1704.2951 - val_loss: 1575.1005\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1704.2951289585658, 894.0675659179688]\n",
      "Epoch 8/1047\n",
      " - 28s - loss: 1629.5160 - val_loss: 1589.7435\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00008: loss improved from 1821.20972 to 1629.51597, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1629.5159661429268, 894.0675659179688]\n",
      "Epoch 9/1047\n",
      " - 23s - loss: 1532.5012 - val_loss: 1463.2046\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1532.5011553083148, 894.0675659179688]\n",
      "Epoch 10/1047\n",
      " - 28s - loss: 1426.0555 - val_loss: 1224.2665\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00010: loss improved from 1629.51597 to 1426.05552, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1426.0555223737445, 894.0675659179688]\n",
      "Epoch 11/1047\n",
      " - 22s - loss: 1394.9934 - val_loss: 1461.7167\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1394.9934419904437, 894.0675659179688]\n",
      "Epoch 12/1047\n",
      " - 23s - loss: 1305.7188 - val_loss: 1142.2031\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00012: loss improved from 1426.05552 to 1305.71881, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1305.7188132149834, 894.0675659179688]\n",
      "Epoch 13/1047\n",
      " - 24s - loss: 1254.0647 - val_loss: 1086.8823\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1254.0647375924248, 894.0675659179688]\n",
      "Epoch 14/1047\n",
      " - 23s - loss: 1158.7574 - val_loss: 1055.2311\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00014: loss improved from 1305.71881 to 1158.75737, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1158.7573672703334, 894.0675659179688]\n",
      "Epoch 15/1047\n",
      " - 21s - loss: 1124.6747 - val_loss: 1055.3195\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [1124.6747262137276, 894.0675659179688]\n",
      "Epoch 16/1047\n",
      " - 32s - loss: 1031.6627 - val_loss: 1126.9655\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00016: loss improved from 1158.75737 to 1031.66271, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [1031.6627137320381, 894.0675659179688]\n",
      "Epoch 17/1047\n",
      " - 21s - loss: 969.2045 - val_loss: 1018.6843\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [969.2045119149344, 894.0675659179688]\n",
      "Epoch 18/1047\n",
      " - 25s - loss: 911.8846 - val_loss: 1573.7014\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00018: loss improved from 1031.66271 to 911.88461, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [911.8846146719796, 894.0675659179688]\n",
      "Epoch 19/1047\n",
      " - 23s - loss: 870.3961 - val_loss: 1018.8101\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 894.06757\n",
      "Saving best loss value: [870.3961219787598, 894.0675659179688]\n",
      "Epoch 20/1047\n",
      " - 23s - loss: 849.5273 - val_loss: 913.7843\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 894.06757\n",
      "\n",
      "Epoch 00020: loss improved from 911.88461 to 849.52726, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [849.5272592817034, 894.0675659179688]\n",
      "Epoch 21/1047\n",
      " - 22s - loss: 790.2476 - val_loss: 695.7363\n",
      "\n",
      "Epoch 00021: val_loss improved from 894.06757 to 695.73627, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [790.2476408822196, 695.7362670898438]\n",
      "Epoch 22/1047\n",
      " - 24s - loss: 770.4411 - val_loss: 680.0165\n",
      "\n",
      "Epoch 00022: val_loss improved from 695.73627 to 680.01648, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00022: loss improved from 849.52726 to 770.44110, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [770.4411032540457, 680.0164794921875]\n",
      "Epoch 23/1047\n",
      " - 23s - loss: 715.2455 - val_loss: 690.8395\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 680.01648\n",
      "Saving best loss value: [715.2455008370536, 680.0164794921875]\n",
      "Epoch 24/1047\n",
      " - 26s - loss: 718.4622 - val_loss: 663.7192\n",
      "\n",
      "Epoch 00024: val_loss improved from 680.01648 to 663.71918, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00024: loss improved from 770.44110 to 718.46224, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [715.2455008370536, 663.7191772460938]\n",
      "Epoch 25/1047\n",
      " - 23s - loss: 641.2875 - val_loss: 583.2443\n",
      "\n",
      "Epoch 00025: val_loss improved from 663.71918 to 583.24426, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [641.2875093732562, 583.2442626953125]\n",
      "Epoch 26/1047\n",
      " - 22s - loss: 613.7979 - val_loss: 605.0378\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 583.24426\n",
      "\n",
      "Epoch 00026: loss improved from 718.46224 to 613.79789, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [613.7978864397321, 583.2442626953125]\n",
      "Epoch 27/1047\n",
      " - 22s - loss: 583.4308 - val_loss: 529.8892\n",
      "\n",
      "Epoch 00027: val_loss improved from 583.24426 to 529.88922, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [583.430785042899, 529.8892211914062]\n",
      "Epoch 28/1047\n",
      " - 23s - loss: 568.4367 - val_loss: 490.2668\n",
      "\n",
      "Epoch 00028: val_loss improved from 529.88922 to 490.26685, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00028: loss improved from 613.79789 to 568.43668, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [568.4366765703473, 490.266845703125]\n",
      "Epoch 29/1047\n",
      " - 25s - loss: 542.5999 - val_loss: 451.5366\n",
      "\n",
      "Epoch 00029: val_loss improved from 490.26685 to 451.53656, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [542.5998595101493, 451.53656005859375]\n",
      "Epoch 30/1047\n",
      " - 23s - loss: 510.7694 - val_loss: 565.9210\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 451.53656\n",
      "\n",
      "Epoch 00030: loss improved from 568.43668 to 510.76943, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [510.76943261282787, 451.53656005859375]\n",
      "Epoch 31/1047\n",
      " - 27s - loss: 494.1440 - val_loss: 450.0269\n",
      "\n",
      "Epoch 00031: val_loss improved from 451.53656 to 450.02689, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [494.143960407802, 450.0268859863281]\n",
      "Epoch 32/1047\n",
      " - 22s - loss: 459.9666 - val_loss: 381.8508\n",
      "\n",
      "Epoch 00032: val_loss improved from 450.02689 to 381.85080, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00032: loss improved from 510.76943 to 459.96665, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [459.9666467394148, 381.8507995605469]\n",
      "Epoch 33/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 452.6729 - val_loss: 356.2049\n",
      "\n",
      "Epoch 00033: val_loss improved from 381.85080 to 356.20490, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [452.6729278564453, 356.20489501953125]\n",
      "Epoch 34/1047\n",
      " - 22s - loss: 457.0593 - val_loss: 399.1700\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 356.20490\n",
      "\n",
      "Epoch 00034: loss improved from 459.96665 to 457.05927, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 35/1047\n",
      " - 23s - loss: 424.6383 - val_loss: 391.9345\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 356.20490\n",
      "Saving best loss value: [424.63830075945174, 356.20489501953125]\n",
      "Epoch 36/1047\n",
      " - 26s - loss: 404.2475 - val_loss: 568.9353\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 356.20490\n",
      "\n",
      "Epoch 00036: loss improved from 457.05927 to 404.24745, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [404.2474504198347, 356.20489501953125]\n",
      "Epoch 37/1047\n",
      " - 27s - loss: 387.1535 - val_loss: 358.3456\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 356.20490\n",
      "Saving best loss value: [387.15352630615234, 356.20489501953125]\n",
      "Epoch 38/1047\n",
      " - 23s - loss: 364.6684 - val_loss: 272.9243\n",
      "\n",
      "Epoch 00038: val_loss improved from 356.20490 to 272.92426, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00038: loss improved from 404.24745 to 364.66837, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [364.668370110648, 272.92425537109375]\n",
      "Epoch 39/1047\n",
      " - 27s - loss: 349.0835 - val_loss: 323.2418\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 272.92426\n",
      "Saving best loss value: [349.08352524893627, 272.92425537109375]\n",
      "Epoch 40/1047\n",
      " - 21s - loss: 334.2451 - val_loss: 333.5166\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 272.92426\n",
      "\n",
      "Epoch 00040: loss improved from 364.66837 to 334.24511, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [334.24510710580006, 272.92425537109375]\n",
      "Epoch 41/1047\n",
      " - 21s - loss: 314.5617 - val_loss: 336.1591\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 272.92426\n",
      "Saving best loss value: [314.5616756166731, 272.92425537109375]\n",
      "Epoch 42/1047\n",
      " - 26s - loss: 310.8026 - val_loss: 412.4413\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 272.92426\n",
      "\n",
      "Epoch 00042: loss improved from 334.24511 to 310.80257, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [310.80256720951627, 272.92425537109375]\n",
      "Epoch 43/1047\n",
      " - 23s - loss: 295.2935 - val_loss: 242.3638\n",
      "\n",
      "Epoch 00043: val_loss improved from 272.92426 to 242.36380, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [295.2935329164778, 242.36380004882812]\n",
      "Epoch 44/1047\n",
      " - 25s - loss: 301.6840 - val_loss: 420.7209\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 242.36380\n",
      "\n",
      "Epoch 00044: loss improved from 310.80257 to 301.68400, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 45/1047\n",
      " - 20s - loss: 291.6074 - val_loss: 901.7390\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 242.36380\n",
      "Saving best loss value: [291.6074345452445, 242.36380004882812]\n",
      "Epoch 46/1047\n",
      " - 26s - loss: 300.2159 - val_loss: 1421.3888\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 242.36380\n",
      "\n",
      "Epoch 00046: loss improved from 301.68400 to 300.21594, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 47/1047\n",
      " - 20s - loss: 274.6603 - val_loss: 202.8596\n",
      "\n",
      "Epoch 00047: val_loss improved from 242.36380 to 202.85965, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [274.66028894696916, 202.85964965820312]\n",
      "Epoch 48/1047\n",
      " - 25s - loss: 258.8484 - val_loss: 416.5658\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 202.85965\n",
      "\n",
      "Epoch 00048: loss improved from 300.21594 to 258.84842, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [258.84841646466936, 202.85964965820312]\n",
      "Epoch 49/1047\n",
      " - 23s - loss: 243.2555 - val_loss: 266.0134\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 202.85965\n",
      "Saving best loss value: [243.25550201960974, 202.85964965820312]\n",
      "Epoch 50/1047\n",
      " - 22s - loss: 244.4509 - val_loss: 214.5975\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 202.85965\n",
      "\n",
      "Epoch 00050: loss improved from 258.84842 to 244.45091, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 51/1047\n",
      " - 21s - loss: 235.1800 - val_loss: 392.2393\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 202.85965\n",
      "Saving best loss value: [235.18003586360388, 202.85964965820312]\n",
      "Epoch 52/1047\n",
      " - 25s - loss: 219.6534 - val_loss: 236.6193\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 202.85965\n",
      "\n",
      "Epoch 00052: loss improved from 244.45091 to 219.65340, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [219.65340491703577, 202.85964965820312]\n",
      "Epoch 53/1047\n",
      " - 22s - loss: 223.3772 - val_loss: 331.1415\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 202.85965\n",
      "Epoch 54/1047\n",
      " - 24s - loss: 206.8511 - val_loss: 610.4245\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 202.85965\n",
      "\n",
      "Epoch 00054: loss improved from 219.65340 to 206.85110, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [206.85110228402274, 202.85964965820312]\n",
      "Epoch 55/1047\n",
      " - 21s - loss: 191.4825 - val_loss: 305.9844\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 202.85965\n",
      "Saving best loss value: [191.48247752870833, 202.85964965820312]\n",
      "Epoch 56/1047\n",
      " - 26s - loss: 199.5154 - val_loss: 206.1427\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 202.85965\n",
      "\n",
      "Epoch 00056: loss improved from 206.85110 to 199.51539, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 57/1047\n",
      " - 22s - loss: 205.0468 - val_loss: 150.0771\n",
      "\n",
      "Epoch 00057: val_loss improved from 202.85965 to 150.07712, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [191.48247752870833, 150.07711791992188]\n",
      "Epoch 58/1047\n",
      " - 21s - loss: 185.9928 - val_loss: 339.6686\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 150.07712\n",
      "\n",
      "Epoch 00058: loss improved from 199.51539 to 185.99282, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [185.99282469068254, 150.07711791992188]\n",
      "Epoch 59/1047\n",
      " - 21s - loss: 182.7689 - val_loss: 223.7400\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 150.07712\n",
      "Saving best loss value: [182.76891469955444, 150.07711791992188]\n",
      "Epoch 60/1047\n",
      " - 27s - loss: 174.4682 - val_loss: 214.9311\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 150.07712\n",
      "\n",
      "Epoch 00060: loss improved from 185.99282 to 174.46819, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [174.4681874683925, 150.07711791992188]\n",
      "Epoch 61/1047\n",
      " - 21s - loss: 176.2789 - val_loss: 122.8543\n",
      "\n",
      "Epoch 00061: val_loss improved from 150.07712 to 122.85432, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [174.4681874683925, 122.85431671142578]\n",
      "Epoch 62/1047\n",
      " - 19s - loss: 181.1686 - val_loss: 167.9607\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 122.85432\n",
      "\n",
      "Epoch 00062: loss did not improve from 174.46819\n",
      "Epoch 63/1047\n",
      " - 31s - loss: 159.7337 - val_loss: 318.3701\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 122.85432\n",
      "Saving best loss value: [159.73373188291276, 122.85431671142578]\n",
      "Epoch 64/1047\n",
      " - 25s - loss: 184.9946 - val_loss: 118.7764\n",
      "\n",
      "Epoch 00064: val_loss improved from 122.85432 to 118.77640, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00064: loss did not improve from 174.46819\n",
      "Saving best loss value: [159.73373188291276, 118.77639770507812]\n",
      "Epoch 65/1047\n",
      " - 23s - loss: 159.4628 - val_loss: 185.6190\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 118.77640\n",
      "Saving best loss value: [159.46279621124268, 118.77639770507812]\n",
      "Epoch 66/1047\n",
      " - 26s - loss: 157.0893 - val_loss: 194.9527\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 118.77640\n",
      "\n",
      "Epoch 00066: loss improved from 174.46819 to 157.08928, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [157.08927726745605, 118.77639770507812]\n",
      "Epoch 67/1047\n",
      " - 24s - loss: 151.4783 - val_loss: 112.3711\n",
      "\n",
      "Epoch 00067: val_loss improved from 118.77640 to 112.37107, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [151.4783137866429, 112.3710708618164]\n",
      "Epoch 68/1047\n",
      " - 20s - loss: 157.0409 - val_loss: 88.1405\n",
      "\n",
      "Epoch 00068: val_loss improved from 112.37107 to 88.14046, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00068: loss improved from 157.08928 to 157.04092, saving model to ./saved_models/model_0_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best loss value: [151.4783137866429, 88.14046478271484]\n",
      "Epoch 69/1047\n",
      " - 26s - loss: 130.0446 - val_loss: 73.9109\n",
      "\n",
      "Epoch 00069: val_loss improved from 88.14046 to 73.91090, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [130.04458039147514, 73.91089630126953]\n",
      "Epoch 70/1047\n",
      " - 21s - loss: 132.2868 - val_loss: 191.0195\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 73.91090\n",
      "\n",
      "Epoch 00070: loss improved from 157.04092 to 132.28683, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 71/1047\n",
      " - 20s - loss: 139.5778 - val_loss: 112.3438\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 73.91090\n",
      "Epoch 72/1047\n",
      " - 25s - loss: 145.7520 - val_loss: 203.9341\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 73.91090\n",
      "\n",
      "Epoch 00072: loss did not improve from 132.28683\n",
      "Epoch 73/1047\n",
      " - 20s - loss: 143.7640 - val_loss: 154.8047\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 73.91090\n",
      "Epoch 74/1047\n",
      " - 20s - loss: 121.5890 - val_loss: 85.3556\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 73.91090\n",
      "\n",
      "Epoch 00074: loss improved from 132.28683 to 121.58898, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [121.58897924423218, 73.91089630126953]\n",
      "Epoch 75/1047\n",
      " - 20s - loss: 128.0700 - val_loss: 69.9759\n",
      "\n",
      "Epoch 00075: val_loss improved from 73.91090 to 69.97591, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [121.58897924423218, 69.97591400146484]\n",
      "Epoch 76/1047\n",
      " - 20s - loss: 117.2564 - val_loss: 217.6814\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 69.97591\n",
      "\n",
      "Epoch 00076: loss improved from 121.58898 to 117.25640, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [117.25639540808541, 69.97591400146484]\n",
      "Epoch 77/1047\n",
      " - 20s - loss: 136.2582 - val_loss: 88.1110\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 69.97591\n",
      "Epoch 78/1047\n",
      " - 23s - loss: 120.0879 - val_loss: 57.9424\n",
      "\n",
      "Epoch 00078: val_loss improved from 69.97591 to 57.94242, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00078: loss did not improve from 117.25640\n",
      "Saving best loss value: [117.25639540808541, 57.942420959472656]\n",
      "Epoch 79/1047\n",
      " - 19s - loss: 115.5826 - val_loss: 50.8818\n",
      "\n",
      "Epoch 00079: val_loss improved from 57.94242 to 50.88182, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [115.58259504181999, 50.88181686401367]\n",
      "Epoch 80/1047\n",
      " - 18s - loss: 123.1275 - val_loss: 163.4187\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 50.88182\n",
      "\n",
      "Epoch 00080: loss did not improve from 117.25640\n",
      "Epoch 81/1047\n",
      " - 24s - loss: 122.1834 - val_loss: 346.7788\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 50.88182\n",
      "Epoch 82/1047\n",
      " - 19s - loss: 113.0281 - val_loss: 153.1000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 50.88182\n",
      "\n",
      "Epoch 00082: loss improved from 117.25640 to 113.02806, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [113.02805611065456, 50.88181686401367]\n",
      "Epoch 83/1047\n",
      " - 20s - loss: 124.4759 - val_loss: 47.4990\n",
      "\n",
      "Epoch 00083: val_loss improved from 50.88182 to 47.49905, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [113.02805611065456, 47.499046325683594]\n",
      "Epoch 84/1047\n",
      " - 20s - loss: 115.9792 - val_loss: 74.4725\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 47.49905\n",
      "\n",
      "Epoch 00084: loss did not improve from 113.02806\n",
      "Epoch 85/1047\n",
      " - 24s - loss: 101.8040 - val_loss: 64.1526\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 47.49905\n",
      "Saving best loss value: [101.80403903552464, 47.499046325683594]\n",
      "Epoch 86/1047\n",
      " - 19s - loss: 105.1495 - val_loss: 29.2553\n",
      "\n",
      "Epoch 00086: val_loss improved from 47.49905 to 29.25527, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00086: loss improved from 113.02806 to 105.14955, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [101.80403903552464, 29.255266189575195]\n",
      "Epoch 87/1047\n",
      " - 19s - loss: 115.0334 - val_loss: 99.5796\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 29.25527\n",
      "Epoch 88/1047\n",
      " - 23s - loss: 104.7964 - val_loss: 63.1030\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00088: loss improved from 105.14955 to 104.79639, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 89/1047\n",
      " - 20s - loss: 92.1676 - val_loss: 143.7720\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 29.25527\n",
      "Saving best loss value: [92.16760165350777, 29.255266189575195]\n",
      "Epoch 90/1047\n",
      " - 23s - loss: 103.1766 - val_loss: 39.2618\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00090: loss improved from 104.79639 to 103.17657, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 91/1047\n",
      " - 20s - loss: 100.8157 - val_loss: 142.7661\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 29.25527\n",
      "Epoch 92/1047\n",
      " - 22s - loss: 100.1263 - val_loss: 38.6477\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00092: loss improved from 103.17657 to 100.12633, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 93/1047\n",
      " - 20s - loss: 109.4367 - val_loss: 97.7230\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 29.25527\n",
      "Epoch 94/1047\n",
      " - 23s - loss: 104.0987 - val_loss: 117.4866\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00094: loss did not improve from 100.12633\n",
      "Epoch 95/1047\n",
      " - 21s - loss: 99.5538 - val_loss: 160.2170\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 29.25527\n",
      "Epoch 96/1047\n",
      " - 21s - loss: 85.9968 - val_loss: 87.4137\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00096: loss improved from 100.12633 to 85.99679, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [85.99679221425738, 29.255266189575195]\n",
      "Epoch 97/1047\n",
      " - 22s - loss: 92.0940 - val_loss: 57.6532\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 29.25527\n",
      "Epoch 98/1047\n",
      " - 23s - loss: 90.2652 - val_loss: 62.2175\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00098: loss did not improve from 85.99679\n",
      "Epoch 99/1047\n",
      " - 20s - loss: 93.3021 - val_loss: 158.8784\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 29.25527\n",
      "Epoch 100/1047\n",
      " - 18s - loss: 91.8940 - val_loss: 201.7858\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00100: loss did not improve from 85.99679\n",
      "Epoch 101/1047\n",
      " - 22s - loss: 99.3976 - val_loss: 58.4325\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 29.25527\n",
      "Epoch 102/1047\n",
      " - 19s - loss: 90.2064 - val_loss: 56.3791\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00102: loss did not improve from 85.99679\n",
      "Epoch 103/1047\n",
      " - 22s - loss: 129.0220 - val_loss: 152.4945\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 29.25527\n",
      "Epoch 104/1047\n",
      " - 23s - loss: 99.2907 - val_loss: 157.9068\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00104: loss did not improve from 85.99679\n",
      "Epoch 105/1047\n",
      " - 19s - loss: 98.9840 - val_loss: 199.5530\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 29.25527\n",
      "Epoch 106/1047\n",
      " - 21s - loss: 99.8796 - val_loss: 214.6214\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00106: loss did not improve from 85.99679\n",
      "Epoch 107/1047\n",
      " - 21s - loss: 96.8455 - val_loss: 41.8805\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 29.25527\n",
      "Epoch 108/1047\n",
      " - 20s - loss: 87.8632 - val_loss: 83.7542\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00108: loss did not improve from 85.99679\n",
      "Epoch 109/1047\n",
      " - 19s - loss: 102.3819 - val_loss: 60.9144\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 29.25527\n",
      "Epoch 110/1047\n",
      " - 23s - loss: 85.7800 - val_loss: 46.2929\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00110: loss improved from 85.99679 to 85.78002, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [85.78001758030483, 29.255266189575195]\n",
      "Epoch 111/1047\n",
      " - 23s - loss: 90.3429 - val_loss: 71.4847\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 29.25527\n",
      "Epoch 112/1047\n",
      " - 28s - loss: 81.5239 - val_loss: 51.1033\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00112: loss improved from 85.78002 to 81.52389, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [81.52388594831739, 29.255266189575195]\n",
      "Epoch 113/1047\n",
      " - 23s - loss: 92.2767 - val_loss: 260.8064\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 29.25527\n",
      "Epoch 114/1047\n",
      " - 23s - loss: 80.8631 - val_loss: 195.4258\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00114: loss improved from 81.52389 to 80.86307, saving model to ./saved_models/model_0_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best loss value: [80.8630703006472, 29.255266189575195]\n",
      "Epoch 115/1047\n",
      " - 21s - loss: 78.7517 - val_loss: 116.2438\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 29.25527\n",
      "Saving best loss value: [78.75166829994747, 29.255266189575195]\n",
      "Epoch 116/1047\n",
      " - 27s - loss: 77.0743 - val_loss: 299.0839\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 29.25527\n",
      "\n",
      "Epoch 00116: loss improved from 80.86307 to 77.07427, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [77.07427070822034, 29.255266189575195]\n",
      "Epoch 117/1047\n",
      " - 23s - loss: 87.4197 - val_loss: 70.6755\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 29.25527\n",
      "Epoch 118/1047\n",
      " - 24s - loss: 89.5426 - val_loss: 28.8730\n",
      "\n",
      "Epoch 00118: val_loss improved from 29.25527 to 28.87304, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00118: loss did not improve from 77.07427\n",
      "Saving best loss value: [77.07427070822034, 28.873044967651367]\n",
      "Epoch 119/1047\n",
      " - 19s - loss: 70.6103 - val_loss: 157.5086\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 28.87304\n",
      "Saving best loss value: [70.61033469438553, 28.873044967651367]\n",
      "Epoch 120/1047\n",
      " - 22s - loss: 87.7521 - val_loss: 42.8749\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 28.87304\n",
      "\n",
      "Epoch 00120: loss did not improve from 77.07427\n",
      "Epoch 121/1047\n",
      " - 19s - loss: 90.1558 - val_loss: 33.5419\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 28.87304\n",
      "Epoch 122/1047\n",
      " - 21s - loss: 97.1445 - val_loss: 116.8798\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 28.87304\n",
      "\n",
      "Epoch 00122: loss did not improve from 77.07427\n",
      "Epoch 123/1047\n",
      " - 23s - loss: 81.6512 - val_loss: 194.0775\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 28.87304\n",
      "Epoch 124/1047\n",
      " - 21s - loss: 88.6076 - val_loss: 22.9641\n",
      "\n",
      "Epoch 00124: val_loss improved from 28.87304 to 22.96411, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "\n",
      "Epoch 00124: loss did not improve from 77.07427\n",
      "Saving best loss value: [70.61033469438553, 22.964113235473633]\n",
      "Epoch 125/1047\n",
      " - 24s - loss: 83.9846 - val_loss: 160.9836\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 22.96411\n",
      "Epoch 126/1047\n",
      " - 23s - loss: 90.9236 - val_loss: 75.2899\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 22.96411\n",
      "\n",
      "Epoch 00126: loss did not improve from 77.07427\n",
      "Epoch 127/1047\n",
      " - 20s - loss: 87.0656 - val_loss: 152.3072\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 22.96411\n",
      "Epoch 128/1047\n",
      " - 20s - loss: 93.4325 - val_loss: 97.6631\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 22.96411\n",
      "\n",
      "Epoch 00128: loss did not improve from 77.07427\n",
      "Epoch 129/1047\n",
      " - 19s - loss: 88.8337 - val_loss: 50.0208\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 22.96411\n",
      "Epoch 130/1047\n",
      " - 22s - loss: 91.1611 - val_loss: 50.5513\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 22.96411\n",
      "\n",
      "Epoch 00130: loss did not improve from 77.07427\n",
      "Epoch 131/1047\n",
      " - 23s - loss: 82.1483 - val_loss: 66.3320\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 22.96411\n",
      "Epoch 132/1047\n",
      " - 25s - loss: 74.2636 - val_loss: 28.9994\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 22.96411\n",
      "\n",
      "Epoch 00132: loss improved from 77.07427 to 74.26362, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 133/1047\n",
      " - 23s - loss: 87.7886 - val_loss: 21.5391\n",
      "\n",
      "Epoch 00133: val_loss improved from 22.96411 to 21.53913, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [70.61033469438553, 21.53912925720215]\n",
      "Epoch 134/1047\n",
      " - 21s - loss: 74.5501 - val_loss: 46.2164\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 21.53913\n",
      "\n",
      "Epoch 00134: loss did not improve from 74.26362\n",
      "Epoch 00134: early stopping\n",
      "\n",
      "Time 3159.616569519043\n",
      "Super-epoch 2 - learn rate: 0.01 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 80.0937 - val_loss: 70.6847\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 21.53913\n",
      "Epoch 2/1047\n",
      " - 20s - loss: 80.0538 - val_loss: 174.0576\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 21.53913\n",
      "\n",
      "Epoch 00002: loss did not improve from 74.26362\n",
      "Epoch 3/1047\n",
      " - 21s - loss: 82.0910 - val_loss: 18.2688\n",
      "\n",
      "Epoch 00003: val_loss improved from 21.53913 to 18.26878, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [70.61033469438553, 18.26877784729004]\n",
      "Epoch 4/1047\n",
      " - 21s - loss: 77.6907 - val_loss: 23.4137\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00004: loss did not improve from 74.26362\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 88.5531 - val_loss: 65.4268\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 18.26878\n",
      "Epoch 6/1047\n",
      " - 21s - loss: 85.6110 - val_loss: 238.0735\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00006: loss did not improve from 74.26362\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 84.8466 - val_loss: 50.5825\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 18.26878\n",
      "Epoch 8/1047\n",
      " - 20s - loss: 73.2035 - val_loss: 74.2653\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00008: loss improved from 74.26362 to 73.20346, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 79.0884 - val_loss: 132.3439\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 18.26878\n",
      "Epoch 10/1047\n",
      " - 19s - loss: 78.6284 - val_loss: 35.2283\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00010: loss did not improve from 73.20346\n",
      "Epoch 11/1047\n",
      " - 21s - loss: 76.5203 - val_loss: 102.9760\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 18.26878\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 83.4147 - val_loss: 178.7625\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00012: loss did not improve from 73.20346\n",
      "Epoch 13/1047\n",
      " - 18s - loss: 64.0283 - val_loss: 135.3442\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 18.26878\n",
      "Saving best loss value: [64.02825948170253, 18.26877784729004]\n",
      "Epoch 14/1047\n",
      " - 20s - loss: 74.5317 - val_loss: 94.9574\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00014: loss did not improve from 73.20346\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 86.8609 - val_loss: 86.1740\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 18.26878\n",
      "Epoch 16/1047\n",
      " - 20s - loss: 91.0250 - val_loss: 28.8760\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00016: loss did not improve from 73.20346\n",
      "Epoch 17/1047\n",
      " - 18s - loss: 77.1644 - val_loss: 311.2498\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 18.26878\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 75.2972 - val_loss: 22.9719\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00018: loss did not improve from 73.20346\n",
      "Epoch 19/1047\n",
      " - 18s - loss: 90.1851 - val_loss: 20.5248\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 18.26878\n",
      "Epoch 20/1047\n",
      " - 19s - loss: 81.3388 - val_loss: 85.2202\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00020: loss did not improve from 73.20346\n",
      "Epoch 21/1047\n",
      " - 18s - loss: 83.0024 - val_loss: 21.0320\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 18.26878\n",
      "Epoch 22/1047\n",
      " - 18s - loss: 76.9595 - val_loss: 97.6191\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00022: loss did not improve from 73.20346\n",
      "Epoch 23/1047\n",
      " - 18s - loss: 78.6977 - val_loss: 203.8450\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 18.26878\n",
      "Epoch 24/1047\n",
      " - 18s - loss: 78.1256 - val_loss: 70.9124\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00024: loss did not improve from 73.20346\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 73.8401 - val_loss: 94.3428\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 18.26878\n",
      "Epoch 26/1047\n",
      " - 20s - loss: 68.8662 - val_loss: 225.0124\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00026: loss improved from 73.20346 to 68.86624, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 27/1047\n",
      " - 18s - loss: 72.2381 - val_loss: 33.5071\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 18.26878\n",
      "Epoch 28/1047\n",
      " - 19s - loss: 75.0731 - val_loss: 326.0172\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00028: loss did not improve from 68.86624\n",
      "Epoch 00028: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 3716.3004133701324\n",
      "Super-epoch 3 - learn rate: 0.006299605249474366 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 23s - loss: 81.5653 - val_loss: 100.1342\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 18.26878\n",
      "Epoch 2/1047\n",
      " - 18s - loss: 79.2179 - val_loss: 48.8860\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00002: loss did not improve from 68.86624\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 87.2337 - val_loss: 77.3421\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 18.26878\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 87.8924 - val_loss: 81.2787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00004: loss did not improve from 68.86624\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 83.1040 - val_loss: 37.0690\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 18.26878\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 74.8739 - val_loss: 28.6870\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00006: loss did not improve from 68.86624\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 77.3035 - val_loss: 49.7293\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 18.26878\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 75.6107 - val_loss: 44.0311\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00008: loss did not improve from 68.86624\n",
      "Epoch 9/1047\n",
      " - 19s - loss: 68.1599 - val_loss: 195.0895\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 18.26878\n",
      "Epoch 10/1047\n",
      " - 20s - loss: 81.0310 - val_loss: 193.9503\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00010: loss did not improve from 68.86624\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 63.1547 - val_loss: 171.2231\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 18.26878\n",
      "Saving best loss value: [63.1547326701028, 18.26877784729004]\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 81.8836 - val_loss: 75.6008\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00012: loss did not improve from 68.86624\n",
      "Epoch 13/1047\n",
      " - 20s - loss: 78.9230 - val_loss: 240.0763\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 18.26878\n",
      "Epoch 14/1047\n",
      " - 21s - loss: 70.5887 - val_loss: 21.0561\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00014: loss did not improve from 68.86624\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 76.6357 - val_loss: 68.0227\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 18.26878\n",
      "Epoch 16/1047\n",
      " - 21s - loss: 82.0918 - val_loss: 198.7328\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 18.26878\n",
      "\n",
      "Epoch 00016: loss did not improve from 68.86624\n",
      "Epoch 17/1047\n",
      " - 24s - loss: 71.0795 - val_loss: 4.4925\n",
      "\n",
      "Epoch 00017: val_loss improved from 18.26878 to 4.49246, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [63.1547326701028, 4.492456436157227]\n",
      "Epoch 18/1047\n",
      " - 19s - loss: 79.6741 - val_loss: 76.7889\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00018: loss did not improve from 68.86624\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 70.1939 - val_loss: 36.2173\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.49246\n",
      "Epoch 20/1047\n",
      " - 20s - loss: 72.5025 - val_loss: 21.8103\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00020: loss did not improve from 68.86624\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 89.4872 - val_loss: 60.7546\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.49246\n",
      "Epoch 22/1047\n",
      " - 21s - loss: 77.9574 - val_loss: 74.9837\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00022: loss did not improve from 68.86624\n",
      "Epoch 23/1047\n",
      " - 22s - loss: 79.0759 - val_loss: 211.1851\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.49246\n",
      "Epoch 24/1047\n",
      " - 22s - loss: 80.4575 - val_loss: 20.7426\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00024: loss did not improve from 68.86624\n",
      "Epoch 25/1047\n",
      " - 20s - loss: 80.5001 - val_loss: 85.2434\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.49246\n",
      "Epoch 26/1047\n",
      " - 21s - loss: 74.6910 - val_loss: 19.0030\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00026: loss did not improve from 68.86624\n",
      "Epoch 00026: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 4245.2045748233795\n",
      "Super-epoch 4 - learn rate: 0.003968502629920499 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 23s - loss: 75.7281 - val_loss: 103.1983\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 4.49246\n",
      "Epoch 2/1047\n",
      " - 23s - loss: 85.2662 - val_loss: 28.7423\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00002: loss did not improve from 68.86624\n",
      "Epoch 3/1047\n",
      " - 20s - loss: 68.0493 - val_loss: 18.4088\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.49246\n",
      "Epoch 4/1047\n",
      " - 19s - loss: 76.2021 - val_loss: 46.1757\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00004: loss did not improve from 68.86624\n",
      "Epoch 5/1047\n",
      " - 22s - loss: 82.9869 - val_loss: 50.6337\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.49246\n",
      "Epoch 6/1047\n",
      " - 19s - loss: 82.2752 - val_loss: 92.4926\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00006: loss did not improve from 68.86624\n",
      "Epoch 7/1047\n",
      " - 21s - loss: 79.7779 - val_loss: 18.2778\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.49246\n",
      "Epoch 8/1047\n",
      " - 20s - loss: 85.6353 - val_loss: 265.8272\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00008: loss did not improve from 68.86624\n",
      "Epoch 9/1047\n",
      " - 22s - loss: 67.4984 - val_loss: 47.8478\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.49246\n",
      "Epoch 10/1047\n",
      " - 20s - loss: 87.4829 - val_loss: 59.8062\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00010: loss did not improve from 68.86624\n",
      "Epoch 11/1047\n",
      " - 21s - loss: 76.6206 - val_loss: 25.7368\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.49246\n",
      "Epoch 12/1047\n",
      " - 24s - loss: 76.5161 - val_loss: 54.6271\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00012: loss did not improve from 68.86624\n",
      "Epoch 13/1047\n",
      " - 22s - loss: 72.7822 - val_loss: 57.8674\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.49246\n",
      "Epoch 14/1047\n",
      " - 21s - loss: 74.1905 - val_loss: 102.3895\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00014: loss did not improve from 68.86624\n",
      "Epoch 15/1047\n",
      " - 21s - loss: 82.5736 - val_loss: 37.2705\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.49246\n",
      "Epoch 16/1047\n",
      " - 20s - loss: 82.4589 - val_loss: 44.2967\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00016: loss did not improve from 68.86624\n",
      "Epoch 17/1047\n",
      " - 20s - loss: 72.4609 - val_loss: 113.9388\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.49246\n",
      "Epoch 18/1047\n",
      " - 22s - loss: 92.7375 - val_loss: 169.0712\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00018: loss did not improve from 68.86624\n",
      "Epoch 19/1047\n",
      " - 24s - loss: 78.8368 - val_loss: 137.0579\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.49246\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 80.9972 - val_loss: 74.6560\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00020: loss did not improve from 68.86624\n",
      "Epoch 21/1047\n",
      " - 22s - loss: 82.9941 - val_loss: 34.8211\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.49246\n",
      "Epoch 22/1047\n",
      " - 22s - loss: 67.1188 - val_loss: 214.6808\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00022: loss improved from 68.86624 to 67.11884, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 70.3971 - val_loss: 43.1811\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.49246\n",
      "Epoch 24/1047\n",
      " - 20s - loss: 88.8682 - val_loss: 107.6080\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00024: loss did not improve from 67.11884\n",
      "Epoch 25/1047\n",
      " - 18s - loss: 69.7867 - val_loss: 42.1829\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.49246\n",
      "Epoch 26/1047\n",
      " - 23s - loss: 74.9278 - val_loss: 19.7761\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00026: loss did not improve from 67.11884\n",
      "Epoch 27/1047\n",
      " - 19s - loss: 75.5596 - val_loss: 141.9239\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.49246\n",
      "Epoch 28/1047\n",
      " - 20s - loss: 71.1235 - val_loss: 109.9263\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00028: loss did not improve from 67.11884\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 79.3240 - val_loss: 42.8319\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.49246\n",
      "Epoch 30/1047\n",
      " - 18s - loss: 79.6947 - val_loss: 126.2026\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00030: loss did not improve from 67.11884\n",
      "Epoch 31/1047\n",
      " - 20s - loss: 71.4329 - val_loss: 28.6664\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.49246\n",
      "Epoch 32/1047\n",
      " - 20s - loss: 77.5923 - val_loss: 30.0218\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00032: loss did not improve from 67.11884\n",
      "Epoch 33/1047\n",
      " - 18s - loss: 71.8125 - val_loss: 26.7538\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 4.49246\n",
      "Epoch 34/1047\n",
      " - 20s - loss: 65.7644 - val_loss: 25.5704\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00034: loss improved from 67.11884 to 65.76438, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 35/1047\n",
      " - 18s - loss: 79.9006 - val_loss: 37.7260\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 4.49246\n",
      "Epoch 36/1047\n",
      " - 19s - loss: 73.7189 - val_loss: 223.1485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00036: loss did not improve from 65.76438\n",
      "Epoch 37/1047\n",
      " - 19s - loss: 80.1199 - val_loss: 166.0494\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 4.49246\n",
      "Epoch 38/1047\n",
      " - 19s - loss: 90.7971 - val_loss: 50.9720\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00038: loss did not improve from 65.76438\n",
      "Epoch 39/1047\n",
      " - 19s - loss: 77.6000 - val_loss: 142.1120\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 4.49246\n",
      "Epoch 40/1047\n",
      " - 22s - loss: 80.0530 - val_loss: 45.5230\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00040: loss did not improve from 65.76438\n",
      "Epoch 41/1047\n",
      " - 19s - loss: 72.3976 - val_loss: 29.6883\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4.49246\n",
      "Epoch 42/1047\n",
      " - 19s - loss: 64.0885 - val_loss: 25.4965\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00042: loss improved from 65.76438 to 64.08845, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Epoch 43/1047\n",
      " - 18s - loss: 69.9210 - val_loss: 142.3494\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4.49246\n",
      "Epoch 44/1047\n",
      " - 21s - loss: 67.6489 - val_loss: 105.3691\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00044: loss did not improve from 64.08845\n",
      "Epoch 45/1047\n",
      " - 19s - loss: 70.8451 - val_loss: 31.4289\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4.49246\n",
      "Epoch 46/1047\n",
      " - 21s - loss: 79.5808 - val_loss: 16.4641\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00046: loss did not improve from 64.08845\n",
      "Epoch 47/1047\n",
      " - 18s - loss: 71.4261 - val_loss: 181.6998\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4.49246\n",
      "Epoch 48/1047\n",
      " - 20s - loss: 80.7404 - val_loss: 24.3617\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00048: loss did not improve from 64.08845\n",
      "Epoch 49/1047\n",
      " - 25s - loss: 78.2703 - val_loss: 255.2863\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4.49246\n",
      "Epoch 50/1047\n",
      " - 21s - loss: 78.0556 - val_loss: 27.3994\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00050: loss did not improve from 64.08845\n",
      "Epoch 51/1047\n",
      " - 22s - loss: 91.3562 - val_loss: 44.1188\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 4.49246\n",
      "Epoch 52/1047\n",
      " - 22s - loss: 74.2160 - val_loss: 47.3548\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00052: loss did not improve from 64.08845\n",
      "Epoch 53/1047\n",
      " - 19s - loss: 67.5518 - val_loss: 19.4526\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 4.49246\n",
      "Epoch 54/1047\n",
      " - 21s - loss: 96.1154 - val_loss: 23.6397\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00054: loss did not improve from 64.08845\n",
      "Epoch 55/1047\n",
      " - 20s - loss: 78.6050 - val_loss: 163.1443\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4.49246\n",
      "Epoch 56/1047\n",
      " - 19s - loss: 68.7309 - val_loss: 183.6095\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00056: loss did not improve from 64.08845\n",
      "Epoch 57/1047\n",
      " - 26s - loss: 76.9268 - val_loss: 155.9987\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4.49246\n",
      "Epoch 00057: early stopping\n",
      "\n",
      "Time 5423.946150302887\n",
      "Super-epoch 5 - learn rate: 0.003968502629920499 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 92.0731 - val_loss: 70.5957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00001: loss did not improve from 64.08845\n",
      "Epoch 2/1047\n",
      " - 20s - loss: 81.2756 - val_loss: 99.3677\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.49246\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 73.1266 - val_loss: 71.6202\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00003: loss did not improve from 64.08845\n",
      "Epoch 4/1047\n",
      " - 20s - loss: 70.8829 - val_loss: 58.2018\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.49246\n",
      "Epoch 5/1047\n",
      " - 21s - loss: 76.1555 - val_loss: 26.4380\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00005: loss did not improve from 64.08845\n",
      "Epoch 6/1047\n",
      " - 23s - loss: 63.1904 - val_loss: 210.6908\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.49246\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 65.5353 - val_loss: 45.3046\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00007: loss did not improve from 64.08845\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 73.4147 - val_loss: 24.9591\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.49246\n",
      "Epoch 9/1047\n",
      " - 19s - loss: 80.5295 - val_loss: 214.7768\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00009: loss did not improve from 64.08845\n",
      "Epoch 10/1047\n",
      " - 23s - loss: 79.4432 - val_loss: 56.2697\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.49246\n",
      "Epoch 11/1047\n",
      " - 20s - loss: 80.8538 - val_loss: 135.4590\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00011: loss did not improve from 64.08845\n",
      "Epoch 12/1047\n",
      " - 26s - loss: 76.4165 - val_loss: 14.8476\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.49246\n",
      "Epoch 13/1047\n",
      " - 22s - loss: 68.4429 - val_loss: 37.0340\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00013: loss did not improve from 64.08845\n",
      "Epoch 14/1047\n",
      " - 20s - loss: 74.8578 - val_loss: 124.7885\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.49246\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 62.5269 - val_loss: 220.3375\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00015: loss improved from 64.08845 to 62.52690, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [62.52690362930298, 4.492456436157227]\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 81.5865 - val_loss: 49.6602\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.49246\n",
      "Epoch 17/1047\n",
      " - 24s - loss: 69.3034 - val_loss: 16.1474\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00017: loss did not improve from 62.52690\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 68.4939 - val_loss: 31.9883\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.49246\n",
      "Epoch 19/1047\n",
      " - 22s - loss: 75.1985 - val_loss: 27.7460\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00019: loss did not improve from 62.52690\n",
      "Epoch 20/1047\n",
      " - 27s - loss: 78.1208 - val_loss: 47.3327\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.49246\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 80.1314 - val_loss: 60.6211\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00021: loss did not improve from 62.52690\n",
      "Epoch 22/1047\n",
      " - 21s - loss: 83.4351 - val_loss: 510.8387\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.49246\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 76.4713 - val_loss: 22.2062\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00023: loss did not improve from 62.52690\n",
      "Epoch 24/1047\n",
      " - 20s - loss: 74.8111 - val_loss: 99.8671\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.49246\n",
      "Epoch 25/1047\n",
      " - 22s - loss: 81.7239 - val_loss: 152.1508\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00025: loss did not improve from 62.52690\n",
      "Epoch 26/1047\n",
      " - 23s - loss: 75.3900 - val_loss: 44.7871\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.49246\n",
      "Epoch 27/1047\n",
      " - 20s - loss: 69.9644 - val_loss: 52.0268\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00027: loss did not improve from 62.52690\n",
      "Epoch 28/1047\n",
      " - 25s - loss: 73.4447 - val_loss: 305.0045\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.49246\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 72.8389 - val_loss: 170.1375\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00029: loss did not improve from 62.52690\n",
      "Epoch 30/1047\n",
      " - 19s - loss: 72.6657 - val_loss: 28.2030\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.49246\n",
      "Epoch 00030: early stopping\n",
      "\n",
      "Time 6063.299791097641\n",
      "Super-epoch 6 - learn rate: 0.003968502629920499 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 25s - loss: 76.3998 - val_loss: 107.8280\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00001: loss did not improve from 62.52690\n",
      "Epoch 2/1047\n",
      " - 21s - loss: 76.8121 - val_loss: 36.9611\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.49246\n",
      "Epoch 3/1047\n",
      " - 22s - loss: 65.2361 - val_loss: 53.1967\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00003: loss did not improve from 62.52690\n",
      "Epoch 4/1047\n",
      " - 20s - loss: 77.9026 - val_loss: 242.4541\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.49246\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 67.1468 - val_loss: 91.6198\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00005: loss did not improve from 62.52690\n",
      "Epoch 6/1047\n",
      " - 22s - loss: 76.5011 - val_loss: 294.3605\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.49246\n",
      "Epoch 7/1047\n",
      " - 22s - loss: 74.0009 - val_loss: 114.1161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00007: loss did not improve from 62.52690\n",
      "Epoch 8/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 75.1962 - val_loss: 82.8467\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.49246\n",
      "Epoch 9/1047\n",
      " - 21s - loss: 71.1390 - val_loss: 69.1684\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00009: loss did not improve from 62.52690\n",
      "Epoch 10/1047\n",
      " - 18s - loss: 77.4792 - val_loss: 30.3802\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.49246\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 74.4698 - val_loss: 63.1706\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00011: loss did not improve from 62.52690\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 80.4048 - val_loss: 73.5592\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.49246\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 58.2202 - val_loss: 51.4339\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00013: loss improved from 62.52690 to 58.22021, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [58.22020722287042, 4.492456436157227]\n",
      "Epoch 14/1047\n",
      " - 20s - loss: 66.5041 - val_loss: 41.7905\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.49246\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 76.2737 - val_loss: 104.7010\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 71.7467 - val_loss: 219.1238\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.49246\n",
      "Epoch 17/1047\n",
      " - 20s - loss: 67.6900 - val_loss: 70.9675\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 19s - loss: 73.7808 - val_loss: 74.1068\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.49246\n",
      "Epoch 19/1047\n",
      " - 19s - loss: 68.3446 - val_loss: 31.3011\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 19s - loss: 62.5131 - val_loss: 112.1985\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.49246\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 70.3007 - val_loss: 54.9542\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 22s - loss: 73.8965 - val_loss: 74.9229\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.49246\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 73.6498 - val_loss: 147.5097\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 70.2768 - val_loss: 44.1477\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.49246\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 71.9754 - val_loss: 87.1516\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 22s - loss: 74.4139 - val_loss: 36.0704\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.49246\n",
      "Epoch 27/1047\n",
      " - 21s - loss: 70.5995 - val_loss: 34.6185\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 19s - loss: 79.5665 - val_loss: 94.0440\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.49246\n",
      "Epoch 00028: early stopping\n",
      "Early stopping patience rate increased - 17.25\n",
      "Learn rate decayed\n",
      "\n",
      "Time 6632.972477912903\n",
      "Super-epoch 7 - learn rate: 0.0025000000000000005 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 63.4811 - val_loss: 37.5109\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 22s - loss: 76.4624 - val_loss: 81.6742\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.49246\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 77.6281 - val_loss: 226.1160\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 19s - loss: 92.5161 - val_loss: 153.9564\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.49246\n",
      "Epoch 5/1047\n",
      " - 21s - loss: 69.0738 - val_loss: 81.6224\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 20s - loss: 80.0643 - val_loss: 44.8327\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.49246\n",
      "Epoch 7/1047\n",
      " - 19s - loss: 72.7722 - val_loss: 28.9491\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 22s - loss: 76.3278 - val_loss: 127.9127\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.49246\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 74.7599 - val_loss: 304.7898\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 21s - loss: 72.5773 - val_loss: 109.3626\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.49246\n",
      "Epoch 11/1047\n",
      " - 19s - loss: 70.5297 - val_loss: 37.4105\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 66.8057 - val_loss: 17.2647\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.49246\n",
      "Epoch 13/1047\n",
      " - 21s - loss: 74.4572 - val_loss: 20.6067\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 20s - loss: 80.2598 - val_loss: 103.0840\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.49246\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 76.8966 - val_loss: 15.2746\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 73.3521 - val_loss: 27.3328\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.49246\n",
      "Epoch 17/1047\n",
      " - 19s - loss: 74.3328 - val_loss: 95.7541\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 23s - loss: 75.5260 - val_loss: 249.9374\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.49246\n",
      "Epoch 19/1047\n",
      " - 19s - loss: 70.0811 - val_loss: 38.0845\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 00019: early stopping\n",
      "\n",
      "Time 7023.0836889743805\n",
      "Super-epoch 8 - learn rate: 0.0025000000000000005 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 75.4543 - val_loss: 83.7332\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 4.49246\n",
      "Epoch 2/1047\n",
      " - 22s - loss: 79.4923 - val_loss: 16.0978\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00002: loss did not improve from 58.22021\n",
      "Epoch 3/1047\n",
      " - 20s - loss: 73.1397 - val_loss: 252.8423\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.49246\n",
      "Epoch 4/1047\n",
      " - 21s - loss: 71.3255 - val_loss: 42.7200\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00004: loss did not improve from 58.22021\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 77.7249 - val_loss: 64.9466\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.49246\n",
      "Epoch 6/1047\n",
      " - 22s - loss: 78.1471 - val_loss: 37.1740\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00006: loss did not improve from 58.22021\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 84.6252 - val_loss: 66.4104\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.49246\n",
      "Epoch 8/1047\n",
      " - 21s - loss: 74.7712 - val_loss: 45.3036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00008: loss did not improve from 58.22021\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 74.5525 - val_loss: 28.0621\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.49246\n",
      "Epoch 10/1047\n",
      " - 22s - loss: 66.4640 - val_loss: 67.0429\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00010: loss did not improve from 58.22021\n",
      "Epoch 11/1047\n",
      " - 22s - loss: 74.4053 - val_loss: 336.7903\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 4.49246\n",
      "Epoch 12/1047\n",
      " - 22s - loss: 73.5672 - val_loss: 28.4673\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 4.49246\n",
      "\n",
      "Epoch 00012: loss did not improve from 58.22021\n",
      "Epoch 13/1047\n",
      " - 21s - loss: 73.4894 - val_loss: 3.0358\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.49246 to 3.03583, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [58.22020722287042, 3.0358314514160156]\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 74.6848 - val_loss: 115.5226\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00014: loss did not improve from 58.22021\n",
      "Epoch 15/1047\n",
      " - 22s - loss: 72.1509 - val_loss: 53.3584\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.03583\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 92.5156 - val_loss: 5.1498\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00016: loss did not improve from 58.22021\n",
      "Epoch 17/1047\n",
      " - 23s - loss: 69.7950 - val_loss: 124.5759\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.03583\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 73.6656 - val_loss: 117.6651\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00018: loss did not improve from 58.22021\n",
      "Epoch 19/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 70.3145 - val_loss: 18.7508\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.03583\n",
      "Epoch 20/1047\n",
      " - 24s - loss: 76.0134 - val_loss: 17.1905\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00020: loss did not improve from 58.22021\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 60.7410 - val_loss: 175.9101\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03583\n",
      "Epoch 22/1047\n",
      " - 25s - loss: 69.2367 - val_loss: 17.2922\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00022: loss did not improve from 58.22021\n",
      "Epoch 23/1047\n",
      " - 21s - loss: 79.4660 - val_loss: 58.0289\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.03583\n",
      "Epoch 24/1047\n",
      " - 20s - loss: 67.4727 - val_loss: 46.5110\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00024: loss did not improve from 58.22021\n",
      "Epoch 25/1047\n",
      " - 20s - loss: 83.8695 - val_loss: 79.6844\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.03583\n",
      "Epoch 26/1047\n",
      " - 20s - loss: 78.3824 - val_loss: 5.0949\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00026: loss did not improve from 58.22021\n",
      "Epoch 27/1047\n",
      " - 21s - loss: 72.6347 - val_loss: 15.3810\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.03583\n",
      "Epoch 28/1047\n",
      " - 21s - loss: 70.1716 - val_loss: 35.3526\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00028: loss did not improve from 58.22021\n",
      "Epoch 29/1047\n",
      " - 23s - loss: 68.3691 - val_loss: 45.7412\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.03583\n",
      "Epoch 30/1047\n",
      " - 20s - loss: 68.5209 - val_loss: 33.8904\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00030: loss did not improve from 58.22021\n",
      "Epoch 31/1047\n",
      " - 20s - loss: 66.2019 - val_loss: 190.2380\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.03583\n",
      "Epoch 32/1047\n",
      " - 20s - loss: 85.8442 - val_loss: 31.7402\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00032: loss did not improve from 58.22021\n",
      "Epoch 33/1047\n",
      " - 18s - loss: 79.3017 - val_loss: 83.8155\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.03583\n",
      "Epoch 34/1047\n",
      " - 19s - loss: 77.4289 - val_loss: 40.2849\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00034: loss did not improve from 58.22021\n",
      "Epoch 35/1047\n",
      " - 21s - loss: 77.4918 - val_loss: 24.7113\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.03583\n",
      "Epoch 36/1047\n",
      " - 19s - loss: 74.2208 - val_loss: 47.9085\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00036: loss did not improve from 58.22021\n",
      "Epoch 37/1047\n",
      " - 18s - loss: 77.2616 - val_loss: 11.9354\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.03583\n",
      "Epoch 38/1047\n",
      " - 22s - loss: 66.2434 - val_loss: 28.1154\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00038: loss did not improve from 58.22021\n",
      "Epoch 39/1047\n",
      " - 21s - loss: 70.5510 - val_loss: 20.6916\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.03583\n",
      "Epoch 00039: early stopping\n",
      "Early stopping patience rate increased - 19.8375\n",
      "\n",
      "Time 7844.672343254089\n",
      "Super-epoch 9 - learn rate: 0.0025000000000000005 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 78.7316 - val_loss: 171.1769\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 21s - loss: 69.3136 - val_loss: 386.3660\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.03583\n",
      "Epoch 3/1047\n",
      " - 22s - loss: 76.8131 - val_loss: 42.3633\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 76.9106 - val_loss: 408.3298\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.03583\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 85.9848 - val_loss: 160.9940\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 20s - loss: 88.2201 - val_loss: 37.3376\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.03583\n",
      "Epoch 7/1047\n",
      " - 19s - loss: 70.8242 - val_loss: 53.3252\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 22s - loss: 77.0881 - val_loss: 175.0404\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.03583\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 74.9696 - val_loss: 30.0325\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 20s - loss: 71.4832 - val_loss: 40.9747\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.03583\n",
      "Epoch 11/1047\n",
      " - 19s - loss: 70.7951 - val_loss: 92.2136\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 68.8200 - val_loss: 43.3175\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.03583\n",
      "Epoch 13/1047\n",
      " - 20s - loss: 76.2414 - val_loss: 252.4895\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 21s - loss: 79.2876 - val_loss: 53.5052\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03583\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 75.6474 - val_loss: 68.8681\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 69.8014 - val_loss: 33.0905\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.03583\n",
      "Epoch 17/1047\n",
      " - 22s - loss: 69.4173 - val_loss: 103.8813\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 61.8672 - val_loss: 27.3967\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.03583\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 83.6030 - val_loss: 56.2319\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 65.2164 - val_loss: 30.5876\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.03583\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 76.9667 - val_loss: 12.8153\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 21s - loss: 71.3289 - val_loss: 29.0877\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.03583\n",
      "Epoch 23/1047\n",
      " - 21s - loss: 68.1312 - val_loss: 140.8545\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 22s - loss: 66.6301 - val_loss: 205.8150\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.03583\n",
      "Epoch 25/1047\n",
      " - 22s - loss: 67.7329 - val_loss: 74.5993\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 20s - loss: 72.7742 - val_loss: 163.9399\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.03583\n",
      "Epoch 27/1047\n",
      " - 20s - loss: 69.2646 - val_loss: 4.8234\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 20s - loss: 67.0012 - val_loss: 41.5210\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.03583\n",
      "Epoch 29/1047\n",
      " - 21s - loss: 88.7142 - val_loss: 33.0571\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 30/1047\n",
      " - 20s - loss: 73.3116 - val_loss: 18.8606\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.03583\n",
      "Epoch 31/1047\n",
      " - 24s - loss: 67.7529 - val_loss: 27.2591\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00031: loss did not improve from 58.22021\n",
      "Epoch 32/1047\n",
      " - 21s - loss: 75.5284 - val_loss: 42.5012\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.03583\n",
      "Epoch 33/1047\n",
      " - 21s - loss: 74.3212 - val_loss: 20.5517\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00033: loss did not improve from 58.22021\n",
      "Epoch 34/1047\n",
      " - 22s - loss: 79.4799 - val_loss: 15.4433\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.03583\n",
      "Epoch 35/1047\n",
      " - 19s - loss: 71.3074 - val_loss: 27.9578\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00035: loss did not improve from 58.22021\n",
      "Epoch 36/1047\n",
      " - 21s - loss: 71.6644 - val_loss: 18.6685\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.03583\n",
      "Epoch 37/1047\n",
      " - 20s - loss: 74.6052 - val_loss: 45.6458\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00037: loss did not improve from 58.22021\n",
      "Epoch 38/1047\n",
      " - 22s - loss: 71.7424 - val_loss: 33.8162\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.03583\n",
      "Epoch 00038: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 8631.80541586876\n",
      "Super-epoch 10 - learn rate: 0.0015749013123685918 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 23s - loss: 80.2306 - val_loss: 25.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 22s - loss: 79.1188 - val_loss: 227.4022\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.03583\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 68.9567 - val_loss: 17.2777\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 21s - loss: 86.7058 - val_loss: 25.8350\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.03583\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 72.0714 - val_loss: 17.8748\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 26s - loss: 79.0720 - val_loss: 140.0429\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.03583\n",
      "Epoch 7/1047\n",
      " - 25s - loss: 81.2651 - val_loss: 75.0169\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 23s - loss: 68.3823 - val_loss: 117.9573\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.03583\n",
      "Epoch 9/1047\n",
      " - 19s - loss: 80.9255 - val_loss: 8.3819\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 21s - loss: 63.2491 - val_loss: 92.5276\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.03583\n",
      "Epoch 11/1047\n",
      " - 25s - loss: 65.0707 - val_loss: 177.1073\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 71.7402 - val_loss: 75.7437\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.03583\n",
      "Epoch 13/1047\n",
      " - 27s - loss: 71.4615 - val_loss: 97.7471\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 21s - loss: 80.2102 - val_loss: 50.5405\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03583\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 76.9614 - val_loss: 93.4285\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 23s - loss: 71.1348 - val_loss: 33.7238\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.03583\n",
      "Epoch 17/1047\n",
      " - 21s - loss: 78.3940 - val_loss: 214.7009\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 22s - loss: 71.1521 - val_loss: 18.4211\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.03583\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 72.0411 - val_loss: 44.6055\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 72.4168 - val_loss: 84.4201\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.03583\n",
      "Epoch 21/1047\n",
      " - 21s - loss: 62.7019 - val_loss: 27.6808\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 20s - loss: 66.5105 - val_loss: 10.2085\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.03583\n",
      "Epoch 23/1047\n",
      " - 21s - loss: 68.5804 - val_loss: 236.5869\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 25s - loss: 77.9086 - val_loss: 2173.0442\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.03583\n",
      "Epoch 25/1047\n",
      " - 21s - loss: 67.3615 - val_loss: 112.5067\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 21s - loss: 62.3574 - val_loss: 34.0466\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.03583\n",
      "Epoch 27/1047\n",
      " - 21s - loss: 77.0723 - val_loss: 62.3102\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 22s - loss: 73.2010 - val_loss: 69.7676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.03583\n",
      "Epoch 29/1047\n",
      " - 20s - loss: 83.1616 - val_loss: 80.4761\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 30/1047\n",
      " - 23s - loss: 65.7329 - val_loss: 26.5183\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.03583\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 80.2538 - val_loss: 85.1626\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00031: loss did not improve from 58.22021\n",
      "Epoch 32/1047\n",
      " - 20s - loss: 65.1508 - val_loss: 123.3031\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.03583\n",
      "Epoch 33/1047\n",
      " - 21s - loss: 72.6847 - val_loss: 115.2093\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00033: loss did not improve from 58.22021\n",
      "Epoch 34/1047\n",
      " - 19s - loss: 74.5417 - val_loss: 50.0005\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.03583\n",
      "Epoch 35/1047\n",
      " - 18s - loss: 74.5685 - val_loss: 197.8629\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00035: loss did not improve from 58.22021\n",
      "Epoch 36/1047\n",
      " - 21s - loss: 73.4025 - val_loss: 130.4281\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.03583\n",
      "Epoch 37/1047\n",
      " - 18s - loss: 75.3339 - val_loss: 93.9256\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00037: loss did not improve from 58.22021\n",
      "Epoch 38/1047\n",
      " - 20s - loss: 69.7847 - val_loss: 191.5858\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.03583\n",
      "Epoch 39/1047\n",
      " - 21s - loss: 67.7452 - val_loss: 33.9922\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00039: loss did not improve from 58.22021\n",
      "Epoch 40/1047\n",
      " - 21s - loss: 78.4442 - val_loss: 16.0720\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.03583\n",
      "Epoch 41/1047\n",
      " - 18s - loss: 73.1423 - val_loss: 30.9267\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00041: loss did not improve from 58.22021\n",
      "Epoch 42/1047\n",
      " - 20s - loss: 77.4367 - val_loss: 315.7184\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.03583\n",
      "Epoch 43/1047\n",
      " - 19s - loss: 79.4722 - val_loss: 13.1060\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00043: loss did not improve from 58.22021\n",
      "Epoch 44/1047\n",
      " - 20s - loss: 69.2843 - val_loss: 38.7746\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.03583\n",
      "Epoch 45/1047\n",
      " - 19s - loss: 71.8936 - val_loss: 190.9253\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00045: loss did not improve from 58.22021\n",
      "Epoch 46/1047\n",
      " - 20s - loss: 82.4450 - val_loss: 73.8949\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.03583\n",
      "Epoch 00046: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 9606.647541046143\n",
      "Super-epoch 11 - learn rate: 0.000992125657480125 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 22s - loss: 79.8627 - val_loss: 150.6767\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 18s - loss: 72.0481 - val_loss: 23.6108\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 3.03583\n",
      "Epoch 3/1047\n",
      " - 20s - loss: 73.4024 - val_loss: 112.7099\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 21s - loss: 77.2744 - val_loss: 124.7329\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.03583\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 68.4133 - val_loss: 18.0043\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 19s - loss: 68.1638 - val_loss: 16.1044\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.03583\n",
      "Epoch 7/1047\n",
      " - 22s - loss: 74.7382 - val_loss: 139.3594\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 80.4404 - val_loss: 181.4559\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.03583\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 74.7358 - val_loss: 49.7523\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 19s - loss: 67.6566 - val_loss: 32.7354\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.03583\n",
      "Epoch 11/1047\n",
      " - 19s - loss: 73.5078 - val_loss: 76.9514\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 79.0392 - val_loss: 111.8902\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.03583\n",
      "Epoch 13/1047\n",
      " - 23s - loss: 73.2770 - val_loss: 33.4881\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 22s - loss: 81.3576 - val_loss: 29.4731\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.03583\n",
      "Epoch 15/1047\n",
      " - 21s - loss: 69.2361 - val_loss: 48.4247\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 21s - loss: 77.9968 - val_loss: 71.5765\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.03583\n",
      "Epoch 17/1047\n",
      " - 19s - loss: 67.6013 - val_loss: 74.8716\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 72.2307 - val_loss: 86.3490\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.03583\n",
      "Epoch 19/1047\n",
      " - 24s - loss: 68.8679 - val_loss: 81.9857\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 69.7087 - val_loss: 57.4352\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.03583\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 66.1406 - val_loss: 46.2175\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 19s - loss: 75.3014 - val_loss: 84.3633\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.03583\n",
      "Epoch 23/1047\n",
      " - 21s - loss: 65.8948 - val_loss: 46.9509\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 24s - loss: 82.1408 - val_loss: 122.6290\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.03583\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 82.5348 - val_loss: 130.4856\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 23s - loss: 65.5766 - val_loss: 59.6488\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.03583\n",
      "Epoch 27/1047\n",
      " - 20s - loss: 68.1000 - val_loss: 63.6116\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.03583\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 20s - loss: 69.2813 - val_loss: 2.6687\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.03583 to 2.66865, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [58.22020722287042, 2.668651819229126]\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 68.8573 - val_loss: 61.6600\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 30/1047\n",
      " - 27s - loss: 67.4176 - val_loss: 142.9659\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "Epoch 31/1047\n",
      " - 20s - loss: 68.9427 - val_loss: 41.9600\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00031: loss did not improve from 58.22021\n",
      "Epoch 32/1047\n",
      " - 22s - loss: 72.9312 - val_loss: 4.0858\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "Epoch 33/1047\n",
      " - 22s - loss: 71.8601 - val_loss: 123.0324\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00033: loss did not improve from 58.22021\n",
      "Epoch 34/1047\n",
      " - 20s - loss: 78.9906 - val_loss: 54.8982\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "Epoch 35/1047\n",
      " - 20s - loss: 76.2894 - val_loss: 24.8737\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00035: loss did not improve from 58.22021\n",
      "Epoch 36/1047\n",
      " - 21s - loss: 78.0548 - val_loss: 249.3666\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "Epoch 37/1047\n",
      " - 19s - loss: 67.8435 - val_loss: 59.3157\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00037: loss did not improve from 58.22021\n",
      "Epoch 38/1047\n",
      " - 22s - loss: 74.7060 - val_loss: 21.9604\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "Epoch 39/1047\n",
      " - 20s - loss: 70.6005 - val_loss: 17.9869\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00039: loss did not improve from 58.22021\n",
      "Epoch 40/1047\n",
      " - 19s - loss: 73.1725 - val_loss: 107.3898\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.66865\n",
      "Epoch 41/1047\n",
      " - 20s - loss: 73.4217 - val_loss: 13.0688\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00041: loss did not improve from 58.22021\n",
      "Epoch 42/1047\n",
      " - 21s - loss: 66.4261 - val_loss: 165.0090\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.66865\n",
      "Epoch 43/1047\n",
      " - 19s - loss: 68.3652 - val_loss: 131.9660\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00043: loss did not improve from 58.22021\n",
      "Epoch 44/1047\n",
      " - 19s - loss: 75.2742 - val_loss: 45.4805\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.66865\n",
      "Epoch 45/1047\n",
      " - 19s - loss: 75.7481 - val_loss: 95.2748\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00045: loss did not improve from 58.22021\n",
      "Epoch 46/1047\n",
      " - 23s - loss: 66.3372 - val_loss: 116.3211\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.66865\n",
      "Epoch 00046: early stopping\n",
      "\n",
      "Time 10558.965785503387\n",
      "Super-epoch 12 - learn rate: 0.000992125657480125 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 27s - loss: 71.0999 - val_loss: 44.6483\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 20s - loss: 71.1633 - val_loss: 23.2170\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "Epoch 3/1047\n",
      " - 22s - loss: 75.6693 - val_loss: 102.0081\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 24s - loss: 72.5187 - val_loss: 119.8327\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 69.4620 - val_loss: 140.8846\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 70.7057 - val_loss: 35.5533\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "Epoch 7/1047\n",
      " - 21s - loss: 73.1848 - val_loss: 155.6029\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 68.9673 - val_loss: 168.9751\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 68.6533 - val_loss: 120.4060\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 19s - loss: 72.2688 - val_loss: 43.7896\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 78.3771 - val_loss: 157.1622\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 74.3381 - val_loss: 85.5515\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "Epoch 13/1047\n",
      " - 18s - loss: 70.6164 - val_loss: 308.0716\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 76.3092 - val_loss: 43.7655\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "Epoch 15/1047\n",
      " - 18s - loss: 75.4352 - val_loss: 95.9266\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 77.6583 - val_loss: 283.7191\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "Epoch 17/1047\n",
      " - 19s - loss: 76.1501 - val_loss: 214.7311\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 18s - loss: 75.5264 - val_loss: 66.2329\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "Epoch 19/1047\n",
      " - 19s - loss: 71.9685 - val_loss: 24.3522\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 18s - loss: 74.0648 - val_loss: 70.4166\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "Epoch 21/1047\n",
      " - 18s - loss: 67.5791 - val_loss: 182.6938\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 18s - loss: 84.4216 - val_loss: 19.2237\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "Epoch 23/1047\n",
      " - 18s - loss: 72.4847 - val_loss: 14.4641\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 71.5978 - val_loss: 83.6751\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 65.6521 - val_loss: 29.8504\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 19s - loss: 73.1825 - val_loss: 260.1276\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "Epoch 27/1047\n",
      " - 18s - loss: 72.7691 - val_loss: 45.0017\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 18s - loss: 78.3260 - val_loss: 15.3667\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 65.9702 - val_loss: 97.3781\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 30/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 18s - loss: 74.6371 - val_loss: 19.9461\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 68.7694 - val_loss: 28.4142\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00031: loss did not improve from 58.22021\n",
      "Epoch 32/1047\n",
      " - 18s - loss: 66.4203 - val_loss: 39.6662\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "Epoch 33/1047\n",
      " - 18s - loss: 68.2857 - val_loss: 300.4698\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00033: loss did not improve from 58.22021\n",
      "Epoch 34/1047\n",
      " - 18s - loss: 78.9164 - val_loss: 70.8322\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "Epoch 35/1047\n",
      " - 18s - loss: 84.6206 - val_loss: 130.7243\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00035: loss did not improve from 58.22021\n",
      "Epoch 36/1047\n",
      " - 19s - loss: 73.9495 - val_loss: 123.7767\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "Epoch 37/1047\n",
      " - 18s - loss: 76.4776 - val_loss: 69.5661\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00037: loss did not improve from 58.22021\n",
      "Epoch 38/1047\n",
      " - 19s - loss: 70.1040 - val_loss: 108.9397\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "Epoch 39/1047\n",
      " - 18s - loss: 65.5267 - val_loss: 49.0820\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00039: loss did not improve from 58.22021\n",
      "Epoch 40/1047\n",
      " - 19s - loss: 65.7997 - val_loss: 42.0824\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.66865\n",
      "Epoch 41/1047\n",
      " - 21s - loss: 63.9767 - val_loss: 32.2706\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00041: loss did not improve from 58.22021\n",
      "Epoch 42/1047\n",
      " - 18s - loss: 75.7189 - val_loss: 14.9833\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.66865\n",
      "Epoch 43/1047\n",
      " - 19s - loss: 66.5874 - val_loss: 27.8774\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00043: loss did not improve from 58.22021\n",
      "Epoch 44/1047\n",
      " - 19s - loss: 75.9606 - val_loss: 56.2931\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.66865\n",
      "Epoch 45/1047\n",
      " - 19s - loss: 71.4239 - val_loss: 16.6911\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00045: loss did not improve from 58.22021\n",
      "Epoch 46/1047\n",
      " - 19s - loss: 77.4007 - val_loss: 146.9620\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.66865\n",
      "Epoch 47/1047\n",
      " - 18s - loss: 77.0950 - val_loss: 124.6017\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00047: loss did not improve from 58.22021\n",
      "Epoch 48/1047\n",
      " - 18s - loss: 72.0083 - val_loss: 77.7827\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.66865\n",
      "Epoch 49/1047\n",
      " - 18s - loss: 72.3227 - val_loss: 53.9960\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00049: loss did not improve from 58.22021\n",
      "Epoch 50/1047\n",
      " - 19s - loss: 75.7422 - val_loss: 39.3734\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.66865\n",
      "Epoch 51/1047\n",
      " - 19s - loss: 69.8047 - val_loss: 16.6254\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00051: loss did not improve from 58.22021\n",
      "Epoch 52/1047\n",
      " - 19s - loss: 63.1753 - val_loss: 15.5817\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.66865\n",
      "Epoch 53/1047\n",
      " - 19s - loss: 69.4279 - val_loss: 67.3651\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00053: loss did not improve from 58.22021\n",
      "Epoch 54/1047\n",
      " - 19s - loss: 85.0131 - val_loss: 145.0909\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.66865\n",
      "Epoch 55/1047\n",
      " - 18s - loss: 83.0389 - val_loss: 67.6580\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00055: loss did not improve from 58.22021\n",
      "Epoch 56/1047\n",
      " - 20s - loss: 69.7296 - val_loss: 29.1655\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.66865\n",
      "Epoch 57/1047\n",
      " - 18s - loss: 73.1998 - val_loss: 64.3592\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00057: loss did not improve from 58.22021\n",
      "Epoch 58/1047\n",
      " - 19s - loss: 76.6155 - val_loss: 55.2981\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.66865\n",
      "Epoch 59/1047\n",
      " - 20s - loss: 69.7573 - val_loss: 41.0997\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00059: loss did not improve from 58.22021\n",
      "Epoch 60/1047\n",
      " - 19s - loss: 81.2623 - val_loss: 33.9429\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.66865\n",
      "Epoch 61/1047\n",
      " - 22s - loss: 67.2350 - val_loss: 55.4133\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00061: loss did not improve from 58.22021\n",
      "Epoch 62/1047\n",
      " - 18s - loss: 72.0836 - val_loss: 86.7043\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.66865\n",
      "Epoch 63/1047\n",
      " - 19s - loss: 78.6096 - val_loss: 43.6524\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00063: loss did not improve from 58.22021\n",
      "Epoch 64/1047\n",
      " - 22s - loss: 75.9737 - val_loss: 47.8445\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.66865\n",
      "Epoch 65/1047\n",
      " - 18s - loss: 66.3112 - val_loss: 208.8467\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00065: loss did not improve from 58.22021\n",
      "Epoch 66/1047\n",
      " - 19s - loss: 75.7792 - val_loss: 91.6841\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.66865\n",
      "Epoch 67/1047\n",
      " - 19s - loss: 68.8064 - val_loss: 151.2508\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00067: loss did not improve from 58.22021\n",
      "Epoch 68/1047\n",
      " - 22s - loss: 75.0535 - val_loss: 116.3880\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.66865\n",
      "Epoch 69/1047\n",
      " - 20s - loss: 67.5327 - val_loss: 106.5300\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00069: loss did not improve from 58.22021\n",
      "Epoch 70/1047\n",
      " - 21s - loss: 80.0356 - val_loss: 152.2235\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.66865\n",
      "Epoch 71/1047\n",
      " - 19s - loss: 72.5567 - val_loss: 21.7553\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00071: loss did not improve from 58.22021\n",
      "Epoch 72/1047\n",
      " - 20s - loss: 77.6741 - val_loss: 135.6562\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.66865\n",
      "Epoch 00072: early stopping\n",
      "Early stopping patience rate increased - 22.813124999999996\n",
      "\n",
      "Time 11940.817790985107\n",
      "Super-epoch 13 - learn rate: 0.000992125657480125 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 22s - loss: 71.7742 - val_loss: 141.1122\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 23s - loss: 69.5001 - val_loss: 29.0772\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 71.8754 - val_loss: 40.3624\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 84.9601 - val_loss: 30.9143\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 79.0574 - val_loss: 37.2912\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 59.6577 - val_loss: 57.5070\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 67.9051 - val_loss: 36.4705\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 66.5811 - val_loss: 91.0641\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 64.0510 - val_loss: 54.2630\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 18s - loss: 64.4922 - val_loss: 58.3471\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 92.1911 - val_loss: 27.9147\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 18s - loss: 63.2437 - val_loss: 161.6391\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 68.4646 - val_loss: 54.9397\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 77.2958 - val_loss: 104.5524\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "Epoch 15/1047\n",
      " - 18s - loss: 76.2268 - val_loss: 46.8847\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 20s - loss: 83.6838 - val_loss: 75.4049\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "Epoch 17/1047\n",
      " - 19s - loss: 87.8317 - val_loss: 70.2215\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 19s - loss: 79.9719 - val_loss: 68.3087\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "Epoch 19/1047\n",
      " - 18s - loss: 81.2813 - val_loss: 42.6080\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 18s - loss: 74.8985 - val_loss: 91.7108\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "Epoch 21/1047\n",
      " - 19s - loss: 59.8429 - val_loss: 35.4733\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 19s - loss: 64.3541 - val_loss: 259.6308\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 77.4255 - val_loss: 166.7739\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 70.0239 - val_loss: 38.4058\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "Epoch 25/1047\n",
      " - 18s - loss: 70.0749 - val_loss: 166.9904\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 18s - loss: 72.0998 - val_loss: 33.0747\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "Epoch 27/1047\n",
      " - 18s - loss: 79.5275 - val_loss: 38.0313\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 19s - loss: 73.5669 - val_loss: 94.2903\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "Epoch 29/1047\n",
      " - 18s - loss: 68.6505 - val_loss: 36.1268\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 00029: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 12495.552603244781\n",
      "Super-epoch 14 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 21s - loss: 61.6595 - val_loss: 328.1510\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "Epoch 2/1047\n",
      " - 18s - loss: 68.8152 - val_loss: 101.7281\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00002: loss did not improve from 58.22021\n",
      "Epoch 3/1047\n",
      " - 18s - loss: 74.6318 - val_loss: 91.9459\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 79.5958 - val_loss: 29.1968\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00004: loss did not improve from 58.22021\n",
      "Epoch 5/1047\n",
      " - 18s - loss: 70.4507 - val_loss: 108.8481\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 73.3572 - val_loss: 49.5597\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00006: loss did not improve from 58.22021\n",
      "Epoch 7/1047\n",
      " - 18s - loss: 71.8480 - val_loss: 87.8371\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 70.8270 - val_loss: 134.9091\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00008: loss did not improve from 58.22021\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 72.5839 - val_loss: 123.8589\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "Epoch 10/1047\n",
      " - 18s - loss: 72.9994 - val_loss: 259.3366\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00010: loss did not improve from 58.22021\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 81.2010 - val_loss: 55.9442\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 77.3412 - val_loss: 14.4435\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00012: loss did not improve from 58.22021\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 76.2010 - val_loss: 87.6985\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 72.8597 - val_loss: 40.5820\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00014: loss did not improve from 58.22021\n",
      "Epoch 15/1047\n",
      " - 21s - loss: 74.8692 - val_loss: 184.6819\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "Epoch 16/1047\n",
      " - 18s - loss: 67.3227 - val_loss: 106.2364\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00016: loss did not improve from 58.22021\n",
      "Epoch 17/1047\n",
      " - 20s - loss: 81.0696 - val_loss: 50.9978\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "Epoch 18/1047\n",
      " - 19s - loss: 67.2033 - val_loss: 48.8713\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00018: loss did not improve from 58.22021\n",
      "Epoch 19/1047\n",
      " - 21s - loss: 68.8390 - val_loss: 27.7110\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "Epoch 20/1047\n",
      " - 22s - loss: 77.2998 - val_loss: 43.7456\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00020: loss did not improve from 58.22021\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 71.1074 - val_loss: 124.3041\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "Epoch 22/1047\n",
      " - 18s - loss: 69.8073 - val_loss: 148.7526\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00022: loss did not improve from 58.22021\n",
      "Epoch 23/1047\n",
      " - 20s - loss: 72.6353 - val_loss: 34.8837\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "Epoch 24/1047\n",
      " - 18s - loss: 77.4034 - val_loss: 37.7047\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00024: loss did not improve from 58.22021\n",
      "Epoch 00024: early stopping\n",
      "Early stopping patience rate increased - 26.235093749999994\n",
      "\n",
      "Time 12962.306643009186\n",
      "Super-epoch 15 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 77.5746 - val_loss: 18.3197\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "Epoch 2/1047\n",
      " - 21s - loss: 74.7891 - val_loss: 17.5653\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00002: loss did not improve from 58.22021\n",
      "Epoch 3/1047\n",
      " - 20s - loss: 82.0523 - val_loss: 144.8254\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 69.0697 - val_loss: 119.8386\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00004: loss did not improve from 58.22021\n",
      "Epoch 5/1047\n",
      " - 20s - loss: 71.1268 - val_loss: 56.8868\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 75.0821 - val_loss: 130.0521\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00006: loss did not improve from 58.22021\n",
      "Epoch 7/1047\n",
      " - 19s - loss: 67.4452 - val_loss: 83.3060\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "Epoch 8/1047\n",
      " - 20s - loss: 75.9546 - val_loss: 19.2461\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00008: loss did not improve from 58.22021\n",
      "Epoch 9/1047\n",
      " - 21s - loss: 75.4354 - val_loss: 138.3031\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "Epoch 10/1047\n",
      " - 24s - loss: 68.3965 - val_loss: 21.9151\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00010: loss did not improve from 58.22021\n",
      "Epoch 11/1047\n",
      " - 21s - loss: 72.0159 - val_loss: 250.0306\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "Epoch 12/1047\n",
      " - 20s - loss: 66.4775 - val_loss: 110.5787\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00012: loss did not improve from 58.22021\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 77.6985 - val_loss: 31.7826\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "Epoch 14/1047\n",
      " - 20s - loss: 70.3470 - val_loss: 107.9913\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00014: loss did not improve from 58.22021\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 68.8351 - val_loss: 42.0277\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "Epoch 16/1047\n",
      " - 21s - loss: 69.3640 - val_loss: 61.6994\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00016: loss did not improve from 58.22021\n",
      "Epoch 17/1047\n",
      " - 24s - loss: 72.4189 - val_loss: 96.5506\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "Epoch 18/1047\n",
      " - 22s - loss: 74.2745 - val_loss: 315.9649\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00018: loss did not improve from 58.22021\n",
      "Epoch 19/1047\n",
      " - 23s - loss: 76.9123 - val_loss: 21.5375\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 77.9762 - val_loss: 36.3005\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00020: loss did not improve from 58.22021\n",
      "Epoch 21/1047\n",
      " - 19s - loss: 80.4631 - val_loss: 97.2840\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "Epoch 22/1047\n",
      " - 18s - loss: 78.0139 - val_loss: 179.9427\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00022: loss did not improve from 58.22021\n",
      "Epoch 23/1047\n",
      " - 20s - loss: 71.8446 - val_loss: 185.2877\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "Epoch 24/1047\n",
      " - 18s - loss: 70.8499 - val_loss: 49.3361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00024: loss did not improve from 58.22021\n",
      "Epoch 25/1047\n",
      " - 20s - loss: 73.1820 - val_loss: 28.7759\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "Epoch 26/1047\n",
      " - 21s - loss: 77.3028 - val_loss: 43.6110\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00026: loss did not improve from 58.22021\n",
      "Epoch 27/1047\n",
      " - 19s - loss: 83.0928 - val_loss: 91.2415\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "Epoch 28/1047\n",
      " - 19s - loss: 70.4363 - val_loss: 54.6586\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00028: loss did not improve from 58.22021\n",
      "Epoch 29/1047\n",
      " - 18s - loss: 67.1768 - val_loss: 32.2850\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "Epoch 30/1047\n",
      " - 18s - loss: 82.5152 - val_loss: 104.4368\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00030: loss did not improve from 58.22021\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 78.9971 - val_loss: 99.6036\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "Epoch 32/1047\n",
      " - 18s - loss: 68.1174 - val_loss: 90.6150\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00032: loss did not improve from 58.22021\n",
      "Epoch 33/1047\n",
      " - 19s - loss: 75.3063 - val_loss: 129.5792\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "Epoch 34/1047\n",
      " - 19s - loss: 72.8469 - val_loss: 35.0623\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00034: loss did not improve from 58.22021\n",
      "Epoch 35/1047\n",
      " - 19s - loss: 67.3983 - val_loss: 47.3649\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "Epoch 36/1047\n",
      " - 19s - loss: 76.8658 - val_loss: 75.6378\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00036: loss did not improve from 58.22021\n",
      "Epoch 37/1047\n",
      " - 18s - loss: 77.8608 - val_loss: 43.9361\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "Epoch 38/1047\n",
      " - 18s - loss: 70.0734 - val_loss: 186.9398\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00038: loss did not improve from 58.22021\n",
      "Epoch 39/1047\n",
      " - 19s - loss: 74.2271 - val_loss: 1584.3931\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "Epoch 00039: early stopping\n",
      "Early stopping patience rate increased - 30.17035781249999\n",
      "\n",
      "Time 13744.229831933975\n",
      "Super-epoch 16 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 22s - loss: 76.2501 - val_loss: 29.4928\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00001: loss did not improve from 58.22021\n",
      "Epoch 2/1047\n",
      " - 19s - loss: 79.6512 - val_loss: 16.2454\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "Epoch 3/1047\n",
      " - 18s - loss: 76.0730 - val_loss: 100.2430\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00003: loss did not improve from 58.22021\n",
      "Epoch 4/1047\n",
      " - 19s - loss: 79.9789 - val_loss: 20.7085\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 69.6592 - val_loss: 35.3449\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00005: loss did not improve from 58.22021\n",
      "Epoch 6/1047\n",
      " - 20s - loss: 58.5371 - val_loss: 25.9149\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "Epoch 7/1047\n",
      " - 18s - loss: 77.2707 - val_loss: 114.8924\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00007: loss did not improve from 58.22021\n",
      "Epoch 8/1047\n",
      " - 18s - loss: 76.0291 - val_loss: 154.8186\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 76.3082 - val_loss: 131.0620\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00009: loss did not improve from 58.22021\n",
      "Epoch 10/1047\n",
      " - 17s - loss: 74.9932 - val_loss: 81.9386\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "Epoch 11/1047\n",
      " - 20s - loss: 72.3836 - val_loss: 70.9890\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00011: loss did not improve from 58.22021\n",
      "Epoch 12/1047\n",
      " - 18s - loss: 70.5471 - val_loss: 55.7008\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "Epoch 13/1047\n",
      " - 21s - loss: 73.9769 - val_loss: 28.2597\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00013: loss did not improve from 58.22021\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 72.5948 - val_loss: 16.7092\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 67.4540 - val_loss: 40.2437\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00015: loss did not improve from 58.22021\n",
      "Epoch 16/1047\n",
      " - 20s - loss: 77.7699 - val_loss: 89.7524\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "Epoch 17/1047\n",
      " - 18s - loss: 73.9683 - val_loss: 34.1254\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00017: loss did not improve from 58.22021\n",
      "Epoch 18/1047\n",
      " - 18s - loss: 66.3782 - val_loss: 76.3998\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 77.8053 - val_loss: 15.5170\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00019: loss did not improve from 58.22021\n",
      "Epoch 20/1047\n",
      " - 19s - loss: 69.6000 - val_loss: 48.0701\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "Epoch 21/1047\n",
      " - 18s - loss: 68.5225 - val_loss: 293.8095\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00021: loss did not improve from 58.22021\n",
      "Epoch 22/1047\n",
      " - 20s - loss: 72.6832 - val_loss: 36.5276\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "Epoch 23/1047\n",
      " - 21s - loss: 83.6553 - val_loss: 53.7933\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00023: loss did not improve from 58.22021\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 70.1283 - val_loss: 78.0658\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "Epoch 25/1047\n",
      " - 20s - loss: 79.9045 - val_loss: 38.1582\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00025: loss did not improve from 58.22021\n",
      "Epoch 26/1047\n",
      " - 21s - loss: 67.9069 - val_loss: 54.7837\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "Epoch 27/1047\n",
      " - 18s - loss: 86.4820 - val_loss: 112.9642\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00027: loss did not improve from 58.22021\n",
      "Epoch 28/1047\n",
      " - 20s - loss: 67.2260 - val_loss: 86.0302\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 73.9141 - val_loss: 126.9710\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00029: loss did not improve from 58.22021\n",
      "Epoch 30/1047\n",
      " - 20s - loss: 87.1084 - val_loss: 26.7334\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "Epoch 31/1047\n",
      " - 20s - loss: 75.7544 - val_loss: 20.6313\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00031: loss did not improve from 58.22021\n",
      "Epoch 32/1047\n",
      " - 20s - loss: 60.3044 - val_loss: 36.5702\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "Epoch 33/1047\n",
      " - 19s - loss: 70.2691 - val_loss: 39.8396\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00033: loss did not improve from 58.22021\n",
      "Epoch 34/1047\n",
      " - 20s - loss: 77.3426 - val_loss: 101.5911\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "Epoch 35/1047\n",
      " - 21s - loss: 69.1830 - val_loss: 93.3107\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00035: loss did not improve from 58.22021\n",
      "Epoch 36/1047\n",
      " - 20s - loss: 66.1636 - val_loss: 15.3267\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "Epoch 37/1047\n",
      " - 21s - loss: 77.0035 - val_loss: 42.3150\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00037: loss did not improve from 58.22021\n",
      "Epoch 00037: early stopping\n",
      "Early stopping patience rate increased - 34.69591148437499\n",
      "\n",
      "Time 14468.785484552383\n",
      "Super-epoch 17 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 24s - loss: 78.7908 - val_loss: 129.0579\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "Epoch 2/1047\n",
      " - 22s - loss: 72.4722 - val_loss: 95.4852\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00002: loss did not improve from 58.22021\n",
      "Epoch 3/1047\n",
      " - 20s - loss: 91.6984 - val_loss: 108.6601\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "Epoch 4/1047\n",
      " - 21s - loss: 68.7750 - val_loss: 105.1870\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00004: loss did not improve from 58.22021\n",
      "Epoch 5/1047\n",
      " - 23s - loss: 70.3371 - val_loss: 80.0609\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "Epoch 6/1047\n",
      " - 26s - loss: 77.1308 - val_loss: 46.5372\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00006: loss did not improve from 58.22021\n",
      "Epoch 7/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 19s - loss: 71.8497 - val_loss: 328.8048\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "Epoch 8/1047\n",
      " - 21s - loss: 72.0606 - val_loss: 71.0257\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00008: loss did not improve from 58.22021\n",
      "Epoch 9/1047\n",
      " - 22s - loss: 76.8750 - val_loss: 46.5264\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "Epoch 10/1047\n",
      " - 20s - loss: 81.6983 - val_loss: 60.2888\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00010: loss did not improve from 58.22021\n",
      "Epoch 11/1047\n",
      " - 21s - loss: 76.2432 - val_loss: 50.0986\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "Epoch 12/1047\n",
      " - 22s - loss: 68.4226 - val_loss: 138.6323\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00012: loss did not improve from 58.22021\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 69.7791 - val_loss: 58.3181\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "Epoch 14/1047\n",
      " - 21s - loss: 74.8298 - val_loss: 33.7795\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00014: loss did not improve from 58.22021\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 70.1276 - val_loss: 12.5376\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 69.9831 - val_loss: 103.1293\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00016: loss did not improve from 58.22021\n",
      "Epoch 17/1047\n",
      " - 18s - loss: 79.1388 - val_loss: 89.7313\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "Epoch 18/1047\n",
      " - 18s - loss: 69.7907 - val_loss: 30.7985\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00018: loss did not improve from 58.22021\n",
      "Epoch 19/1047\n",
      " - 19s - loss: 68.5958 - val_loss: 234.2891\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 75.2650 - val_loss: 215.5123\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00020: loss did not improve from 58.22021\n",
      "Epoch 21/1047\n",
      " - 24s - loss: 70.1234 - val_loss: 42.7561\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "Epoch 22/1047\n",
      " - 19s - loss: 73.2426 - val_loss: 78.4268\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00022: loss did not improve from 58.22021\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 66.4254 - val_loss: 80.9830\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 69.2473 - val_loss: 111.5627\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00024: loss did not improve from 58.22021\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 65.5454 - val_loss: 125.0705\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "Epoch 26/1047\n",
      " - 18s - loss: 74.8490 - val_loss: 19.1192\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00026: loss did not improve from 58.22021\n",
      "Epoch 27/1047\n",
      " - 21s - loss: 65.8292 - val_loss: 70.6873\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "Epoch 28/1047\n",
      " - 19s - loss: 74.1232 - val_loss: 69.3578\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00028: loss did not improve from 58.22021\n",
      "Epoch 29/1047\n",
      " - 18s - loss: 70.8091 - val_loss: 60.4208\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "Epoch 30/1047\n",
      " - 18s - loss: 70.0729 - val_loss: 85.1743\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00030: loss did not improve from 58.22021\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 70.6130 - val_loss: 49.2814\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "Epoch 32/1047\n",
      " - 19s - loss: 79.1423 - val_loss: 116.2559\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00032: loss did not improve from 58.22021\n",
      "Epoch 33/1047\n",
      " - 19s - loss: 69.3617 - val_loss: 162.1702\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "Epoch 34/1047\n",
      " - 18s - loss: 77.0437 - val_loss: 50.4474\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00034: loss did not improve from 58.22021\n",
      "Epoch 35/1047\n",
      " - 18s - loss: 62.0779 - val_loss: 82.4966\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "Epoch 36/1047\n",
      " - 19s - loss: 78.3832 - val_loss: 122.9520\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00036: loss did not improve from 58.22021\n",
      "Epoch 37/1047\n",
      " - 18s - loss: 70.7305 - val_loss: 24.5897\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "Epoch 38/1047\n",
      " - 19s - loss: 68.2205 - val_loss: 116.1975\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00038: loss did not improve from 58.22021\n",
      "Epoch 39/1047\n",
      " - 20s - loss: 72.3514 - val_loss: 101.6249\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "Epoch 40/1047\n",
      " - 19s - loss: 67.9940 - val_loss: 182.5331\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00040: loss did not improve from 58.22021\n",
      "Epoch 41/1047\n",
      " - 19s - loss: 63.6172 - val_loss: 155.4133\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.66865\n",
      "Epoch 42/1047\n",
      " - 18s - loss: 71.4370 - val_loss: 224.7446\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00042: loss did not improve from 58.22021\n",
      "Epoch 43/1047\n",
      " - 20s - loss: 74.7029 - val_loss: 52.5663\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.66865\n",
      "Epoch 44/1047\n",
      " - 19s - loss: 83.9239 - val_loss: 66.7729\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00044: loss did not improve from 58.22021\n",
      "Epoch 45/1047\n",
      " - 20s - loss: 76.1041 - val_loss: 55.6310\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.66865\n",
      "Epoch 46/1047\n",
      " - 18s - loss: 73.8874 - val_loss: 68.5968\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00046: loss did not improve from 58.22021\n",
      "Epoch 47/1047\n",
      " - 19s - loss: 71.1376 - val_loss: 136.8209\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.66865\n",
      "Epoch 48/1047\n",
      " - 19s - loss: 67.9895 - val_loss: 29.0391\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00048: loss did not improve from 58.22021\n",
      "Epoch 49/1047\n",
      " - 18s - loss: 61.7917 - val_loss: 51.1956\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.66865\n",
      "Epoch 50/1047\n",
      " - 18s - loss: 75.0605 - val_loss: 81.0735\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00050: loss did not improve from 58.22021\n",
      "Epoch 51/1047\n",
      " - 20s - loss: 63.7430 - val_loss: 35.4845\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.66865\n",
      "Epoch 52/1047\n",
      " - 19s - loss: 67.1017 - val_loss: 103.1277\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00052: loss did not improve from 58.22021\n",
      "Epoch 53/1047\n",
      " - 19s - loss: 69.7026 - val_loss: 5.5145\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.66865\n",
      "Epoch 54/1047\n",
      " - 18s - loss: 73.6496 - val_loss: 67.4714\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00054: loss did not improve from 58.22021\n",
      "Epoch 55/1047\n",
      " - 20s - loss: 73.0678 - val_loss: 195.8317\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.66865\n",
      "Epoch 56/1047\n",
      " - 18s - loss: 68.7602 - val_loss: 103.2090\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00056: loss did not improve from 58.22021\n",
      "Epoch 57/1047\n",
      " - 19s - loss: 72.0281 - val_loss: 36.1278\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.66865\n",
      "Epoch 58/1047\n",
      " - 20s - loss: 66.3018 - val_loss: 23.4584\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00058: loss did not improve from 58.22021\n",
      "Epoch 59/1047\n",
      " - 18s - loss: 70.7202 - val_loss: 218.0268\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.66865\n",
      "Epoch 60/1047\n",
      " - 19s - loss: 69.7711 - val_loss: 28.5650\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00060: loss did not improve from 58.22021\n",
      "Epoch 61/1047\n",
      " - 18s - loss: 72.2168 - val_loss: 35.0579\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.66865\n",
      "Epoch 62/1047\n",
      " - 21s - loss: 67.8391 - val_loss: 39.3112\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00062: loss did not improve from 58.22021\n",
      "Epoch 63/1047\n",
      " - 20s - loss: 75.6809 - val_loss: 27.1020\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.66865\n",
      "Epoch 64/1047\n",
      " - 20s - loss: 69.3439 - val_loss: 45.5100\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00064: loss did not improve from 58.22021\n",
      "Epoch 65/1047\n",
      " - 20s - loss: 64.1185 - val_loss: 41.9298\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.66865\n",
      "Epoch 66/1047\n",
      " - 20s - loss: 74.1838 - val_loss: 18.1137\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00066: loss did not improve from 58.22021\n",
      "Epoch 67/1047\n",
      " - 19s - loss: 70.6929 - val_loss: 26.8544\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.66865\n",
      "Epoch 68/1047\n",
      " - 21s - loss: 72.6496 - val_loss: 165.1410\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00068: loss did not improve from 58.22021\n",
      "Epoch 69/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 69.3570 - val_loss: 148.0043\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.66865\n",
      "Epoch 70/1047\n",
      " - 19s - loss: 70.9673 - val_loss: 45.5712\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00070: loss did not improve from 58.22021\n",
      "Epoch 71/1047\n",
      " - 19s - loss: 74.3701 - val_loss: 57.9748\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.66865\n",
      "Epoch 72/1047\n",
      " - 24s - loss: 75.8981 - val_loss: 109.3747\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00072: loss did not improve from 58.22021\n",
      "Epoch 73/1047\n",
      " - 18s - loss: 78.2042 - val_loss: 30.4180\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.66865\n",
      "Epoch 74/1047\n",
      " - 20s - loss: 58.6670 - val_loss: 32.2496\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00074: loss did not improve from 58.22021\n",
      "Epoch 75/1047\n",
      " - 21s - loss: 74.1405 - val_loss: 43.6153\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.66865\n",
      "Epoch 76/1047\n",
      " - 22s - loss: 84.9764 - val_loss: 90.0943\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00076: loss did not improve from 58.22021\n",
      "Epoch 77/1047\n",
      " - 19s - loss: 83.2216 - val_loss: 20.2444\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.66865\n",
      "Epoch 78/1047\n",
      " - 20s - loss: 82.9492 - val_loss: 27.7801\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00078: loss did not improve from 58.22021\n",
      "Epoch 79/1047\n",
      " - 19s - loss: 59.7555 - val_loss: 30.7877\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.66865\n",
      "Epoch 80/1047\n",
      " - 21s - loss: 75.5325 - val_loss: 23.2124\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00080: loss did not improve from 58.22021\n",
      "Epoch 81/1047\n",
      " - 21s - loss: 70.4396 - val_loss: 15.2112\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.66865\n",
      "Epoch 82/1047\n",
      " - 19s - loss: 82.0321 - val_loss: 144.7837\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00082: loss did not improve from 58.22021\n",
      "Epoch 83/1047\n",
      " - 23s - loss: 71.7666 - val_loss: 41.4277\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.66865\n",
      "Epoch 84/1047\n",
      " - 21s - loss: 73.3460 - val_loss: 29.4104\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00084: loss did not improve from 58.22021\n",
      "Epoch 85/1047\n",
      " - 20s - loss: 68.9682 - val_loss: 130.3800\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.66865\n",
      "Epoch 86/1047\n",
      " - 20s - loss: 63.9070 - val_loss: 37.9821\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00086: loss did not improve from 58.22021\n",
      "Epoch 87/1047\n",
      " - 18s - loss: 75.5921 - val_loss: 209.3348\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.66865\n",
      "Epoch 88/1047\n",
      " - 18s - loss: 77.5470 - val_loss: 52.5814\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00088: loss did not improve from 58.22021\n",
      "Epoch 89/1047\n",
      " - 22s - loss: 71.7214 - val_loss: 32.6299\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.66865\n",
      "Epoch 90/1047\n",
      " - 18s - loss: 63.0388 - val_loss: 73.2869\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00090: loss did not improve from 58.22021\n",
      "Epoch 91/1047\n",
      " - 18s - loss: 72.5178 - val_loss: 142.6046\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.66865\n",
      "Epoch 92/1047\n",
      " - 19s - loss: 75.2751 - val_loss: 43.0326\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00092: loss did not improve from 58.22021\n",
      "Epoch 93/1047\n",
      " - 18s - loss: 67.1439 - val_loss: 38.7756\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.66865\n",
      "Epoch 94/1047\n",
      " - 19s - loss: 65.7203 - val_loss: 67.6731\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00094: loss did not improve from 58.22021\n",
      "Epoch 95/1047\n",
      " - 19s - loss: 71.2089 - val_loss: 36.1344\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.66865\n",
      "Epoch 96/1047\n",
      " - 18s - loss: 61.9846 - val_loss: 42.2410\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00096: loss did not improve from 58.22021\n",
      "Epoch 97/1047\n",
      " - 18s - loss: 71.5141 - val_loss: 41.4446\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.66865\n",
      "Epoch 98/1047\n",
      " - 18s - loss: 70.2549 - val_loss: 38.8521\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00098: loss did not improve from 58.22021\n",
      "Epoch 99/1047\n",
      " - 18s - loss: 70.4251 - val_loss: 40.0925\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.66865\n",
      "Epoch 100/1047\n",
      " - 18s - loss: 76.0620 - val_loss: 60.2958\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00100: loss did not improve from 58.22021\n",
      "Epoch 101/1047\n",
      " - 19s - loss: 77.8470 - val_loss: 135.9480\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.66865\n",
      "Epoch 102/1047\n",
      " - 19s - loss: 60.7044 - val_loss: 129.9532\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00102: loss did not improve from 58.22021\n",
      "Epoch 103/1047\n",
      " - 19s - loss: 73.3955 - val_loss: 52.4095\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.66865\n",
      "Epoch 104/1047\n",
      " - 19s - loss: 69.2491 - val_loss: 45.0019\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00104: loss did not improve from 58.22021\n",
      "Epoch 105/1047\n",
      " - 19s - loss: 66.1511 - val_loss: 13.9542\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.66865\n",
      "Epoch 106/1047\n",
      " - 19s - loss: 66.5349 - val_loss: 172.3157\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00106: loss did not improve from 58.22021\n",
      "Epoch 107/1047\n",
      " - 19s - loss: 86.0478 - val_loss: 18.5910\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.66865\n",
      "Epoch 108/1047\n",
      " - 17s - loss: 71.2843 - val_loss: 158.7554\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00108: loss did not improve from 58.22021\n",
      "Epoch 109/1047\n",
      " - 20s - loss: 69.2588 - val_loss: 25.5437\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2.66865\n",
      "Epoch 00109: early stopping\n",
      "Early stopping patience rate increased - 39.900298207031234\n",
      "\n",
      "Time 16613.771194934845\n",
      "Super-epoch 18 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 22s - loss: 56.6971 - val_loss: 110.5094\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00001: loss improved from 58.22021 to 56.69710, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [56.69710219757898, 2.668651819229126]\n",
      "Epoch 2/1047\n",
      " - 17s - loss: 71.8261 - val_loss: 54.5782\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "Epoch 3/1047\n",
      " - 19s - loss: 68.8911 - val_loss: 33.4171\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00003: loss did not improve from 56.69710\n",
      "Epoch 4/1047\n",
      " - 19s - loss: 70.9787 - val_loss: 51.3633\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "Epoch 5/1047\n",
      " - 18s - loss: 63.7430 - val_loss: 36.1719\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00005: loss did not improve from 56.69710\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 80.6457 - val_loss: 129.6943\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "Epoch 7/1047\n",
      " - 19s - loss: 79.5643 - val_loss: 88.5911\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00007: loss did not improve from 56.69710\n",
      "Epoch 8/1047\n",
      " - 19s - loss: 66.3746 - val_loss: 97.5611\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 84.1473 - val_loss: 147.8476\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00009: loss did not improve from 56.69710\n",
      "Epoch 10/1047\n",
      " - 20s - loss: 76.4856 - val_loss: 26.4409\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "Epoch 11/1047\n",
      " - 18s - loss: 78.5311 - val_loss: 42.0933\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00011: loss did not improve from 56.69710\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 71.8915 - val_loss: 78.5723\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 67.4881 - val_loss: 190.8831\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00013: loss did not improve from 56.69710\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 79.2677 - val_loss: 27.0236\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "Epoch 15/1047\n",
      " - 20s - loss: 73.3318 - val_loss: 242.3549\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00015: loss did not improve from 56.69710\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 85.1053 - val_loss: 47.9108\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "Epoch 17/1047\n",
      " - 20s - loss: 74.2165 - val_loss: 64.2024\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00017: loss did not improve from 56.69710\n",
      "Epoch 18/1047\n",
      " - 20s - loss: 68.3420 - val_loss: 25.0287\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 65.4947 - val_loss: 49.6361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00019: loss did not improve from 56.69710\n",
      "Epoch 20/1047\n",
      " - 19s - loss: 81.7071 - val_loss: 118.9585\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "Epoch 21/1047\n",
      " - 19s - loss: 73.6488 - val_loss: 44.1335\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00021: loss did not improve from 56.69710\n",
      "Epoch 22/1047\n",
      " - 19s - loss: 80.5823 - val_loss: 51.9728\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "Epoch 23/1047\n",
      " - 20s - loss: 75.4716 - val_loss: 53.3570\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00023: loss did not improve from 56.69710\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 67.7569 - val_loss: 151.0511\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "Epoch 25/1047\n",
      " - 21s - loss: 79.3756 - val_loss: 21.5205\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00025: loss did not improve from 56.69710\n",
      "Epoch 26/1047\n",
      " - 26s - loss: 78.0634 - val_loss: 33.4691\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "Epoch 27/1047\n",
      " - 22s - loss: 70.8855 - val_loss: 25.8237\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00027: loss did not improve from 56.69710\n",
      "Epoch 28/1047\n",
      " - 23s - loss: 72.6527 - val_loss: 32.0665\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "Epoch 29/1047\n",
      " - 22s - loss: 71.6302 - val_loss: 69.4313\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00029: loss did not improve from 56.69710\n",
      "Epoch 30/1047\n",
      " - 23s - loss: 60.6119 - val_loss: 43.7480\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "Epoch 31/1047\n",
      " - 20s - loss: 85.6121 - val_loss: 60.2343\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00031: loss did not improve from 56.69710\n",
      "Epoch 32/1047\n",
      " - 24s - loss: 69.2126 - val_loss: 16.0456\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "Epoch 33/1047\n",
      " - 21s - loss: 69.0973 - val_loss: 18.0630\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00033: loss did not improve from 56.69710\n",
      "Epoch 34/1047\n",
      " - 20s - loss: 70.8189 - val_loss: 116.7340\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "Epoch 35/1047\n",
      " - 22s - loss: 74.9372 - val_loss: 98.9657\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00035: loss did not improve from 56.69710\n",
      "Epoch 36/1047\n",
      " - 20s - loss: 64.8414 - val_loss: 26.7840\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "Epoch 37/1047\n",
      " - 19s - loss: 66.0609 - val_loss: 138.6837\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00037: loss did not improve from 56.69710\n",
      "Epoch 38/1047\n",
      " - 20s - loss: 70.0705 - val_loss: 120.4522\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "Epoch 39/1047\n",
      " - 19s - loss: 64.0337 - val_loss: 27.3635\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00039: loss did not improve from 56.69710\n",
      "Epoch 40/1047\n",
      " - 23s - loss: 62.5252 - val_loss: 28.7878\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.66865\n",
      "Epoch 41/1047\n",
      " - 21s - loss: 75.7446 - val_loss: 153.8582\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00041: loss did not improve from 56.69710\n",
      "Epoch 00041: early stopping\n",
      "Early stopping patience rate increased - 45.88534293808591\n",
      "\n",
      "Time 17450.042501926422\n",
      "Super-epoch 19 - learn rate: 0.0006250000000000002 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 23s - loss: 64.6575 - val_loss: 262.3106\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.66865\n",
      "Epoch 2/1047\n",
      " - 19s - loss: 75.3391 - val_loss: 33.2305\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00002: loss did not improve from 56.69710\n",
      "Epoch 3/1047\n",
      " - 22s - loss: 72.2277 - val_loss: 57.7866\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.66865\n",
      "Epoch 4/1047\n",
      " - 20s - loss: 77.5229 - val_loss: 72.6949\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00004: loss did not improve from 56.69710\n",
      "Epoch 5/1047\n",
      " - 21s - loss: 68.1539 - val_loss: 94.7940\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.66865\n",
      "Epoch 6/1047\n",
      " - 22s - loss: 70.2291 - val_loss: 18.5297\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00006: loss did not improve from 56.69710\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 80.5008 - val_loss: 145.2049\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.66865\n",
      "Epoch 8/1047\n",
      " - 18s - loss: 68.1932 - val_loss: 102.2044\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00008: loss did not improve from 56.69710\n",
      "Epoch 9/1047\n",
      " - 20s - loss: 79.6528 - val_loss: 274.6884\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.66865\n",
      "Epoch 10/1047\n",
      " - 19s - loss: 69.6051 - val_loss: 51.8910\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00010: loss did not improve from 56.69710\n",
      "Epoch 11/1047\n",
      " - 20s - loss: 67.9329 - val_loss: 87.9299\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.66865\n",
      "Epoch 12/1047\n",
      " - 18s - loss: 75.6282 - val_loss: 43.2606\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00012: loss did not improve from 56.69710\n",
      "Epoch 13/1047\n",
      " - 19s - loss: 72.2962 - val_loss: 62.0501\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.66865\n",
      "Epoch 14/1047\n",
      " - 18s - loss: 73.4303 - val_loss: 47.6245\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00014: loss did not improve from 56.69710\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 73.2933 - val_loss: 13.5433\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.66865\n",
      "Epoch 16/1047\n",
      " - 19s - loss: 81.4522 - val_loss: 44.8159\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00016: loss did not improve from 56.69710\n",
      "Epoch 17/1047\n",
      " - 18s - loss: 77.1899 - val_loss: 50.3693\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.66865\n",
      "Epoch 18/1047\n",
      " - 19s - loss: 69.7825 - val_loss: 19.5944\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00018: loss did not improve from 56.69710\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 72.6674 - val_loss: 161.5527\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.66865\n",
      "Epoch 20/1047\n",
      " - 21s - loss: 70.1916 - val_loss: 92.8386\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00020: loss did not improve from 56.69710\n",
      "Epoch 21/1047\n",
      " - 20s - loss: 77.5906 - val_loss: 14.9485\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.66865\n",
      "Epoch 22/1047\n",
      " - 18s - loss: 87.0713 - val_loss: 204.8413\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00022: loss did not improve from 56.69710\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 74.7517 - val_loss: 18.5604\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.66865\n",
      "Epoch 24/1047\n",
      " - 18s - loss: 74.0441 - val_loss: 120.9326\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00024: loss did not improve from 56.69710\n",
      "Epoch 25/1047\n",
      " - 19s - loss: 64.1412 - val_loss: 37.1425\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.66865\n",
      "Epoch 26/1047\n",
      " - 18s - loss: 75.5730 - val_loss: 113.7061\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00026: loss did not improve from 56.69710\n",
      "Epoch 27/1047\n",
      " - 20s - loss: 69.7789 - val_loss: 104.6372\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.66865\n",
      "Epoch 28/1047\n",
      " - 18s - loss: 68.0689 - val_loss: 145.3047\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00028: loss did not improve from 56.69710\n",
      "Epoch 29/1047\n",
      " - 19s - loss: 66.2956 - val_loss: 108.4014\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.66865\n",
      "Epoch 30/1047\n",
      " - 20s - loss: 74.8154 - val_loss: 144.8714\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00030: loss did not improve from 56.69710\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 65.7061 - val_loss: 84.6778\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.66865\n",
      "Epoch 32/1047\n",
      " - 19s - loss: 67.2112 - val_loss: 27.0938\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00032: loss did not improve from 56.69710\n",
      "Epoch 33/1047\n",
      " - 20s - loss: 72.0119 - val_loss: 29.1064\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.66865\n",
      "Epoch 34/1047\n",
      " - 19s - loss: 63.9613 - val_loss: 16.0536\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00034: loss did not improve from 56.69710\n",
      "Epoch 35/1047\n",
      " - 19s - loss: 68.2734 - val_loss: 69.7231\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.66865\n",
      "Epoch 36/1047\n",
      " - 18s - loss: 71.9516 - val_loss: 101.2355\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00036: loss did not improve from 56.69710\n",
      "Epoch 37/1047\n",
      " - 19s - loss: 81.6891 - val_loss: 51.2191\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.66865\n",
      "Epoch 38/1047\n",
      " - 19s - loss: 74.4797 - val_loss: 66.2784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00038: loss did not improve from 56.69710\n",
      "Epoch 39/1047\n",
      " - 19s - loss: 71.1250 - val_loss: 3.1643\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.66865\n",
      "Epoch 40/1047\n",
      " - 20s - loss: 69.8202 - val_loss: 89.5265\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00040: loss did not improve from 56.69710\n",
      "Epoch 41/1047\n",
      " - 19s - loss: 78.7386 - val_loss: 36.0739\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.66865\n",
      "Epoch 42/1047\n",
      " - 19s - loss: 73.9216 - val_loss: 66.1537\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00042: loss did not improve from 56.69710\n",
      "Epoch 43/1047\n",
      " - 20s - loss: 64.7406 - val_loss: 101.0954\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.66865\n",
      "Epoch 44/1047\n",
      " - 20s - loss: 71.5634 - val_loss: 45.2373\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00044: loss did not improve from 56.69710\n",
      "Epoch 45/1047\n",
      " - 19s - loss: 65.8691 - val_loss: 112.5615\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.66865\n",
      "Epoch 46/1047\n",
      " - 19s - loss: 70.4831 - val_loss: 122.4482\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00046: loss did not improve from 56.69710\n",
      "Epoch 47/1047\n",
      " - 20s - loss: 71.2213 - val_loss: 242.7904\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.66865\n",
      "Epoch 48/1047\n",
      " - 20s - loss: 79.8641 - val_loss: 16.2281\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00048: loss did not improve from 56.69710\n",
      "Epoch 49/1047\n",
      " - 18s - loss: 85.7899 - val_loss: 28.9302\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.66865\n",
      "Epoch 50/1047\n",
      " - 20s - loss: 71.6390 - val_loss: 32.2239\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.66865\n",
      "\n",
      "Epoch 00050: loss did not improve from 56.69710\n",
      "Epoch 51/1047\n",
      " - 20s - loss: 67.6346 - val_loss: 1.9749\n",
      "\n",
      "Epoch 00051: val_loss improved from 2.66865 to 1.97494, saving model to ./saved_models/model_0_checkpoint.h5\n",
      "Saving best loss value: [56.69710219757898, 1.97493577003479]\n",
      "Epoch 52/1047\n",
      " - 19s - loss: 74.0586 - val_loss: 85.7211\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00052: loss did not improve from 56.69710\n",
      "Epoch 53/1047\n",
      " - 25s - loss: 64.6705 - val_loss: 114.4686\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.97494\n",
      "Epoch 54/1047\n",
      " - 19s - loss: 75.1212 - val_loss: 34.8041\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00054: loss did not improve from 56.69710\n",
      "Epoch 55/1047\n",
      " - 21s - loss: 80.0305 - val_loss: 105.5060\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.97494\n",
      "Epoch 56/1047\n",
      " - 19s - loss: 70.5395 - val_loss: 26.1180\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00056: loss did not improve from 56.69710\n",
      "Epoch 57/1047\n",
      " - 21s - loss: 72.3351 - val_loss: 15.1444\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.97494\n",
      "Epoch 58/1047\n",
      " - 22s - loss: 73.5721 - val_loss: 28.0631\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00058: loss did not improve from 56.69710\n",
      "Epoch 59/1047\n",
      " - 20s - loss: 73.0595 - val_loss: 128.2347\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.97494\n",
      "Epoch 60/1047\n",
      " - 20s - loss: 73.9926 - val_loss: 57.1786\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00060: loss did not improve from 56.69710\n",
      "Epoch 61/1047\n",
      " - 21s - loss: 68.0901 - val_loss: 44.3058\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.97494\n",
      "Epoch 62/1047\n",
      " - 19s - loss: 86.4164 - val_loss: 72.4731\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00062: loss did not improve from 56.69710\n",
      "Epoch 63/1047\n",
      " - 20s - loss: 74.9545 - val_loss: 90.6076\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.97494\n",
      "Epoch 64/1047\n",
      " - 22s - loss: 73.1927 - val_loss: 38.6665\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00064: loss did not improve from 56.69710\n",
      "Epoch 65/1047\n",
      " - 20s - loss: 76.6427 - val_loss: 73.2720\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.97494\n",
      "Epoch 66/1047\n",
      " - 24s - loss: 69.5530 - val_loss: 35.9803\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00066: loss did not improve from 56.69710\n",
      "Epoch 67/1047\n",
      " - 19s - loss: 66.6963 - val_loss: 41.1245\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.97494\n",
      "Epoch 68/1047\n",
      " - 20s - loss: 70.1135 - val_loss: 195.9398\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00068: loss did not improve from 56.69710\n",
      "Epoch 69/1047\n",
      " - 20s - loss: 75.0295 - val_loss: 63.7256\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.97494\n",
      "Epoch 70/1047\n",
      " - 20s - loss: 89.8562 - val_loss: 59.9080\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00070: loss did not improve from 56.69710\n",
      "Epoch 71/1047\n",
      " - 25s - loss: 68.8213 - val_loss: 41.7673\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.97494\n",
      "Epoch 72/1047\n",
      " - 21s - loss: 66.1757 - val_loss: 28.8041\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00072: loss did not improve from 56.69710\n",
      "Epoch 73/1047\n",
      " - 20s - loss: 72.4858 - val_loss: 73.9706\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.97494\n",
      "Epoch 74/1047\n",
      " - 19s - loss: 75.3347 - val_loss: 22.1059\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00074: loss did not improve from 56.69710\n",
      "Epoch 75/1047\n",
      " - 20s - loss: 73.5918 - val_loss: 42.0642\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.97494\n",
      "Epoch 76/1047\n",
      " - 23s - loss: 71.5500 - val_loss: 49.9714\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00076: loss did not improve from 56.69710\n",
      "Epoch 77/1047\n",
      " - 26s - loss: 74.8636 - val_loss: 33.3903\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.97494\n",
      "Epoch 78/1047\n",
      " - 20s - loss: 75.3322 - val_loss: 94.4690\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00078: loss did not improve from 56.69710\n",
      "Epoch 79/1047\n",
      " - 18s - loss: 82.4152 - val_loss: 40.8412\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.97494\n",
      "Epoch 80/1047\n",
      " - 19s - loss: 80.0836 - val_loss: 47.5673\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00080: loss did not improve from 56.69710\n",
      "Epoch 00080: early stopping\n",
      "Early stopping patience rate increased - 52.768144378798794\n",
      "Learn rate decayed\n",
      "\n",
      "Time 19054.06318807602\n",
      "Super-epoch 20 - learn rate: 0.000393725328092148 - minimum LR: 0.0001\n",
      "\n",
      "Epoch 1/1047\n",
      " - 22s - loss: 71.2439 - val_loss: 16.8839\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.97494\n",
      "Epoch 2/1047\n",
      " - 18s - loss: 74.0467 - val_loss: 49.3960\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00002: loss did not improve from 56.69710\n",
      "Epoch 3/1047\n",
      " - 18s - loss: 81.6223 - val_loss: 16.0541\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.97494\n",
      "Epoch 4/1047\n",
      " - 18s - loss: 70.0260 - val_loss: 17.2392\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00004: loss did not improve from 56.69710\n",
      "Epoch 5/1047\n",
      " - 19s - loss: 73.8232 - val_loss: 19.3656\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.97494\n",
      "Epoch 6/1047\n",
      " - 18s - loss: 73.8246 - val_loss: 32.0140\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00006: loss did not improve from 56.69710\n",
      "Epoch 7/1047\n",
      " - 20s - loss: 77.7994 - val_loss: 246.1401\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.97494\n",
      "Epoch 8/1047\n",
      " - 18s - loss: 73.9006 - val_loss: 28.8117\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00008: loss did not improve from 56.69710\n",
      "Epoch 9/1047\n",
      " - 18s - loss: 86.1022 - val_loss: 67.5392\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.97494\n",
      "Epoch 10/1047\n",
      " - 19s - loss: 75.9599 - val_loss: 212.0418\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00010: loss did not improve from 56.69710\n",
      "Epoch 11/1047\n",
      " - 19s - loss: 75.0236 - val_loss: 43.8161\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.97494\n",
      "Epoch 12/1047\n",
      " - 19s - loss: 71.8103 - val_loss: 48.3773\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00012: loss did not improve from 56.69710\n",
      "Epoch 13/1047\n",
      " - 18s - loss: 80.9500 - val_loss: 14.9153\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.97494\n",
      "Epoch 14/1047\n",
      " - 19s - loss: 65.1044 - val_loss: 73.1012\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00014: loss did not improve from 56.69710\n",
      "Epoch 15/1047\n",
      " - 19s - loss: 77.4710 - val_loss: 27.7325\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.97494\n",
      "Epoch 16/1047\n",
      " - 18s - loss: 76.7902 - val_loss: 27.0997\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00016: loss did not improve from 56.69710\n",
      "Epoch 17/1047\n",
      " - 18s - loss: 67.1554 - val_loss: 34.5999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_loss did not improve from 1.97494\n",
      "Epoch 18/1047\n",
      " - 19s - loss: 78.0712 - val_loss: 43.4324\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00018: loss did not improve from 56.69710\n",
      "Epoch 19/1047\n",
      " - 20s - loss: 76.3382 - val_loss: 69.1209\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.97494\n",
      "Epoch 20/1047\n",
      " - 18s - loss: 68.3519 - val_loss: 53.2678\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00020: loss did not improve from 56.69710\n",
      "Epoch 21/1047\n",
      " - 18s - loss: 74.9316 - val_loss: 117.6505\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.97494\n",
      "Epoch 22/1047\n",
      " - 19s - loss: 81.6433 - val_loss: 124.6925\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00022: loss did not improve from 56.69710\n",
      "Epoch 23/1047\n",
      " - 19s - loss: 65.6355 - val_loss: 10.8914\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.97494\n",
      "Epoch 24/1047\n",
      " - 19s - loss: 71.1010 - val_loss: 46.5202\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00024: loss did not improve from 56.69710\n",
      "Epoch 25/1047\n",
      " - 18s - loss: 67.8750 - val_loss: 158.0723\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.97494\n",
      "Epoch 26/1047\n",
      " - 19s - loss: 64.1168 - val_loss: 56.4348\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00026: loss did not improve from 56.69710\n",
      "Epoch 27/1047\n",
      " - 19s - loss: 73.9748 - val_loss: 221.8216\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.97494\n",
      "Epoch 28/1047\n",
      " - 18s - loss: 71.7961 - val_loss: 106.6452\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00028: loss did not improve from 56.69710\n",
      "Epoch 29/1047\n",
      " - 23s - loss: 79.4742 - val_loss: 41.7296\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.97494\n",
      "Epoch 30/1047\n",
      " - 21s - loss: 82.1439 - val_loss: 225.8950\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00030: loss did not improve from 56.69710\n",
      "Epoch 31/1047\n",
      " - 19s - loss: 81.3673 - val_loss: 37.4736\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.97494\n",
      "Epoch 32/1047\n",
      " - 23s - loss: 70.6765 - val_loss: 16.5124\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00032: loss did not improve from 56.69710\n",
      "Epoch 33/1047\n",
      " - 20s - loss: 74.3245 - val_loss: 66.8924\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.97494\n",
      "Epoch 34/1047\n",
      " - 23s - loss: 72.0630 - val_loss: 29.9612\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00034: loss did not improve from 56.69710\n",
      "Epoch 35/1047\n",
      " - 21s - loss: 68.4870 - val_loss: 171.1068\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.97494\n",
      "Epoch 36/1047\n",
      " - 20s - loss: 70.5219 - val_loss: 259.5410\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00036: loss did not improve from 56.69710\n",
      "Epoch 37/1047\n",
      " - 20s - loss: 71.3910 - val_loss: 14.9383\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.97494\n",
      "Epoch 38/1047\n",
      " - 22s - loss: 67.9453 - val_loss: 53.1295\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00038: loss did not improve from 56.69710\n",
      "Epoch 39/1047\n",
      " - 21s - loss: 75.2991 - val_loss: 8.9972\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.97494\n",
      "Epoch 40/1047\n",
      " - 20s - loss: 79.5473 - val_loss: 33.3725\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00040: loss did not improve from 56.69710\n",
      "Epoch 41/1047\n",
      " - 20s - loss: 75.6090 - val_loss: 53.4827\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.97494\n",
      "Epoch 42/1047\n",
      " - 19s - loss: 81.5407 - val_loss: 17.5977\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00042: loss did not improve from 56.69710\n",
      "Epoch 43/1047\n",
      " - 19s - loss: 73.4595 - val_loss: 70.9752\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.97494\n",
      "Epoch 44/1047\n",
      " - 20s - loss: 64.8860 - val_loss: 122.4982\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00044: loss did not improve from 56.69710\n",
      "Epoch 45/1047\n",
      " - 22s - loss: 74.4789 - val_loss: 143.3204\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.97494\n",
      "Epoch 46/1047\n",
      " - 20s - loss: 63.2034 - val_loss: 42.9786\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00046: loss did not improve from 56.69710\n",
      "Epoch 47/1047\n",
      " - 20s - loss: 66.7724 - val_loss: 33.0301\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.97494\n",
      "Epoch 48/1047\n",
      " - 20s - loss: 76.8840 - val_loss: 43.8093\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00048: loss did not improve from 56.69710\n",
      "Epoch 49/1047\n",
      " - 20s - loss: 73.8238 - val_loss: 15.6001\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.97494\n",
      "Epoch 50/1047\n",
      " - 20s - loss: 65.8700 - val_loss: 25.7650\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00050: loss did not improve from 56.69710\n",
      "Epoch 51/1047\n",
      " - 21s - loss: 75.7957 - val_loss: 29.9240\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.97494\n",
      "Epoch 52/1047\n",
      " - 20s - loss: 76.6775 - val_loss: 47.6084\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00052: loss did not improve from 56.69710\n",
      "Epoch 53/1047\n",
      " - 21s - loss: 83.6788 - val_loss: 71.0364\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.97494\n",
      "Epoch 54/1047\n",
      " - 19s - loss: 86.0869 - val_loss: 52.8024\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00054: loss did not improve from 56.69710\n",
      "Epoch 55/1047\n",
      " - 21s - loss: 76.7977 - val_loss: 13.0344\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.97494\n",
      "Epoch 56/1047\n",
      " - 20s - loss: 77.5487 - val_loss: 126.0000\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00056: loss did not improve from 56.69710\n",
      "Epoch 57/1047\n",
      " - 21s - loss: 60.8673 - val_loss: 17.0683\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.97494\n",
      "Epoch 58/1047\n",
      " - 22s - loss: 65.3602 - val_loss: 57.0816\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00058: loss did not improve from 56.69710\n",
      "Epoch 59/1047\n",
      " - 21s - loss: 77.0160 - val_loss: 25.2231\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.97494\n",
      "Epoch 60/1047\n",
      " - 23s - loss: 70.7651 - val_loss: 376.0772\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00060: loss did not improve from 56.69710\n",
      "Epoch 61/1047\n",
      " - 19s - loss: 73.3974 - val_loss: 43.5606\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.97494\n",
      "Epoch 62/1047\n",
      " - 20s - loss: 82.4520 - val_loss: 69.6400\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00062: loss did not improve from 56.69710\n",
      "Epoch 63/1047\n",
      " - 23s - loss: 68.9982 - val_loss: 137.2134\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.97494\n",
      "Epoch 64/1047\n",
      " - 20s - loss: 62.9073 - val_loss: 45.0696\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00064: loss did not improve from 56.69710\n",
      "Epoch 65/1047\n",
      " - 22s - loss: 70.4486 - val_loss: 57.0001\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.97494\n",
      "Epoch 66/1047\n",
      " - 21s - loss: 70.3260 - val_loss: 34.1448\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00066: loss did not improve from 56.69710\n",
      "Epoch 67/1047\n",
      " - 19s - loss: 74.1374 - val_loss: 251.2384\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.97494\n",
      "Epoch 68/1047\n",
      " - 20s - loss: 80.1981 - val_loss: 30.8855\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00068: loss did not improve from 56.69710\n",
      "Epoch 69/1047\n",
      " - 19s - loss: 73.3788 - val_loss: 108.4127\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.97494\n",
      "Epoch 70/1047\n",
      " - 20s - loss: 67.5482 - val_loss: 2.8608\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00070: loss did not improve from 56.69710\n",
      "Epoch 71/1047\n",
      " - 19s - loss: 75.7169 - val_loss: 17.6621\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.97494\n",
      "Epoch 72/1047\n",
      " - 21s - loss: 75.5500 - val_loss: 24.7049\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00072: loss did not improve from 56.69710\n",
      "Epoch 73/1047\n",
      " - 18s - loss: 69.2315 - val_loss: 28.8154\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.97494\n",
      "Epoch 74/1047\n",
      " - 19s - loss: 78.2635 - val_loss: 49.6016\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00074: loss did not improve from 56.69710\n",
      "Epoch 75/1047\n",
      " - 18s - loss: 78.1658 - val_loss: 80.6103\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.97494\n",
      "Epoch 76/1047\n",
      " - 19s - loss: 73.8882 - val_loss: 86.4412\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00076: loss did not improve from 56.69710\n",
      "Epoch 77/1047\n",
      " - 18s - loss: 58.4212 - val_loss: 32.7850\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.97494\n",
      "Epoch 78/1047\n",
      " - 19s - loss: 68.7284 - val_loss: 52.9228\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00078: loss did not improve from 56.69710\n",
      "Epoch 79/1047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 19s - loss: 69.3761 - val_loss: 145.8154\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.97494\n",
      "Epoch 80/1047\n",
      " - 20s - loss: 64.5283 - val_loss: 158.1265\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00080: loss did not improve from 56.69710\n",
      "Epoch 81/1047\n",
      " - 19s - loss: 69.5368 - val_loss: 59.4281\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.97494\n",
      "Epoch 82/1047\n",
      " - 19s - loss: 72.0387 - val_loss: 78.1184\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00082: loss did not improve from 56.69710\n",
      "Epoch 83/1047\n",
      " - 19s - loss: 73.6260 - val_loss: 26.6813\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.97494\n",
      "Epoch 84/1047\n",
      " - 19s - loss: 68.3374 - val_loss: 162.1488\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00084: loss did not improve from 56.69710\n",
      "Epoch 85/1047\n",
      " - 19s - loss: 65.4667 - val_loss: 48.0846\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.97494\n",
      "Epoch 86/1047\n",
      " - 18s - loss: 70.1718 - val_loss: 21.9898\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00086: loss did not improve from 56.69710\n",
      "Epoch 87/1047\n",
      " - 19s - loss: 66.8207 - val_loss: 92.1494\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.97494\n",
      "Epoch 88/1047\n",
      " - 19s - loss: 76.8682 - val_loss: 68.1637\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00088: loss did not improve from 56.69710\n",
      "Epoch 89/1047\n",
      " - 19s - loss: 61.3416 - val_loss: 55.6729\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.97494\n",
      "Epoch 90/1047\n",
      " - 19s - loss: 75.8731 - val_loss: 240.2982\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00090: loss did not improve from 56.69710\n",
      "Epoch 91/1047\n",
      " - 19s - loss: 62.7438 - val_loss: 50.5368\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.97494\n",
      "Epoch 92/1047\n",
      " - 19s - loss: 71.9126 - val_loss: 80.2261\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00092: loss did not improve from 56.69710\n",
      "Epoch 93/1047\n",
      " - 20s - loss: 68.1836 - val_loss: 109.5164\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.97494\n",
      "Epoch 94/1047\n",
      " - 19s - loss: 68.9969 - val_loss: 240.9575\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00094: loss did not improve from 56.69710\n",
      "Epoch 95/1047\n",
      " - 19s - loss: 79.6219 - val_loss: 35.0166\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.97494\n",
      "Epoch 96/1047\n",
      " - 19s - loss: 68.7241 - val_loss: 49.3291\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00096: loss did not improve from 56.69710\n",
      "Epoch 97/1047\n",
      " - 19s - loss: 75.0844 - val_loss: 126.6933\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.97494\n",
      "Epoch 98/1047\n",
      " - 19s - loss: 75.9672 - val_loss: 62.9501\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00098: loss did not improve from 56.69710\n",
      "Epoch 99/1047\n",
      " - 20s - loss: 76.0845 - val_loss: 34.8906\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.97494\n",
      "Epoch 100/1047\n",
      " - 19s - loss: 61.9733 - val_loss: 226.8122\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00100: loss did not improve from 56.69710\n",
      "Epoch 101/1047\n",
      " - 19s - loss: 77.0550 - val_loss: 26.9249\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1.97494\n",
      "Epoch 102/1047\n",
      " - 19s - loss: 68.2792 - val_loss: 93.5288\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00102: loss did not improve from 56.69710\n",
      "Epoch 103/1047\n",
      " - 20s - loss: 66.7847 - val_loss: 32.1341\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.97494\n",
      "Epoch 104/1047\n",
      " - 19s - loss: 74.7112 - val_loss: 44.7371\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00104: loss did not improve from 56.69710\n",
      "Epoch 105/1047\n",
      " - 21s - loss: 77.6760 - val_loss: 27.9958\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.97494\n",
      "Epoch 106/1047\n",
      " - 19s - loss: 62.0679 - val_loss: 17.8862\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00106: loss did not improve from 56.69710\n",
      "Epoch 107/1047\n",
      " - 20s - loss: 70.8243 - val_loss: 188.0186\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.97494\n",
      "Epoch 108/1047\n",
      " - 21s - loss: 78.5151 - val_loss: 54.0170\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00108: loss did not improve from 56.69710\n",
      "Epoch 109/1047\n",
      " - 20s - loss: 63.0489 - val_loss: 87.5219\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.97494\n",
      "Epoch 110/1047\n",
      " - 20s - loss: 82.1555 - val_loss: 122.1197\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00110: loss did not improve from 56.69710\n",
      "Epoch 111/1047\n",
      " - 18s - loss: 65.8895 - val_loss: 183.0238\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.97494\n",
      "Epoch 112/1047\n",
      " - 21s - loss: 72.6309 - val_loss: 22.8673\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00112: loss did not improve from 56.69710\n",
      "Epoch 113/1047\n",
      " - 21s - loss: 68.6561 - val_loss: 23.6391\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.97494\n",
      "Epoch 114/1047\n",
      " - 20s - loss: 70.4604 - val_loss: 38.1200\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00114: loss did not improve from 56.69710\n",
      "Epoch 115/1047\n",
      " - 21s - loss: 72.2116 - val_loss: 32.5085\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.97494\n",
      "Epoch 116/1047\n",
      " - 20s - loss: 82.4783 - val_loss: 67.2153\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00116: loss did not improve from 56.69710\n",
      "Epoch 117/1047\n",
      " - 22s - loss: 75.6513 - val_loss: 76.8956\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.97494\n",
      "Epoch 118/1047\n",
      " - 19s - loss: 64.4416 - val_loss: 42.2226\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00118: loss did not improve from 56.69710\n",
      "Epoch 119/1047\n",
      " - 21s - loss: 68.6081 - val_loss: 125.6598\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.97494\n",
      "Epoch 120/1047\n",
      " - 21s - loss: 76.8908 - val_loss: 65.1866\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00120: loss did not improve from 56.69710\n",
      "Epoch 121/1047\n",
      " - 22s - loss: 66.9796 - val_loss: 13.7381\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.97494\n",
      "Epoch 122/1047\n",
      " - 20s - loss: 63.3672 - val_loss: 152.8151\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00122: loss did not improve from 56.69710\n",
      "Epoch 123/1047\n",
      " - 19s - loss: 73.1889 - val_loss: 168.5370\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.97494\n",
      "Epoch 124/1047\n",
      " - 20s - loss: 68.6012 - val_loss: 98.9313\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00124: loss did not improve from 56.69710\n",
      "Epoch 125/1047\n",
      " - 20s - loss: 67.0414 - val_loss: 58.7347\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.97494\n",
      "Epoch 126/1047\n",
      " - 20s - loss: 67.9048 - val_loss: 27.9284\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00126: loss did not improve from 56.69710\n",
      "Epoch 127/1047\n",
      " - 20s - loss: 72.7525 - val_loss: 111.3348\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.97494\n",
      "Epoch 128/1047\n",
      " - 19s - loss: 71.5938 - val_loss: 40.8420\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00128: loss did not improve from 56.69710\n",
      "Epoch 129/1047\n",
      " - 21s - loss: 72.0324 - val_loss: 56.6160\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.97494\n",
      "Epoch 130/1047\n",
      " - 19s - loss: 77.9250 - val_loss: 19.9306\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.97494\n",
      "\n",
      "Epoch 00130: loss did not improve from 56.69710\n",
      "Epoch 00130: early stopping\n",
      "Early stopping patience rate increased - 60.68336603561861\n",
      "\n",
      "model_0 training done in 21629.669177293777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "# ''' // comment on this line to enable/disable this block\n",
    "model_0_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_0_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_0_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_0_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_0_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_0_checkpoint_val\n",
    ")\n",
    "model_0_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_0_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_0_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_0_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_0_history = model_0.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_0_checkpoint_val,\n",
    "            model_0_checkpoint_loss,\n",
    "            model_0_recorder,\n",
    "            model_0_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_0_ER.patience = model_0_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_0_ER.patience)\n",
    "    if model_0_learnRate * model_0_LRDecay >= minimumLR and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_0_learnRate = model_0_LRDecay * model_0_learnRate\n",
    "    model_0.load_weights(\"./saved_models/model_0_checkpoint.h5\")\n",
    "    model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_0 training done in\", str(time.time() - start_time))\n",
    "model_0.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_1_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_1_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_1_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_1_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_1_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_1_checkpoint_val\n",
    ")\n",
    "model_1_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_1_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_1_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_1_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_1_history = model_1.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_1_checkpoint_val,\n",
    "            model_1_checkpoint_loss,\n",
    "            model_1_recorder,\n",
    "            model_1_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_1_ER.patience = model_1_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_1_ER.patience)\n",
    "    if model_1_learnRate * model_1_LRDecay >= minimumLR and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_1_learnRate = model_1_LRDecay * model_1_learnRate\n",
    "    model_1.load_weights(\"./saved_models/model_1_checkpoint.h5\")\n",
    "    model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_1 training done in\", str(time.time() - start_time))\n",
    "model_1.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_2_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_2_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_2_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_2_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_2_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_2_checkpoint_val\n",
    ")\n",
    "model_2_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_2_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_2_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_2_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_2_history = model_2.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_2_checkpoint_val,\n",
    "            model_2_checkpoint_loss,\n",
    "            model_2_recorder,\n",
    "            model_2_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_2_ER.patience = model_2_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_2_ER.patience)\n",
    "    if model_2_learnRate * model_2_LRDecay >= minimumLR and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_2_learnRate = model_2_LRDecay * model_2_learnRate\n",
    "    model_2.load_weights(\"./saved_models/model_2_checkpoint.h5\")\n",
    "    model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_2 training done in\", str(time.time() - start_time))\n",
    "model_2.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_3_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_3_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_3_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_3_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_3_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_3_checkpoint_val\n",
    ")\n",
    "model_3_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_3_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_3_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_3_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_3_history = model_3.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_3_checkpoint_val,\n",
    "            model_3_checkpoint_loss,\n",
    "            model_3_recorder,\n",
    "            model_3_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_3_ER.patience = model_3_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_3_ER.patience)\n",
    "    if model_3_learnRate * model_3_LRDecay >= minimumLR and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_3_learnRate = model_3_LRDecay * model_3_learnRate\n",
    "    model_3.load_weights(\"./saved_models/model_3_checkpoint.h5\")\n",
    "    model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_3 training done in\", str(time.time() - start_time))\n",
    "model_3.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_4_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_4_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_4_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_4_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_4_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_4_checkpoint_val\n",
    ")\n",
    "model_4_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_4_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_4_LRDecay = math.pow(1 / 4, 1 / 8) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_4_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_4_history = model_4.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_4_checkpoint_val,\n",
    "            model_4_checkpoint_loss,\n",
    "            model_4_recorder,\n",
    "            model_4_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_4_ER.patience = model_4_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_4_ER.patience)\n",
    "    if model_4_learnRate * model_4_LRDecay >= minimumLR and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_4_learnRate = model_4_LRDecay * model_4_learnRate\n",
    "    model_4.load_weights(\"./saved_models/model_4_checkpoint.h5\")\n",
    "    model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_4 training done in\", str(time.time() - start_time))\n",
    "model_4.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource successfully released\n"
     ]
    }
   ],
   "source": [
    "print(\"Resource successfully released\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
