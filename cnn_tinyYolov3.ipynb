{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version 2.1.0\n",
      "Keras is running on tensorflow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "from PIL import Image\n",
    "import math\n",
    "import tensorflow.python.keras as keras\n",
    "from keras.layers import Input, Layer, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam\n",
    "import keras.backend as K\n",
    "import os\n",
    "K.clear_session()\n",
    "print(\"Running Tensorflow version\", tf.__version__)\n",
    "print(\"Keras is running on\", K.backend(), \"backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom layer classes successfully defined\n"
     ]
    }
   ],
   "source": [
    "# problem with model with rounding \n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # first one that works with model_1 & model_2 \n",
    "    # problem - this rounding function is slow: model_2 = 3 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # in addition, off by half with integer inputs (lower than actual value, e.g. floor(2) ≈ 1.5, floor(2.01) ≈ 2)\n",
    "    # source: https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#Continuity_and_series_expansions\n",
    "    if True:\n",
    "        result = x - 0.5\n",
    "        for p in range(1, 7):\n",
    "            result = result + K.sin(x * p * 2 * math.pi) / (p * math.pi)\n",
    "    return result\n",
    "# '''\n",
    "'''     \n",
    "def roundingAlgo(x):\n",
    "    # second one that works with model_2 \n",
    "    # problem - this rounding function is slower than first working algo: model_2 = 4,2 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # source: self\n",
    "    return x - x % 1\n",
    "# '''\n",
    "# '''\n",
    "def roundingAlgo(x): \n",
    "    # simplification of the first algo loop by simplifying the expression for range(1,7)\n",
    "    # problem - rounding function is still slow = 2,5 hours / epoch\n",
    "    # all non-speed problem of first algo still applies\n",
    "    result = x - 0.5\n",
    "    resultCos = K.cos(2 * math.pi * x)\n",
    "    return result + K.sin(2 * math.pi * x) * (1 + resultCos) * (13 + 2 * resultCos - 18 * K.pow(resultCos, 2) - 32 * K.pow(resultCos, 3) + 80 * K.pow(resultCos, 4)) / 15\n",
    "# '''\n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # made to fool the engine to have a gradient\n",
    "    return 0 * x + K.round(x)\n",
    "# '''\n",
    "\n",
    "\n",
    "# check https://github.com/keras-team/keras/issues/2218\n",
    "# check https://github.com/keras-team/keras/issues/2221\n",
    "# https://www.tensorflow.org/api_docs/python/tf/custom_gradient\n",
    "class RoundClampQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 4096), -524288, 524287) / 4096.0\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(RoundClampQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "class RoundOverflowQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 4096) + 524288) % 1048576) - 524288) / 4096.0\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(RoundOverflowQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "class RoundClampQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 16), -128, 127) / 16.0\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(RoundClampQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "class RoundOverflowQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 128) % 256) - 128) / 16.0\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(RoundOverflowQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "class Identity(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Identity, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "# TODO: change IdentityFinalLayer into the final layer specified in https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg\n",
    "# Reference: https://github.com/BoXiao123/py-tiny-yolo-from-scratch/blob/master/main.py\n",
    "# Reference: https://github.com/BoXiao123/py-tiny-yolo-from-scratch/blob/master/forward_region.py\n",
    "# Reference: https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-2/\n",
    "class IdentityFinalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IdentityFinalLayer, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(IdentityFinalLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "def DBL(previousLayer, layerFilter, kernelSize=(3, 3), roundingFunction=Identity(), name=None):\n",
    "    placeholder = \"\"\n",
    "    if name is not None:\n",
    "        placeholder = str(name)\n",
    "    return roundingFunction(LeakyReLU(alpha=0.1)(roundingFunction(BatchNormalization(name=\"BatchNorm_\"+placeholder)(Conv2D(filters=layerFilter, kernel_size=kernelSize, padding='same', name=\"Conv2D_\"+placeholder)(previousLayer)))))\n",
    "print(\"Custom layer classes successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class classification is 80\n"
     ]
    }
   ],
   "source": [
    "# from pycocotools.coco import COCO\n",
    "nms = 0\n",
    "coco = 0\n",
    "''' // comment on this line to enable/disable this block\n",
    "# this block uses COCO annotation to find how many classification for learning (in case of updates)\n",
    "dataDir='.'\n",
    "dataType='train2017'\n",
    "coco=COCO('{}/annotations/instances_{}.json'.format(dataDir,dataType))\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "nms=[cat['name'] for cat in cats]\n",
    "# '''\n",
    "if isinstance(nms, list):\n",
    "    classificationClass = len(nms)\n",
    "else:\n",
    "    classificationClass = 80\n",
    "\n",
    "print(\"Number of class classification is\", classificationClass)\n",
    "''' // comment on this line to enable/disable this block\n",
    "# this block runs a sample of target data generation\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "imgIds = coco.getImgIds(catIds=coco.getCatIds(catNms=['person','dog','skateboard']));\n",
    "img = coco.loadImgs(imgIds[int(len(imgIds) / 2)])[0]\n",
    "\n",
    "%matplotlib inline\n",
    "imgLoad = Image.open('{}/{}/{}'.format(dataDir, dataType, img['file_name']))\n",
    "imgWRatio = 448 / imgLoad.size[0]\n",
    "imgHRatio = 448 / imgLoad.size[1]\n",
    "imgLoad = np.asarray(imgLoad.resize((448,448)))\n",
    "\n",
    "print(\"Sample image input\")\n",
    "\n",
    "imgplot = plt.imshow(imgLoad)\n",
    "plt.show()\n",
    "\n",
    "annotations = coco.loadAnns(ids=coco.getAnnIds(imgIds=int(img['file_name'].split('.')[0])))\n",
    "bbox_array = list(map(lambda x: x['bbox'], annotations))\n",
    "cat_array = list(map(lambda x: x['category_id'], annotations))\n",
    "bigBox_array = []\n",
    "smolBox_array = []\n",
    "toAppendArray = []\n",
    "for x in range(len(bbox_array)):\n",
    "    print(\"object\", x)\n",
    "    print(x, \"-\", bbox_array[x], \"\\tcategory\", cat_array[x])\n",
    "    toAppendArray = bbox_array[x]\n",
    "    toAppendArray[0] = math.floor(toAppendArray[0] * imgWRatio * 100) / 100\n",
    "    toAppendArray[1] = math.floor(toAppendArray[1] * imgHRatio * 100) / 100\n",
    "    toAppendArray[2] = math.floor(toAppendArray[2] * imgWRatio * 100) / 100\n",
    "    toAppendArray[3] = math.floor(toAppendArray[3] * imgHRatio * 100) / 100\n",
    "    if bbox_array[x][2] * bbox_array[x][3] > 10000:\n",
    "        if len(bigBox_array) < 3:\n",
    "            bigBox_array.append([cat_array[x], toAppendArray])\n",
    "    else:\n",
    "        if len(smolBox_array) < 3:\n",
    "            smolBox_array.append([cat_array[x], toAppendArray])\n",
    "# https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "# https://www.immersivelimit.com/tutorials/create-coco-annotations-from-scratch\n",
    "# https://medium.com/oracledevs/final-layers-and-loss-functions-of-single-stage-detectors-part-1-4abbfa9aa71c\n",
    "print('Big Box')\n",
    "for p in range(len(bigBox_array)):\n",
    "    print(bigBox_array[p])\n",
    "print('Small Box')\n",
    "for p in range(len(smolBox_array)):\n",
    "    print(smolBox_array[p])\n",
    "\n",
    "\n",
    "# bigBox get small grid\n",
    "smallGrid = np.zeros(shape=(14, 14, 3 * (5 + classificationClass)), dtype=np.float32)\n",
    "for x in bigBox_array:\n",
    "    for p in range(3):\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass)] = 1\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass) + 1] = x[1][0]\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass) + 2] = x[1][1]\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass) + 3] = x[1][2]\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass) + 4] = x[1][3]\n",
    "        smallGrid[math.floor(x[1][0] / 32), math.floor(x[1][1] / 32), p * (5 + classificationClass) + 4 + x[0]] = 1\n",
    "# smolBox get big grid\n",
    "bigGrid = np.zeros(shape=(28, 28, 3 * (5 + classificationClass)), dtype=np.float32)\n",
    "for x in smolBox_array:\n",
    "    for p in range(3):\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass)] = 1\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass) + 1] = x[1][0]\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass) + 2] = x[1][1]\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass) + 3] = x[1][2]\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass) + 4] = x[1][3]\n",
    "        bigGrid[math.floor(x[1][0] / 16), math.floor(x[1][1] / 16), p * (5 + classificationClass) + 4 + x[0]] = 1\n",
    "        \n",
    "print(K.constant(value=smallGrid, dtype='float32', shape=(14, 14, 3 * (classificationClass + 5))).shape)\n",
    "print(K.constant(value=bigGrid, dtype='float32', shape=(28, 28, 3 * (classificationClass + 5))).shape)\n",
    "i = 0\n",
    "with (os.scandir('{}/{}/'.format(dataDir, dataType))) as trainingPictures:\n",
    "    for currentPicture in trainingPictures:\n",
    "        print(currentPicture.name)\n",
    "        i = i + 1\n",
    "        if i > 9:\n",
    "            break\n",
    "# '''\n",
    "\n",
    "del coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target data generator successfully defined\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "# '''\n",
    "\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''\n",
    "    random preprocessing for real-time data augmentation \n",
    "    \n",
    "    random=True induces image processing (better data accuracy with cost of cycles)\n",
    "    '''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i % n], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % (n * 2)\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "'''\n",
    "# added quick-fix for categories that are not included in COCO dataset (2017) - https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "def cocoCategoryQF(value):\n",
    "    subtractValue = 0\n",
    "    if value > 12:\n",
    "        subtractValue = subtractValue + 1\n",
    "        if value > 26:\n",
    "            subtractValue = subtractValue + 1\n",
    "            if value > 30:\n",
    "                subtractValue = subtractValue + 2\n",
    "                if value > 45:\n",
    "                    subtractValue = subtractValue + 1\n",
    "                    if value > 66:\n",
    "                        subtractValue = subtractValue + 1\n",
    "                        if value > 69:\n",
    "                            subtractValue = subtractValue + 2\n",
    "                            if value > 71:\n",
    "                                subtractValue = subtractValue + 1\n",
    "                                if value > 83:\n",
    "                                    subtractValue = subtractValue + 1\n",
    "                                    if value > 91:\n",
    "                                        subtractValue = subtractValue + 1\n",
    "    return value - subtractValue\n",
    "# '''\n",
    "print(\"Target data generator successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diambil dari https://github.com/qqwweee/keras-yolo3\n",
    "'''\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 qqwweee\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    "\n",
    "image_size = (416,416)\n",
    "image_height, image_width = image_size\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "tinyYolo_anchors = get_anchors(\"../CNN-VLSI/tiny_yolo_anchors.txt\")\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l], anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "        if print_loss:\n",
    "            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data is 117266\n",
      "# of validation data is 4952\n"
     ]
    }
   ],
   "source": [
    "with open(\"../CNN-VLSI/train.txt\") as trainText:\n",
    "    train_annotation_lines = trainText.readlines()\n",
    "with open(\"../CNN-VLSI/val.txt\") as valText:\n",
    "    val_annotation_lines = valText.readlines()\n",
    "lenTrain = len(train_annotation_lines)\n",
    "print(\"# of training data is\", lenTrain)\n",
    "lenVal = len(val_annotation_lines)\n",
    "print(\"# of validation data is\", lenVal)\n",
    "np.random.seed(31415)\n",
    "np.random.shuffle(train_annotation_lines)\n",
    "np.random.shuffle(val_annotation_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, None, None, 3)\n",
      "(None, None, None, 16)\n",
      "(None, None, None, 16)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 32)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 64)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 256)\n",
      "Branch split from main branch - following branch 0\n",
      "(None, None, None, 256)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 512)\n",
      "(None, None, None, 1024)\n",
      "(None, None, None, 256)\n",
      "Branch split from branch 0 - following branch 0,0\n",
      "(None, None, None, 128)\n",
      "(None, None, None, 128)\n",
      "Branch merge from branch 1 and branch 0,0\n",
      "(None, None, None, 384)\n",
      "(None, None, None, 256)\n",
      "Model output 0 shape: (None, None, None, 255)\n",
      "\n",
      "Branch split from branch 0 - following branch 0,1\n",
      "(None, None, None, 512)\n",
      "Model output 1 shape: (None, None, None, 255)\n",
      "\n",
      "Model model_0 compilation complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_0 = None\n",
    "# '''\n",
    "# model_0 does no rounding (float32 operation)\n",
    "model_0_input = Input(shape=(None, None, 3), name=\"model_0_inputLayer\")\n",
    "model_0_pointer = model_0_input\n",
    "print(\"Input shape:\", model_0_pointer.shape) # 448 x 448 x 3\n",
    "model_0_startBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_input, layerFilter=16, name=\"model_0_layer0_branch\") \n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 448 x 448 x 16\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 224 x 224 x 16\n",
    "model_0_startBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_startBranch, layerFilter=32, name=\"model_0_layer1_branch\")\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 224 x 224 x 32\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 112 x 112 x 32\n",
    "model_0_startBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_startBranch, layerFilter=64, name=\"model_0_layer2_branch\")\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 112 x 112 x 64\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 56 x 56 x 64\n",
    "model_0_startBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_startBranch, layerFilter=128, name=\"model_0_layer3_branch\")\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 56 x 56 x 128\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "model_0_startBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_startBranch, layerFilter=256, name=\"model_0_layer4_branch\")\n",
    "model_0_pointer = model_0_startBranch\n",
    "print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_0_branch0\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "model_0_pointer = model_0_branch0\n",
    "print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "model_0_branch0 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer5_branch0\")\n",
    "model_0_pointer = model_0_branch0\n",
    "print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_0_branch0)\n",
    "model_0_pointer = model_0_branch0\n",
    "print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch0, layerFilter=1024, name=\"model_0_layer6_branch0\")\n",
    "model_0_pointer = model_0_branch0\n",
    "print(model_0_pointer.shape) # 14 x 14 x 1024\n",
    "model_0_branch0 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch0, layerFilter=256, kernelSize=(1, 1))\n",
    "model_0_pointer = model_0_branch0\n",
    "print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_0_branch0 (14 x 14 x 256), following model_0_branch00\n",
    "model_0_branch00 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_0_layer7_branch00\")\n",
    "model_0_pointer = model_0_branch00\n",
    "print(model_0_pointer.shape) # 14 x 14 x 128\n",
    "model_0_branch00 = UpSampling2D()(model_0_branch00)\n",
    "model_0_pointer = model_0_branch00\n",
    "print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_0_branch1 (unchanged from model_0_startBranch) and model_0_branch00\n",
    "model_0_mergedBranch = Concatenate()([model_0_startBranch, model_0_branch00])\n",
    "model_0_pointer = model_0_mergedBranch\n",
    "print(model_0_pointer.shape) # 28 x 28 x 384\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_mergedBranch, layerFilter=256, name=\"model_0_layer8_branch1\")\n",
    "model_0_pointer = model_0_mergedBranch\n",
    "print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity(), previousLayer=model_0_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layer9_branch1\")\n",
    "model_0_pointer = model_0_mergedBranch\n",
    "print(\"Model output 0 shape:\", model_0_pointer.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_0_mergedBranch = IdentityFinalLayer(name=\"model_0_outputLayer_0\")(model_0_mergedBranch)\n",
    "print() # OUTPUT = model_0_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_0_branch01\n",
    "model_0_branch01 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer7_branch01\")\n",
    "model_0_pointer = model_0_branch01\n",
    "print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch01 = DBL(roundingFunction=Identity(), previousLayer=model_0_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layer8_branch01\")\n",
    "model_0_pointer = model_0_branch01\n",
    "print(\"Model output 1 shape:\", model_0_pointer.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_0_branch01 = IdentityFinalLayer(name=\"model_0_outputLayer_1\")(model_0_branch01)\n",
    "print() # OUTPUT = model_0_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_0_actual = Model(inputs=model_0_input, outputs=[model_0_mergedBranch, model_0_branch01])\n",
    "# model_0.compile(optimizer=SGD(lr=0.001, decay=0.0005, momentum=0.9), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_0 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.7\n",
    "}\n",
    "\n",
    "y_true_model_0 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_0_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_0', arguments=setArgs_model_0)([*model_0_actual.output, *y_true_model_0])\n",
    "\n",
    "model_0 = Model([model_0_actual.input, *y_true_model_0], model_0_loss)\n",
    "\n",
    "# model_0_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_0 adalah pendekatan sehingga output model_0 sedekat mungkin dengan 0 (model_0 ≈ model_0_actual - y_true)\n",
    "\n",
    "model_0.compile(optimizer=Adam(lr=1e-3), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_0 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_1 approximates Q7.12 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers\n",
    "model_1 = None\n",
    "'''\n",
    "model_1_input = Input(shape=(448, 448, 3))\n",
    "model_1_pointer = model_1_input\n",
    "print(\"Input shape:\", model_1_pointer.shape) # 448 x 448 x 3\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_input, layerFilter=16) \n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 448 x 448 x 16\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 224 x 224 x 16\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_startBranch, layerFilter=32)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 224 x 224 x 32\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 112 x 112 x 32\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_startBranch, layerFilter=64)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 112 x 112 x 64\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 56 x 56 x 64\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_startBranch, layerFilter=128)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 56 x 56 x 128\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_startBranch, layerFilter=256)\n",
    "model_1_pointer = model_1_startBranch\n",
    "print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_1_branch0\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "model_1_pointer = model_1_branch0\n",
    "print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch0, layerFilter=512)\n",
    "model_1_pointer = model_1_branch0\n",
    "print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_1_branch0)\n",
    "model_1_pointer = model_1_branch0\n",
    "print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch0, layerFilter=1024)\n",
    "model_1_pointer = model_1_branch0\n",
    "print(model_1_pointer.shape) # 14 x 14 x 1024\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch0, layerFilter=256, kernelSize=(1, 1))\n",
    "model_1_pointer = model_1_branch0\n",
    "print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_1_branch0 (14 x 14 x 256), following model_1_branch00\n",
    "model_1_branch00 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch0, layerFilter=128, kernelSize=(1, 1))\n",
    "model_1_pointer = model_1_branch00\n",
    "print(model_1_pointer.shape) # 14 x 14 x 128\n",
    "model_1_branch00 = UpSampling2D()(model_1_branch00)\n",
    "model_1_pointer = model_1_branch00\n",
    "print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_1_branch1 (unchanged from model_1_startBranch) and model_1_branch00\n",
    "model_1_mergedBranch = Concatenate()([model_1_startBranch, model_1_branch00])\n",
    "model_1_pointer = model_1_mergedBranch\n",
    "print(model_1_pointer.shape) # 28 x 28 x 384\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_mergedBranch, layerFilter=256)\n",
    "model_1_pointer = model_1_mergedBranch\n",
    "print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_1_pointer = model_1_mergedBranch\n",
    "print(\"Model output 0 shape:\", model_1_pointer.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_1_mergedBranch = IdentityFinalLayer()(model_1_mergedBranch)\n",
    "print() # OUTPUT = model_1_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\") # following model_1_branch01\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch0, layerFilter=512)\n",
    "model_1_pointer = model_1_branch01\n",
    "print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12(), previousLayer=model_1_branch01, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_1_pointer = model_1_branch01\n",
    "print(\"Model output 1 shape:\", model_1_pointer.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_1_branch01 = IdentityFinalLayer()(model_1_branch01)\n",
    "print() # OUTPUT = model_1_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_1 = Model(inputs=model_1_input, outputs=[model_1_mergedBranch, model_1_branch01])\n",
    "model_1.compile(optimizer=SGD(lr=0.001, decay=0.0005, momentum=0.9), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "print(\"Model model_1 compilation complete\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_2 approximates Q7.12 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers\n",
    "model_2 = None\n",
    "'''\n",
    "model_2_input = Input(shape=(448, 448, 3))\n",
    "model_2_pointer = model_2_input\n",
    "print(\"Input shape:\", model_2_pointer.shape) # 448 x 448 x 3\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_input, layerFilter=16) \n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 448 x 448 x 16\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 224 x 224 x 16\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_startBranch, layerFilter=32)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 224 x 224 x 32\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 112 x 112 x 32\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_startBranch, layerFilter=64)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 112 x 112 x 64\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 56 x 56 x 64\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_startBranch, layerFilter=128)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 56 x 56 x 128\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_startBranch, layerFilter=256)\n",
    "model_2_pointer = model_2_startBranch\n",
    "print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_2_branch0\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "model_2_pointer = model_2_branch0\n",
    "print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch0, layerFilter=512)\n",
    "model_2_pointer = model_2_branch0\n",
    "print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_2_branch0)\n",
    "model_2_pointer = model_2_branch0\n",
    "print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch0, layerFilter=1024)\n",
    "model_2_pointer = model_2_branch0\n",
    "print(model_2_pointer.shape) # 14 x 14 x 1024\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch0, layerFilter=256, kernelSize=(1, 1))\n",
    "model_2_pointer = model_2_branch0\n",
    "print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_2_branch0 (14 x 14 x 256), following model_2_branch00\n",
    "model_2_branch00 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch0, layerFilter=128, kernelSize=(1, 1))\n",
    "model_2_pointer = model_2_branch00\n",
    "print(model_2_pointer.shape) # 14 x 14 x 128\n",
    "model_2_branch00 = UpSampling2D()(model_2_branch00)\n",
    "model_2_pointer = model_2_branch00\n",
    "print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_2_branch1 (unchanged from model_2_startBranch) and model_2_branch00\n",
    "model_2_mergedBranch = Concatenate()([model_2_startBranch, model_2_branch00])\n",
    "model_2_pointer = model_2_mergedBranch\n",
    "print(model_2_pointer.shape) # 28 x 28 x 384\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_mergedBranch, layerFilter=256)\n",
    "model_2_pointer = model_2_mergedBranch\n",
    "print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_2_pointer = model_2_mergedBranch\n",
    "print(\"Model output 0 shape:\", model_2_pointer.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_2_mergedBranch = IdentityFinalLayer()(model_2_mergedBranch)\n",
    "print() # OUTPUT = model_2_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_2_branch01\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch0, layerFilter=512)\n",
    "model_2_pointer = model_2_branch01\n",
    "print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12(), previousLayer=model_2_branch01, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_2_pointer = model_2_branch01\n",
    "print(\"Model output 1 shape:\", model_2_pointer.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_2_branch01 = IdentityFinalLayer()(model_2_branch01)\n",
    "print() # OUTPUT = model_2_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_2 = Model(inputs=model_2_input, outputs=[model_2_mergedBranch, model_2_branch01])\n",
    "model_2.compile(optimizer=SGD(lr=0.001, decay=0.0005, momentum=0.9), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "print(\"Model model_2 compilation complete\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_3 approximates Q3.4 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers\n",
    "model_3 = None\n",
    "'''\n",
    "model_3_input = Input(shape=(448, 448, 3))\n",
    "model_3_pointer = model_3_input\n",
    "print(\"Input shape:\", model_3_pointer.shape) # 448 x 448 x 3\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_input, layerFilter=16) \n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 448 x 448 x 16\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 224 x 224 x 16\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_startBranch, layerFilter=32)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 224 x 224 x 32\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 112 x 112 x 32\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_startBranch, layerFilter=64)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 112 x 112 x 64\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 56 x 56 x 64\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_startBranch, layerFilter=128)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 56 x 56 x 128\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_startBranch, layerFilter=256)\n",
    "model_3_pointer = model_3_startBranch\n",
    "print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_3_branch0\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "model_3_pointer = model_3_branch0\n",
    "print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch0, layerFilter=512)\n",
    "model_3_pointer = model_3_branch0\n",
    "print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_3_branch0)\n",
    "model_3_pointer = model_3_branch0\n",
    "print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch0, layerFilter=1024)\n",
    "model_3_pointer = model_3_branch0\n",
    "print(model_3_pointer.shape) # 14 x 14 x 1024\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch0, layerFilter=256, kernelSize=(1, 1))\n",
    "model_3_pointer = model_3_branch0\n",
    "print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_3_branch0 (14 x 14 x 256), following model_3_branch00\n",
    "model_3_branch00 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch0, layerFilter=128, kernelSize=(1, 1))\n",
    "model_3_pointer = model_3_branch00\n",
    "print(model_3_pointer.shape) # 14 x 14 x 128\n",
    "model_3_branch00 = UpSampling2D()(model_3_branch00)\n",
    "model_3_pointer = model_3_branch00\n",
    "print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_3_branch1 (unchanged from model_3_startBranch) and model_3_branch00\n",
    "model_3_mergedBranch = Concatenate()([model_3_startBranch, model_3_branch00])\n",
    "model_3_pointer = model_3_mergedBranch\n",
    "print(model_3_pointer.shape) # 28 x 28 x 384\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_mergedBranch, layerFilter=256)\n",
    "model_3_pointer = model_3_mergedBranch\n",
    "print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_3_pointer = model_3_mergedBranch\n",
    "print(\"Model output 0 shape:\", model_3_pointer.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_3_mergedBranch = IdentityFinalLayer()(model_3_mergedBranch)\n",
    "print() # OUTPUT = model_3_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\") # following model_3_branch01\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch0, layerFilter=512)\n",
    "model_3_pointer = model_3_branch01\n",
    "print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4(), previousLayer=model_3_branch01, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_3_pointer = model_3_branch01\n",
    "print(\"Model output 1 shape:\", model_3_pointer.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_3_branch01 = IdentityFinalLayer()(model_3_branch01)\n",
    "print() # OUTPUT = model_3_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_3 = Model(inputs=model_3_input, outputs=[model_3_mergedBranch, model_3_branch01])\n",
    "model_3.compile(optimizer=SGD(lr=0.001, decay=0.0005, momentum=0.9), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "print(\"Model model_3 compilation complete\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_4 approximates Q3.4 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers\n",
    "model_4 = None\n",
    "'''\n",
    "model_4_input = Input(shape=(448, 448, 3))\n",
    "model_4_pointer = model_4_input\n",
    "print(\"Input shape:\", model_4_pointer.shape) # 448 x 448 x 3\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_input, layerFilter=16) \n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 448 x 448 x 16\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 224 x 224 x 16\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_startBranch, layerFilter=32)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 224 x 224 x 32\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 112 x 112 x 32\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_startBranch, layerFilter=64)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 112 x 112 x 64\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 56 x 56 x 64\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_startBranch, layerFilter=128)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 56 x 56 x 128\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_startBranch, layerFilter=256)\n",
    "model_4_pointer = model_4_startBranch\n",
    "print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_4_branch0\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "model_4_pointer = model_4_branch0\n",
    "print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch0, layerFilter=512)\n",
    "model_4_pointer = model_4_branch0\n",
    "print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_4_branch0)\n",
    "model_4_pointer = model_4_branch0\n",
    "print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch0, layerFilter=1024)\n",
    "model_4_pointer = model_4_branch0\n",
    "print(model_4_pointer.shape) # 14 x 14 x 1024\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch0, layerFilter=256, kernelSize=(1, 1))\n",
    "model_4_pointer = model_4_branch0\n",
    "print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_4_branch0 (14 x 14 x 256), following model_4_branch00\n",
    "model_4_branch00 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch0, layerFilter=128, kernelSize=(1, 1))\n",
    "model_4_pointer = model_4_branch00\n",
    "print(model_4_pointer.shape) # 14 x 14 x 128\n",
    "model_4_branch00 = UpSampling2D()(model_4_branch00)\n",
    "model_4_pointer = model_4_branch00\n",
    "print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_4_branch1 (unchanged from model_4_startBranch) and model_4_branch00\n",
    "model_4_mergedBranch = Concatenate()([model_4_startBranch, model_4_branch00])\n",
    "model_4_pointer = model_4_mergedBranch\n",
    "print(model_4_pointer.shape) # 28 x 28 x 384\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_mergedBranch, layerFilter=256)\n",
    "model_4_pointer = model_4_mergedBranch\n",
    "print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_4_pointer = model_4_mergedBranch\n",
    "print(\"Model output 0 shape:\", model_4_pointer.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_4_mergedBranch = IdentityFinalLayer()(model_4_mergedBranch)\n",
    "print() # OUTPUT = model_4_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_4_branch01\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch0, layerFilter=512)\n",
    "model_4_pointer = model_4_branch01\n",
    "print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4(), previousLayer=model_4_branch01, layerFilter=3 * (4 + 1 + classificationClass))\n",
    "model_4_pointer = model_4_branch01\n",
    "print(\"Model output 1 shape:\", model_4_pointer.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_4_branch01 = IdentityFinalLayer()(model_4_branch01)\n",
    "print() # OUTPUT = model_4_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_4 = Model(inputs=model_4_input, outputs=[model_4_mergedBranch, model_4_branch01])\n",
    "model_4.compile(optimizer=SGD(lr=0.001, decay=0.0005, momentum=0.9), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "print(\"Model model_4 compilation complete\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "model_0_inputLayer (InputLayer) (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer0_branch (C (None, None, None, 1 448         model_0_inputLayer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer0_branch (None, None, None, 1 64          Conv2D_model_0_layer0_branch[0][0\n",
      "__________________________________________________________________________________________________\n",
      "identity_2 (Identity)           (None, None, None, 1 0           BatchNorm_model_0_layer0_branch[0\n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 1 0           identity_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           identity_2[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer1_branch (C (None, None, None, 3 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer1_branch (None, None, None, 3 128         Conv2D_model_0_layer1_branch[0][0\n",
      "__________________________________________________________________________________________________\n",
      "identity_3 (Identity)           (None, None, None, 3 0           BatchNorm_model_0_layer1_branch[0\n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 3 0           identity_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 3 0           identity_3[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer2_branch (C (None, None, None, 6 18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer2_branch (None, None, None, 6 256         Conv2D_model_0_layer2_branch[0][0\n",
      "__________________________________________________________________________________________________\n",
      "identity_4 (Identity)           (None, None, None, 6 0           BatchNorm_model_0_layer2_branch[0\n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 6 0           identity_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 6 0           identity_4[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer3_branch (C (None, None, None, 1 73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer3_branch (None, None, None, 1 512         Conv2D_model_0_layer3_branch[0][0\n",
      "__________________________________________________________________________________________________\n",
      "identity_5 (Identity)           (None, None, None, 1 0           BatchNorm_model_0_layer3_branch[0\n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 1 0           identity_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 1 0           identity_5[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer4_branch (C (None, None, None, 2 295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer4_branch (None, None, None, 2 1024        Conv2D_model_0_layer4_branch[0][0\n",
      "__________________________________________________________________________________________________\n",
      "identity_6 (Identity)           (None, None, None, 2 0           BatchNorm_model_0_layer4_branch[0\n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 2 0           identity_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 2 0           identity_6[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer5_branch0 ( (None, None, None, 5 1180160     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer5_branch (None, None, None, 5 2048        Conv2D_model_0_layer5_branch0[0][\n",
      "__________________________________________________________________________________________________\n",
      "identity_7 (Identity)           (None, None, None, 5 0           BatchNorm_model_0_layer5_branch0[\n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 5 0           identity_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 5 0           identity_7[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer6_branch0 ( (None, None, None, 1 4719616     max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer6_branch (None, None, None, 1 4096        Conv2D_model_0_layer6_branch0[0][\n",
      "__________________________________________________________________________________________________\n",
      "identity_8 (Identity)           (None, None, None, 1 0           BatchNorm_model_0_layer6_branch0[\n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           identity_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_ (Conv2D)                (None, None, None, 2 262400      identity_8[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_ (BatchNormalization) (None, None, None, 2 1024        Conv2D_[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "identity_9 (Identity)           (None, None, None, 2 0           BatchNorm_[0][0]                 \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 2 0           identity_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer7_branch00  (None, None, None, 1 32896       identity_9[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer7_branch (None, None, None, 1 512         Conv2D_model_0_layer7_branch00[0]\n",
      "__________________________________________________________________________________________________\n",
      "identity_10 (Identity)          (None, None, None, 1 0           BatchNorm_model_0_layer7_branch00\n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           identity_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           identity_10[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 3 0           identity_6[1][0]                 \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer8_branch1 ( (None, None, None, 2 884992      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer7_branch01  (None, None, None, 5 1180160     identity_9[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer8_branch (None, None, None, 2 1024        Conv2D_model_0_layer8_branch1[0][\n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer7_branch (None, None, None, 5 2048        Conv2D_model_0_layer7_branch01[0]\n",
      "__________________________________________________________________________________________________\n",
      "identity_11 (Identity)          (None, None, None, 2 0           BatchNorm_model_0_layer8_branch1[\n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "identity_13 (Identity)          (None, None, None, 5 0           BatchNorm_model_0_layer7_branch01\n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           identity_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 5 0           identity_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer9_branch1 ( (None, None, None, 2 587775      identity_11[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv2D_model_0_layer8_branch01  (None, None, None, 2 1175295     identity_13[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer9_branch (None, None, None, 2 1020        Conv2D_model_0_layer9_branch1[0][\n",
      "__________________________________________________________________________________________________\n",
      "BatchNorm_model_0_layer8_branch (None, None, None, 2 1020        Conv2D_model_0_layer8_branch01[0]\n",
      "__________________________________________________________________________________________________\n",
      "identity_12 (Identity)          (None, None, None, 2 0           BatchNorm_model_0_layer9_branch1[\n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "identity_14 (Identity)          (None, None, None, 2 0           BatchNorm_model_0_layer8_branch01\n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 2 0           identity_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 2 0           identity_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_0_outputLayer_0 (Identity (None, None, None, 2 0           identity_12[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "model_0_outputLayer_1 (Identity (None, None, None, 2 0           identity_14[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 13, 13, 3, 85 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 26, 26, 3, 85 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "yolo_loss_model_0 (Lambda)      (None, 1)            0           model_0_outputLayer_0[0][0]      \n",
      "                                                                 model_0_outputLayer_1[0][0]      \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,430,678\n",
      "Trainable params: 10,423,290\n",
      "Non-trainable params: 7,388\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "if model_0 is not None:\n",
    "    print(model_0.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_1 is not None:\n",
    "    print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_2 is not None:\n",
    "    print(model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_3 is not None:\n",
    "    print(model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_4 is not None:\n",
    "    print(model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "trainingBatchSize = 16\n",
    "train_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=train_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "val_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=val_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [16,26,26,3,1] vs. [16,13,13,3,1]\n\t [[node yolo_loss_model_0/logistic_loss_5/mul (defined at b:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_13960]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b862afd38d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlenVal\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mtrainingBatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [16,26,26,3,1] vs. [16,13,13,3,1]\n\t [[node yolo_loss_model_0/logistic_loss_5/mul (defined at b:\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_13960]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "# ''' // comment on this line to enable/disable this block\n",
    "model_0_history = model_0.fit_generator(\n",
    "    generator=train_data_generator, \n",
    "    steps_per_epoch=max(1, lenTrain//trainingBatchSize), \n",
    "    epochs=5,\n",
    "    validation_data=val_data_generator,\n",
    "    validation_steps=max(1, lenVal//trainingBatchSize),\n",
    ")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_1_history = model_1.fit_generator(\n",
    "    generator=getImageParam_iter('.', 'train2017', cocoTrain), \n",
    "    steps_per_epoch=epoch_steps, \n",
    "    epochs=epoch_number,\n",
    "    validation_data=getImageParam_iter('.', 'val2017', cocoVal),\n",
    "    validation_steps=val_steps,\n",
    "    validation_freq=val_freq\n",
    ")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_2_history = model_2.fit_generator(\n",
    "    generator=getImageParam_iter('.', 'train2017', cocoTrain), \n",
    "    steps_per_epoch=epoch_steps, \n",
    "    epochs=epoch_number,\n",
    "    validation_data=getImageParam_iter('.', 'val2017', cocoVal),\n",
    "    validation_steps=val_steps,\n",
    "    validation_freq=val_freq\n",
    ")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_3_history = model_3.fit_generator(\n",
    "    generator=getImageParam_iter('.', 'train2017', cocoTrain), \n",
    "    steps_per_epoch=epoch_steps, \n",
    "    epochs=epoch_number,\n",
    "    validation_data=getImageParam_iter('.', 'val2017', cocoVal),\n",
    "    validation_steps=val_steps,\n",
    "    validation_freq=val_freq\n",
    ")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_4_history = model_4.fit_generator(\n",
    "    generator=getImageParam_iter('.', 'train2017', cocoTrain), \n",
    "    steps_per_epoch=epoch_steps, \n",
    "    epochs=epoch_number,\n",
    "    validation_data=getImageParam_iter('.', 'val2017', cocoVal),\n",
    "    validation_steps=val_steps,\n",
    "    validation_freq=val_freq\n",
    ")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource successfully released\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
