{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version 2.1.0\n",
      "Keras is running on tensorflow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "from PIL import Image\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Layer, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add, Lambda\n",
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint, Callback, EarlyStopping\n",
    "import keras.backend as K\n",
    "import os\n",
    "K.clear_session()\n",
    "K.set_floatx('float32')\n",
    "print(\"Running Tensorflow version\", tf.__version__)\n",
    "print(\"Keras is running on\", K.backend(), \"backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom layer classes successfully defined\n"
     ]
    }
   ],
   "source": [
    "# problem with model with rounding \n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # first one that works with model_1 & model_2 \n",
    "    # problem - this rounding function is slow: model_2 = 3 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # in addition, off by half with integer inputs (lower than actual value, e.g. floor(2) ≈ 1.5, floor(2.01) ≈ 2)\n",
    "    # source: https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#Continuity_and_series_expansions\n",
    "    if True:\n",
    "        result = x - 0.5\n",
    "        for p in range(1, 7):\n",
    "            result = result + K.sin(x * p * 2 * math.pi) / (p * math.pi)\n",
    "    return result\n",
    "# '''\n",
    "'''     \n",
    "def roundingAlgo(x):\n",
    "    # second one that works with model_2 \n",
    "    # problem - this rounding function is slower than first working algo: model_2 = 4,2 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # source: self\n",
    "    return x - x % 1\n",
    "# '''\n",
    "# '''\n",
    "def roundingAlgo(x): \n",
    "    # simplification of the first algo loop by simplifying the expression for range(1,7)\n",
    "    # problem - rounding function is still slow = 2,5 hours / epoch\n",
    "    # all non-speed problem of first algo still applies\n",
    "    result = x - 0.5\n",
    "    resultCos = K.cos(2 * math.pi * x)\n",
    "    return result + K.sin(2 * math.pi * x) * (1 + resultCos) * (13 + 2 * resultCos - 18 * K.pow(resultCos, 2) - 32 * K.pow(resultCos, 3) + 80 * K.pow(resultCos, 4)) / 15\n",
    "# '''\n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # made to fool the engine to have a gradient\n",
    "    return 0 * x + K.round(x)\n",
    "# '''\n",
    "\n",
    "\n",
    "# check https://github.com/keras-team/keras/issues/2218\n",
    "# check https://github.com/keras-team/keras/issues/2221\n",
    "# https://www.tensorflow.org/api_docs/python/tf/custom_gradient\n",
    "class RoundClampQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 4096), -524288, 524287) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 4096) + 524288) % 1048576) - 524288) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundClampQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 16), -128, 127) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 128) % 256) - 128) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class Identity(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(Identity, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class IdentityFinalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IdentityFinalLayer, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(IdentityFinalLayer, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "    \n",
    "def DBL(previousLayer, layerFilter, kernelSize=(3, 3), roundingFunction=Identity, name=None):\n",
    "    placeholder = \"\"\n",
    "    if name is not None:\n",
    "        placeholder = str(name)\n",
    "    else:\n",
    "        placeholder = str(time.time_ns())\n",
    "    return roundingFunction(name=\"ThirdRound_\"+placeholder, dtype=K.floatx())(\n",
    "        LeakyReLU(alpha=0.1, dtype=K.floatx())(\n",
    "            roundingFunction(name=\"SecondRound_\"+placeholder, dtype=K.floatx())(\n",
    "                BatchNormalization(name=\"BatchNorm_\"+placeholder, dtype=K.floatx())(\n",
    "                    roundingFunction(name=\"FirstRound_\"+placeholder, dtype=K.floatx())(\n",
    "                        Conv2D(filters=layerFilter, kernel_size=kernelSize, padding='same', use_bias=False, kernel_regularizer=l2(5e-4), name=\"Conv2D_\"+placeholder, dtype=K.floatx())(\n",
    "                            previousLayer\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "print(\"Custom layer classes successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class classification is 80\n"
     ]
    }
   ],
   "source": [
    "classificationClass = 80\n",
    "\n",
    "print(\"Number of class classification is\", classificationClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target data generator successfully defined\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''\n",
    "    random preprocessing for real-time data augmentation \n",
    "    \n",
    "    random=True induces image processing (better data accuracy with cost of cycles)\n",
    "    '''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "print(\"Target data generator successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diambil dari https://github.com/qqwweee/keras-yolo3\n",
    "'''\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 qqwweee\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    "\n",
    "image_size = (448,448)\n",
    "image_height, image_width = image_size\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "tinyYolo_anchors = get_anchors(\"../CNN-VLSI/tiny_yolo_anchors.txt\")\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # edited by instructions in https://stackoverflow.com/questions/57558476/training-a-keras-model-yields-multiple-optimizer-errors\n",
    "    box_xy = (K.hard_sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[...,::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[...,::-1], K.dtype(feats))\n",
    "    box_confidence = K.hard_sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.hard_sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l], anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data is 117266\n",
      "# of validation data is 4952\n"
     ]
    }
   ],
   "source": [
    "with open(\"../CNN-VLSI/train.txt\") as trainText:\n",
    "    train_annotation_lines = trainText.readlines()\n",
    "with open(\"../CNN-VLSI/val.txt\") as valText:\n",
    "    val_annotation_lines = valText.readlines()\n",
    "lenTrain = len(train_annotation_lines)\n",
    "print(\"# of training data is\", lenTrain)\n",
    "lenVal = len(val_annotation_lines)\n",
    "print(\"# of validation data is\", lenVal)\n",
    "np.random.shuffle(train_annotation_lines)\n",
    "np.random.shuffle(val_annotation_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 does no rounding (float32 operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_0 = None\n",
    "'''\n",
    "model_0_input = Input(shape=(None, None, 3), name=\"model_0_inputLayer\")\n",
    "# model_0_pointer = model_0_input\n",
    "print(\"Input shape:\", model_0_input.shape) # 448 x 448 x 3\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_input, layerFilter=16, name=\"model_0_layer0_branch\") \n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 448 x 448 x 16\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 16\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=32, name=\"model_0_layer1_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 32\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 32\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=64, name=\"model_0_layer2_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 64\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 64\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=128, name=\"model_0_layer3_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 128\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=256, name=\"model_0_layer4_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_0_branch0\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer5_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_0_branch0)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=1024, name=\"model_0_layer6_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 1024\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_0_layer7_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_0_branch0 (14 x 14 x 256), following model_0_branch00\n",
    "model_0_branch00 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_0_layer8_branch00\")\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 128\n",
    "model_0_branch00 = UpSampling2D()(model_0_branch00)\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_0_branch1 (unchanged from model_0_startBranch) and model_0_branch00\n",
    "model_0_mergedBranch = Concatenate()([model_0_startBranch, model_0_branch00])\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 384\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=256, name=\"model_0_layer9_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layerA_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_0_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_0_mergedBranch = IdentityFinalLayer(name=\"model_0_outputLayer_1\")(model_0_mergedBranch)\n",
    "print() # OUTPUT = model_0_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_0_branch01\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer8_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layer9_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "print(\"Model output 0 shape:\", model_0_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_0_branch01 = IdentityFinalLayer(name=\"model_0_outputLayer_0\")(model_0_branch01)\n",
    "print() # OUTPUT = model_0_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_0_actual = Model(inputs=model_0_input, outputs=[model_0_branch01, model_0_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_0_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_0_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_0_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_0_actual.load_weights(\"./saved_models/model_0_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_0\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_0:\", e)\n",
    "try:\n",
    "    model_0_actual.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_0 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_0 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_0_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_0', arguments=setArgs_model_0)([*model_0_actual.output, *y_true_model_0])\n",
    "\n",
    "model_0 = Model([model_0_actual.input, *y_true_model_0], model_0_loss)\n",
    "\n",
    "# model_0_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_0 adalah pendekatan sehingga output model_0 sedekat mungkin dengan 0 (model_0 ≈ model_0_actual - y_true)\n",
    "model_0_learnRate = 1e-2\n",
    "model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_0 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 approximates Q7.12 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = None\n",
    "'''\n",
    "model_1_input = Input(shape=(None, None, 3), name=\"model_1_inputLayer\")\n",
    "# model_1_pointer = model_1_input\n",
    "print(\"Input shape:\", model_1_input.shape) # 448 x 448 x 3\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_input, layerFilter=16, name=\"model_1_layer0_branch\") \n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 448 x 448 x 16\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 16\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=32, name=\"model_1_layer1_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 32\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 32\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=64, name=\"model_1_layer2_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 64\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 64\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=128, name=\"model_1_layer3_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 128\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=256, name=\"model_1_layer4_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_1_branch0\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer5_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_1_branch0)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=1024, name=\"model_1_layer6_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 1024\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_1_layer7_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_1_branch0 (14 x 14 x 256), following model_1_branch00\n",
    "model_1_branch00 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_1_layer8_branch00\")\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 128\n",
    "model_1_branch00 = UpSampling2D()(model_1_branch00)\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_1_branch1 (unchanged from model_1_startBranch) and model_1_branch00\n",
    "model_1_mergedBranch = Concatenate()([model_1_startBranch, model_1_branch00])\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 384\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=256, name=\"model_1_layer9_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layerA_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_1_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_1_mergedBranch = IdentityFinalLayer(name=\"model_1_outputLayer_1\")(model_1_mergedBranch)\n",
    "print() # OUTPUT = model_1_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_1_branch01\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer8_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layer9_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "print(\"Model output 0 shape:\", model_1_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_1_branch01 = IdentityFinalLayer(name=\"model_1_outputLayer_0\")(model_1_branch01)\n",
    "print() # OUTPUT = model_1_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_1_actual = Model(inputs=model_1_input, outputs=[model_1_branch01, model_1_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_1_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_1_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_1_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_1_actual.load_weights(\"./saved_models/model_1_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_1\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_1:\", e)\n",
    "try:\n",
    "    model_1_actual.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_1 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_1 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_1_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_1', arguments=setArgs_model_1)([*model_1_actual.output, *y_true_model_1])\n",
    "\n",
    "model_1 = Model([model_1_actual.input, *y_true_model_1], model_1_loss)\n",
    "\n",
    "# model_1_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_1 adalah pendekatan sehingga output model_1 sedekat mungkin dengan 0 (model_1 ≈ model_1_actual - y_true)\n",
    "model_1_learnRate = 1e-2\n",
    "model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_1 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 approximates Q7.12 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = None\n",
    "'''\n",
    "model_2_input = Input(shape=(None, None, 3), name=\"model_2_inputLayer\")\n",
    "# model_2_pointer = model_2_input\n",
    "print(\"Input shape:\", model_2_input.shape) # 448 x 448 x 3\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_input, layerFilter=16, name=\"model_2_layer0_branch\") \n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 448 x 448 x 16\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 16\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=32, name=\"model_2_layer1_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 32\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 32\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=64, name=\"model_2_layer2_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 64\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 64\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=128, name=\"model_2_layer3_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 128\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=256, name=\"model_2_layer4_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_2_branch0\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer5_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_2_branch0)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=1024, name=\"model_2_layer6_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 1024\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_2_layer7_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_2_branch0 (14 x 14 x 256), following model_2_branch00\n",
    "model_2_branch00 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_2_layer8_branch00\")\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 128\n",
    "model_2_branch00 = UpSampling2D()(model_2_branch00)\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_2_branch1 (unchanged from model_2_startBranch) and model_2_branch00\n",
    "model_2_mergedBranch = Concatenate()([model_2_startBranch, model_2_branch00])\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 384\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=256, name=\"model_2_layer9_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layerA_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_2_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_2_mergedBranch = IdentityFinalLayer(name=\"model_2_outputLayer_1\")(model_2_mergedBranch)\n",
    "print() # OUTPUT = model_2_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_2_branch01\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer8_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layer9_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "print(\"Model output 0 shape:\", model_2_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_2_branch01 = IdentityFinalLayer(name=\"model_2_outputLayer_0\")(model_2_branch01)\n",
    "print() # OUTPUT = model_2_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_2_actual = Model(inputs=model_2_input, outputs=[model_2_branch01, model_2_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_2_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_2_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_2_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_2_actual.load_weights(\"./saved_models/model_2_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_2\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_2:\", e)\n",
    "try:\n",
    "    model_2_actual.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_2 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_2 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_2_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_2', arguments=setArgs_model_2)([*model_2_actual.output, *y_true_model_2])\n",
    "\n",
    "model_2 = Model([model_2_actual.input, *y_true_model_2], model_2_loss)\n",
    "\n",
    "# model_2_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_2 adalah pendekatan sehingga output model_2 sedekat mungkin dengan 0 (model_2 ≈ model_2_actual - y_true)\n",
    "model_2_learnRate = 1e-2\n",
    "model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_2 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 approximates Q3.4 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = None\n",
    "'''\n",
    "model_3_input = Input(shape=(None, None, 3), name=\"model_3_inputLayer\")\n",
    "# model_3_pointer = model_3_input\n",
    "print(\"Input shape:\", model_3_input.shape) # 448 x 448 x 3\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_input, layerFilter=16, name=\"model_3_layer0_branch\") \n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 448 x 448 x 16\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 16\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=32, name=\"model_3_layer1_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 32\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 32\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=64, name=\"model_3_layer2_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 64\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 64\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=128, name=\"model_3_layer3_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 128\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=256, name=\"model_3_layer4_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_3_branch0\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer5_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_3_branch0)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=1024, name=\"model_3_layer6_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 1024\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_3_layer7_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_3_branch0 (14 x 14 x 256), following model_3_branch00\n",
    "model_3_branch00 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_3_layer8_branch00\")\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 128\n",
    "model_3_branch00 = UpSampling2D()(model_3_branch00)\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_3_branch1 (unchanged from model_3_startBranch) and model_3_branch00\n",
    "model_3_mergedBranch = Concatenate()([model_3_startBranch, model_3_branch00])\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 384\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=256, name=\"model_3_layer9_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layerA_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_3_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_3_mergedBranch = IdentityFinalLayer(name=\"model_3_outputLayer_1\")(model_3_mergedBranch)\n",
    "print() # OUTPUT = model_3_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_3_branch01\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer8_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layer9_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "print(\"Model output 0 shape:\", model_3_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_3_branch01 = IdentityFinalLayer(name=\"model_3_outputLayer_0\")(model_3_branch01)\n",
    "print() # OUTPUT = model_3_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_3_actual = Model(inputs=model_3_input, outputs=[model_3_branch01, model_3_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_3_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_3_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_3_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_3_actual.load_weights(\"./saved_models/model_3_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_3\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_3:\", e)\n",
    "try:\n",
    "    model_3_actual.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_3 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_3 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_3_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_3', arguments=setArgs_model_3)([*model_3_actual.output, *y_true_model_3])\n",
    "\n",
    "model_3 = Model([model_3_actual.input, *y_true_model_3], model_3_loss)\n",
    "\n",
    "# model_3_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_3 adalah pendekatan sehingga output model_3 sedekat mungkin dengan 0 (model_3 ≈ model_3_actual - y_true)\n",
    "model_3_learnRate = 1e-2\n",
    "model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_3 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 approximates Q3.4 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, None, None, 3)\n",
      "Branch split from main branch - following branch 0\n",
      "Branch split from branch 0 - following branch 0,0\n",
      "Branch merge from branch 1 and branch 0,0\n",
      "Model output 1 shape: (None, None, None, 255)\n",
      "\n",
      "Branch split from branch 0 - following branch 0,1\n",
      "Model output 0 shape: (None, None, None, 255)\n",
      "\n",
      "Weight load attempt success for model_4\n",
      "Loaded model is successfully re-saved\n",
      "Model model_4 compilation complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = None\n",
    "# '''\n",
    "model_4_input = Input(shape=(None, None, 3), name=\"model_4_inputLayer\")\n",
    "# model_4_pointer = model_4_input\n",
    "print(\"Input shape:\", model_4_input.shape) # 448 x 448 x 3\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_input, layerFilter=16, name=\"model_4_layer0_branch\") \n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 448 x 448 x 16\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 16\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=32, name=\"model_4_layer1_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 32\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 32\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=64, name=\"model_4_layer2_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 64\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 64\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=128, name=\"model_4_layer3_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 128\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=256, name=\"model_4_layer4_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_4_branch0\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer5_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_4_branch0)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=1024, name=\"model_4_layer6_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 1024\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_4_layer7_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_4_branch0 (14 x 14 x 256), following model_4_branch00\n",
    "model_4_branch00 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_4_layer8_branch00\")\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 128\n",
    "model_4_branch00 = UpSampling2D()(model_4_branch00)\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_4_branch1 (unchanged from model_4_startBranch) and model_4_branch00\n",
    "model_4_mergedBranch = Concatenate()([model_4_startBranch, model_4_branch00])\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 384\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=256, name=\"model_4_layer9_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layerA_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_4_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_4_mergedBranch = IdentityFinalLayer(name=\"model_4_outputLayer_1\")(model_4_mergedBranch)\n",
    "print() # OUTPUT = model_4_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_4_branch01\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer8_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layer9_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "print(\"Model output 0 shape:\", model_4_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_4_branch01 = IdentityFinalLayer(name=\"model_4_outputLayer_0\")(model_4_branch01)\n",
    "print() # OUTPUT = model_4_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_4_actual = Model(inputs=model_4_input, outputs=[model_4_branch01, model_4_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_4_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_4_actual.to_json())\n",
    "\n",
    "try:\n",
    "    model_4_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "#     model_4_actual.load_weights(\"./saved_models/model_4_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_4\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_4:\", e)\n",
    "try:\n",
    "    model_4_actual.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_4 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_4 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_4_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_4', arguments=setArgs_model_4)([*model_4_actual.output, *y_true_model_4])\n",
    "\n",
    "model_4 = Model([model_4_actual.input, *y_true_model_4], model_4_loss)\n",
    "\n",
    "# model_4_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_4 adalah pendekatan sehingga output model_4 sedekat mungkin dengan 0 (model_4 ≈ model_4_actual - y_true)\n",
    "model_4_learnRate = 1e-3\n",
    "model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_4 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_0 is not None:\n",
    "    with open(\"./saved_models/model_0_summary.txt\", \"wt\") as textFile:\n",
    "        model_0.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_1 is not None:\n",
    "    with open(\"./saved_models/model_1_summary.txt\", \"wt\") as textFile:\n",
    "        model_1.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_2 is not None:\n",
    "    with open(\"./saved_models/model_2_summary.txt\", \"wt\") as textFile:\n",
    "        model_2.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_3 is not None:\n",
    "    with open(\"./saved_models/model_3_summary.txt\", \"wt\") as textFile:\n",
    "        model_3.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_4 is not None:\n",
    "    with open(\"./saved_models/model_4_summary.txt\", \"wt\") as textFile:\n",
    "        model_4.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "trainingBatchSize = 1\n",
    "epochSplit = 2094 \n",
    "# because high split = more work saved; 117266 mod 499 = 1 <= less image lost for (416,416)\n",
    "# 117266 mod 2094 = 2 <= due to high loss of (448,448)\n",
    "train_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=train_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "val_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=val_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "minimumLR = 1e-5\n",
    "decayChance = 0.25\n",
    "# class ReloadOnNaN(Callback):\n",
    "#     def __init__(self, filepath=None):\n",
    "#         super(ReloadOnNaN, self).__init__()\n",
    "#         self.filepath = filepath\n",
    "#     def on_batch_end(self, batch, logs=None):\n",
    "#         logs = logs or {}\n",
    "#         loss = logs.get('loss')\n",
    "#         if loss is not None:\n",
    "#             if np.isnan(loss) or np.isinf(loss):\n",
    "#                 if np.isnan(loss):\n",
    "#                     print('\\nDetected nan loss at batch %d, terminating training' % (batch))\n",
    "#                 else:\n",
    "#                     print('\\nDetected inf loss at batch %d, terminating training' % (batch))\n",
    "# #                 self.model.load_weights(self.filepath, by_name=True, skip_mismatch=True)\n",
    "# #                 self.model.reset_metrics()\n",
    "#                 self.model.stop_training = True\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_0_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_0_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_0_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_0_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_0_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_0_learnRate)\n",
    "    print()\n",
    "    model_0_history = model_0.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_0_checkpoint_val,\n",
    "            model_0_checkpoint_loss,\n",
    "#             model_0_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_0_learnRate > minimumLR / model_0_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_0_learnRate = model_0_LRDecay * model_0_learnRate\n",
    "    model_0.load_weights(\"./saved_models/model_0_checkpoint.h5\")\n",
    "    model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_0 training done in\", str(time.time() - start_time))\n",
    "model_0.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_1_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_1_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_1_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_1_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_1_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_1_learnRate)\n",
    "    print()\n",
    "    model_1_history = model_1.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_1_checkpoint_val,\n",
    "            model_1_checkpoint_loss,\n",
    "#             model_1_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_1_learnRate > minimumLR / model_1_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_1_learnRate = model_1_LRDecay * model_1_learnRate\n",
    "    model_1.load_weights(\"./saved_models/model_1_checkpoint.h5\")\n",
    "    model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_1 training done in\", str(time.time() - start_time))\n",
    "model_1.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_2_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_2_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_2_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_2_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_2_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_2_learnRate)\n",
    "    print()\n",
    "    model_2_history = model_2.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_2_checkpoint_val,\n",
    "            model_2_checkpoint_loss,\n",
    "#             model_2_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_2_learnRate > minimumLR / model_2_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_2_learnRate = model_2_LRDecay * model_2_learnRate\n",
    "    model_2.load_weights(\"./saved_models/model_2_checkpoint.h5\")\n",
    "    model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_2 training done in\", str(time.time() - start_time))\n",
    "model_2.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_3_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_3_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_3_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_3_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_3_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_3_learnRate)\n",
    "    print()\n",
    "    model_3_history = model_3.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_3_checkpoint_val,\n",
    "            model_3_checkpoint_loss,\n",
    "#             model_3_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_3_learnRate > minimumLR / model_3_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_3_learnRate = model_3_LRDecay * model_3_learnRate\n",
    "    model_3.load_weights(\"./saved_models/model_3_checkpoint.h5\")\n",
    "    model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_3 training done in\", str(time.time() - start_time))\n",
    "model_3.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 0.0\n",
      "Super-epoch 1 - learn rate: 0.0005\n",
      "\n",
      "Epoch 1/2094\n",
      " - 34s - loss: 2870.8932 - val_loss: 4772.9873\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4772.98730, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2838.4924 - val_loss: 3525.3269\n",
      "\n",
      "Epoch 00002: val_loss improved from 4772.98730 to 3525.32690, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00002: loss improved from inf to 2838.49241, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2830.3024 - val_loss: 7679.3159\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 3525.32690\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2846.3232 - val_loss: 3216.5825\n",
      "\n",
      "Epoch 00004: val_loss improved from 3525.32690 to 3216.58252, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00004: loss did not improve from 2838.49241\n",
      "Epoch 5/2094\n",
      " - 23s - loss: 2798.2960 - val_loss: 4092.5574\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 3216.58252\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2816.2170 - val_loss: 3236.4238\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3216.58252\n",
      "\n",
      "Epoch 00006: loss improved from 2838.49241 to 2816.21697, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2859.1665 - val_loss: 3467.1958\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3216.58252\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2811.5255 - val_loss: 3478.6479\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3216.58252\n",
      "\n",
      "Epoch 00008: loss improved from 2816.21697 to 2811.52548, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2796.5484 - val_loss: 3540.3953\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3216.58252\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2864.0546 - val_loss: 3985.0137\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3216.58252\n",
      "\n",
      "Epoch 00010: loss did not improve from 2811.52548\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2972.9580 - val_loss: 2910.8096\n",
      "\n",
      "Epoch 00011: val_loss improved from 3216.58252 to 2910.80957, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2903.9585 - val_loss: 3316.3523\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2910.80957\n",
      "\n",
      "Epoch 00012: loss did not improve from 2811.52548\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2891.0229 - val_loss: 3734.3770\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2910.80957\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2849.0637 - val_loss: 2646.5481\n",
      "\n",
      "Epoch 00014: val_loss improved from 2910.80957 to 2646.54810, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00014: loss did not improve from 2811.52548\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2863.3733 - val_loss: 2686.4465\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2646.54810\n",
      "Epoch 16/2094\n",
      "Batch 35: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2646.54810\n",
      "\n",
      "Epoch 00016: loss did not improve from 2811.52548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 371.88651514053345\n",
      "Super-epoch 2 - learn rate: 0.0005\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2888.3209 - val_loss: 4365.9946\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2646.54810\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2667.6779 - val_loss: 2919.0481\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2646.54810\n",
      "\n",
      "Epoch 00002: loss improved from 2811.52548 to 2667.67789, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2734.1612 - val_loss: 2609.9775\n",
      "\n",
      "Epoch 00003: val_loss improved from 2646.54810 to 2609.97754, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2810.1166 - val_loss: 2598.7678\n",
      "\n",
      "Epoch 00004: val_loss improved from 2609.97754 to 2598.76782, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00004: loss did not improve from 2667.67789\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2804.7127 - val_loss: 2526.3030\n",
      "\n",
      "Epoch 00005: val_loss improved from 2598.76782 to 2526.30298, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2780.7944 - val_loss: 3975.5051\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2526.30298\n",
      "\n",
      "Epoch 00006: loss did not improve from 2667.67789\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2735.3506 - val_loss: 3545.7612\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2526.30298\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2727.0953 - val_loss: 3190.9839\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2526.30298\n",
      "\n",
      "Epoch 00008: loss did not improve from 2667.67789\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2805.0159 - val_loss: 2589.3079\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2526.30298\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2768.9993 - val_loss: 3050.4172\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2526.30298\n",
      "\n",
      "Epoch 00010: loss did not improve from 2667.67789\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2789.4882 - val_loss: 2765.9485\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2526.30298\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2741.3354 - val_loss: 2655.3088\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2526.30298\n",
      "\n",
      "Epoch 00012: loss did not improve from 2667.67789\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2798.2424 - val_loss: 3350.2617\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2526.30298\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2774.3050 - val_loss: 2704.5322\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2526.30298\n",
      "\n",
      "Epoch 00014: loss did not improve from 2667.67789\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2752.5197 - val_loss: 2327.9905\n",
      "\n",
      "Epoch 00015: val_loss improved from 2526.30298 to 2327.99048, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 16/2094\n",
      " - 23s - loss: 2871.3062 - val_loss: 2710.6892\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00016: loss did not improve from 2667.67789\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2874.0725 - val_loss: 2812.1118\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2327.99048\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2781.2957 - val_loss: 2423.0798\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00018: loss did not improve from 2667.67789\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2808.4194 - val_loss: 2632.3613\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2327.99048\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2716.5425 - val_loss: 2614.9487\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00020: loss did not improve from 2667.67789\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2736.9316 - val_loss: 3237.2344\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2327.99048\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2736.3965 - val_loss: 3250.6350\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00022: loss did not improve from 2667.67789\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2654.1567 - val_loss: 2430.5757\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2327.99048\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2657.8307 - val_loss: 3407.5549\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00024: loss improved from 2667.67789 to 2657.83066, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2717.8836 - val_loss: 3067.1843\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2327.99048\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2719.9415 - val_loss: 2770.9014\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00026: loss did not improve from 2657.83066\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2725.0500 - val_loss: 2796.6238\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2327.99048\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2699.5396 - val_loss: 2373.0977\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00028: loss did not improve from 2657.83066\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2625.1205 - val_loss: 2680.8684\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2327.99048\n",
      "Epoch 30/2094\n",
      " - 23s - loss: 2690.0364 - val_loss: 2752.2380\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00030: loss did not improve from 2657.83066\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2631.4703 - val_loss: 2604.3843\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2327.99048\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2670.8770 - val_loss: 2642.2505\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00032: loss did not improve from 2657.83066\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2697.0338 - val_loss: 2778.8049\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2327.99048\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2744.9230 - val_loss: 2818.4395\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2327.99048\n",
      "\n",
      "Epoch 00034: loss did not improve from 2657.83066\n",
      "Epoch 35/2094\n",
      " - 22s - loss: 2845.4035 - val_loss: 2311.1975\n",
      "\n",
      "Epoch 00035: val_loss improved from 2327.99048 to 2311.19751, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 36/2094\n",
      " - 22s - loss: 2654.1702 - val_loss: 2060.5305\n",
      "\n",
      "Epoch 00036: val_loss improved from 2311.19751 to 2060.53052, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00036: loss improved from 2657.83066 to 2654.17019, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2576.1243 - val_loss: 3603.9897\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2060.53052\n",
      "Epoch 38/2094\n",
      " - 22s - loss: 2618.2798 - val_loss: 3400.5549\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00038: loss improved from 2654.17019 to 2618.27979, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2676.7460 - val_loss: 3576.7805\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2060.53052\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2663.4547 - val_loss: 3196.3372\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00040: loss did not improve from 2618.27979\n",
      "Epoch 41/2094\n",
      " - 22s - loss: 2757.4418 - val_loss: 2374.1697\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2060.53052\n",
      "Epoch 42/2094\n",
      " - 22s - loss: 2631.1705 - val_loss: 3066.8198\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00042: loss did not improve from 2618.27979\n",
      "Epoch 43/2094\n",
      " - 22s - loss: 2696.7018 - val_loss: 2934.8821\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2060.53052\n",
      "Epoch 44/2094\n",
      " - 23s - loss: 2648.6864 - val_loss: 3404.7942\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00044: loss did not improve from 2618.27979\n",
      "Epoch 45/2094\n",
      " - 22s - loss: 2663.7078 - val_loss: 2872.5039\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2060.53052\n",
      "Epoch 46/2094\n",
      " - 23s - loss: 2619.3622 - val_loss: 2640.6541\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00046: loss did not improve from 2618.27979\n",
      "Epoch 47/2094\n",
      " - 22s - loss: 2623.8163 - val_loss: 2527.2668\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2060.53052\n",
      "Epoch 48/2094\n",
      " - 22s - loss: 2576.8688 - val_loss: 2890.9280\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00048: loss improved from 2618.27979 to 2576.86884, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 49/2094\n",
      " - 22s - loss: 2575.1129 - val_loss: 2852.8513\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2060.53052\n",
      "Epoch 50/2094\n",
      " - 22s - loss: 2625.6764 - val_loss: 2713.5117\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00050: loss did not improve from 2576.86884\n",
      "Epoch 51/2094\n",
      " - 22s - loss: 2612.5772 - val_loss: 2511.8845\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2060.53052\n",
      "Epoch 52/2094\n",
      " - 22s - loss: 2523.3936 - val_loss: 2475.1021\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00052: loss improved from 2576.86884 to 2523.39364, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 53/2094\n",
      " - 22s - loss: 2512.9585 - val_loss: 2725.0437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00053: val_loss did not improve from 2060.53052\n",
      "Epoch 54/2094\n",
      " - 22s - loss: 2581.1487 - val_loss: 2460.5374\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00054: loss did not improve from 2523.39364\n",
      "Epoch 55/2094\n",
      " - 22s - loss: 2528.6725 - val_loss: 2247.0903\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2060.53052\n",
      "Epoch 56/2094\n",
      " - 22s - loss: 2449.4718 - val_loss: 2664.4578\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00056: loss improved from 2523.39364 to 2449.47185, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 57/2094\n",
      " - 23s - loss: 2558.4124 - val_loss: 2660.4175\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2060.53052\n",
      "Epoch 58/2094\n",
      " - 22s - loss: 2663.8492 - val_loss: 2417.7124\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00058: loss did not improve from 2449.47185\n",
      "Epoch 59/2094\n",
      " - 22s - loss: 2643.8474 - val_loss: 2342.1877\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2060.53052\n",
      "Epoch 60/2094\n",
      " - 22s - loss: 2558.3508 - val_loss: 2938.9207\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00060: loss did not improve from 2449.47185\n",
      "Epoch 61/2094\n",
      " - 22s - loss: 2431.2811 - val_loss: 3051.8574\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2060.53052\n",
      "Epoch 62/2094\n",
      " - 22s - loss: 2538.5264 - val_loss: 2407.3181\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00062: loss did not improve from 2449.47185\n",
      "Epoch 63/2094\n",
      " - 22s - loss: 2568.9947 - val_loss: 4383.5371\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2060.53052\n",
      "Epoch 64/2094\n",
      " - 22s - loss: 2559.8528 - val_loss: 2445.7781\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00064: loss did not improve from 2449.47185\n",
      "Epoch 65/2094\n",
      " - 22s - loss: 2545.2254 - val_loss: 2322.7732\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2060.53052\n",
      "Epoch 66/2094\n",
      " - 22s - loss: 2543.3090 - val_loss: 2995.8418\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00066: loss did not improve from 2449.47185\n",
      "Epoch 67/2094\n",
      " - 22s - loss: 2603.2110 - val_loss: 3449.2656\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2060.53052\n",
      "Epoch 68/2094\n",
      " - 22s - loss: 2505.7607 - val_loss: 3575.1892\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00068: loss did not improve from 2449.47185\n",
      "Epoch 69/2094\n",
      " - 22s - loss: 2601.6107 - val_loss: 2359.7441\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2060.53052\n",
      "Epoch 70/2094\n",
      " - 22s - loss: 2510.1713 - val_loss: 3108.9556\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00070: loss did not improve from 2449.47185\n",
      "Epoch 71/2094\n",
      " - 23s - loss: 2565.5048 - val_loss: 2321.1584\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2060.53052\n",
      "Epoch 72/2094\n",
      " - 22s - loss: 2634.5049 - val_loss: 2323.5295\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00072: loss did not improve from 2449.47185\n",
      "Epoch 73/2094\n",
      " - 22s - loss: 2541.3330 - val_loss: 2714.9272\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2060.53052\n",
      "Epoch 74/2094\n",
      " - 22s - loss: 2619.3867 - val_loss: 3473.0344\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00074: loss did not improve from 2449.47185\n",
      "Epoch 75/2094\n",
      " - 22s - loss: 2485.7156 - val_loss: 3428.8706\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2060.53052\n",
      "Epoch 76/2094\n",
      " - 22s - loss: 2552.3570 - val_loss: 2462.6050\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00076: loss did not improve from 2449.47185\n",
      "Epoch 77/2094\n",
      " - 22s - loss: 2591.2266 - val_loss: 2231.5742\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2060.53052\n",
      "Epoch 78/2094\n",
      " - 22s - loss: 2567.3086 - val_loss: 2177.0605\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00078: loss did not improve from 2449.47185\n",
      "Epoch 79/2094\n",
      " - 22s - loss: 2576.8763 - val_loss: 2334.6628\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2060.53052\n",
      "Epoch 80/2094\n",
      " - 22s - loss: 2542.4156 - val_loss: 2541.9468\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00080: loss did not improve from 2449.47185\n",
      "Epoch 81/2094\n",
      " - 22s - loss: 2542.6718 - val_loss: 2551.1160\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2060.53052\n",
      "Epoch 82/2094\n",
      " - 22s - loss: 2519.2110 - val_loss: 2732.1584\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00082: loss did not improve from 2449.47185\n",
      "Epoch 83/2094\n",
      " - 22s - loss: 2448.0326 - val_loss: 2767.4561\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2060.53052\n",
      "Epoch 84/2094\n",
      " - 22s - loss: 2521.0108 - val_loss: 2159.0620\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00084: loss did not improve from 2449.47185\n",
      "Epoch 85/2094\n",
      " - 23s - loss: 2428.1667 - val_loss: 2464.7686\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2060.53052\n",
      "Epoch 86/2094\n",
      " - 22s - loss: 2471.1303 - val_loss: 2359.8464\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00086: loss did not improve from 2449.47185\n",
      "Epoch 87/2094\n",
      " - 22s - loss: 2451.6214 - val_loss: 2280.6970\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2060.53052\n",
      "Epoch 88/2094\n",
      " - 22s - loss: 2550.1340 - val_loss: 2146.2300\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00088: loss did not improve from 2449.47185\n",
      "Epoch 89/2094\n",
      " - 22s - loss: 2523.0892 - val_loss: 2268.4448\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2060.53052\n",
      "Epoch 90/2094\n",
      " - 22s - loss: 2492.3509 - val_loss: 2167.0625\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00090: loss did not improve from 2449.47185\n",
      "Epoch 91/2094\n",
      " - 22s - loss: 2491.7430 - val_loss: 3135.6692\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2060.53052\n",
      "Epoch 92/2094\n",
      " - 22s - loss: 2516.1516 - val_loss: 2739.0681\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00092: loss did not improve from 2449.47185\n",
      "Epoch 93/2094\n",
      " - 22s - loss: 2554.5742 - val_loss: 3396.5779\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2060.53052\n",
      "Epoch 94/2094\n",
      " - 22s - loss: 2588.9698 - val_loss: 3029.1702\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00094: loss did not improve from 2449.47185\n",
      "Epoch 95/2094\n",
      " - 22s - loss: 2479.8837 - val_loss: 2369.8987\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2060.53052\n",
      "Epoch 96/2094\n",
      " - 22s - loss: 2538.5623 - val_loss: 2723.8926\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00096: loss did not improve from 2449.47185\n",
      "Epoch 97/2094\n",
      " - 22s - loss: 2479.9742 - val_loss: 2431.9805\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2060.53052\n",
      "Epoch 98/2094\n",
      " - 22s - loss: 2500.6102 - val_loss: 2606.0486\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00098: loss did not improve from 2449.47185\n",
      "Epoch 99/2094\n",
      " - 23s - loss: 2401.2675 - val_loss: 2136.6738\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2060.53052\n",
      "Epoch 100/2094\n",
      " - 22s - loss: 2427.4301 - val_loss: 2888.6807\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00100: loss improved from 2449.47185 to 2427.43012, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 101/2094\n",
      " - 22s - loss: 2419.5764 - val_loss: 2685.8218\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2060.53052\n",
      "Epoch 102/2094\n",
      " - 22s - loss: 2410.9271 - val_loss: 2864.1516\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00102: loss improved from 2427.43012 to 2410.92712, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 103/2094\n",
      " - 22s - loss: 2395.3330 - val_loss: 2228.4658\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2060.53052\n",
      "Epoch 104/2094\n",
      " - 22s - loss: 2308.0355 - val_loss: 2224.7522\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00104: loss improved from 2410.92712 to 2308.03546, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 105/2094\n",
      " - 22s - loss: 2385.3842 - val_loss: 2855.7092\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2060.53052\n",
      "Epoch 106/2094\n",
      " - 22s - loss: 2481.1787 - val_loss: 2532.0020\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00106: loss did not improve from 2308.03546\n",
      "Epoch 107/2094\n",
      " - 22s - loss: 2482.6459 - val_loss: 2737.3479\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2060.53052\n",
      "Epoch 108/2094\n",
      " - 22s - loss: 2415.2392 - val_loss: 2151.0161\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00108: loss did not improve from 2308.03546\n",
      "Epoch 109/2094\n",
      " - 22s - loss: 2428.5824 - val_loss: 2488.2378\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2060.53052\n",
      "Epoch 110/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2541.0639 - val_loss: 2244.4016\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00110: loss did not improve from 2308.03546\n",
      "Epoch 111/2094\n",
      " - 22s - loss: 2477.4712 - val_loss: 2385.7253\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2060.53052\n",
      "Epoch 112/2094\n",
      " - 22s - loss: 2390.1639 - val_loss: 2384.4297\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00112: loss did not improve from 2308.03546\n",
      "Epoch 113/2094\n",
      " - 23s - loss: 2320.7024 - val_loss: 2728.5305\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2060.53052\n",
      "Epoch 114/2094\n",
      " - 22s - loss: 2364.2837 - val_loss: 2207.0076\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00114: loss did not improve from 2308.03546\n",
      "Epoch 115/2094\n",
      " - 22s - loss: 2351.2276 - val_loss: 2418.4858\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2060.53052\n",
      "Epoch 116/2094\n",
      " - 22s - loss: 2427.3490 - val_loss: 2082.3279\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00116: loss did not improve from 2308.03546\n",
      "Epoch 117/2094\n",
      " - 22s - loss: 2350.7715 - val_loss: 3301.9009\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2060.53052\n",
      "Epoch 118/2094\n",
      " - 22s - loss: 2378.2986 - val_loss: 2458.3220\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00118: loss did not improve from 2308.03546\n",
      "Epoch 119/2094\n",
      " - 23s - loss: 2400.8554 - val_loss: 2188.8738\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2060.53052\n",
      "Epoch 120/2094\n",
      " - 22s - loss: 2409.2564 - val_loss: 2635.0535\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00120: loss did not improve from 2308.03546\n",
      "Epoch 121/2094\n",
      " - 22s - loss: 2388.7122 - val_loss: 2565.0554\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2060.53052\n",
      "Epoch 122/2094\n",
      " - 22s - loss: 2373.7053 - val_loss: 2523.2437\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00122: loss did not improve from 2308.03546\n",
      "Epoch 123/2094\n",
      " - 22s - loss: 2419.0249 - val_loss: 2147.7610\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2060.53052\n",
      "Epoch 124/2094\n",
      " - 22s - loss: 2363.4731 - val_loss: 2558.6401\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00124: loss did not improve from 2308.03546\n",
      "Epoch 125/2094\n",
      " - 22s - loss: 2339.9495 - val_loss: 2644.9263\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 2060.53052\n",
      "Epoch 126/2094\n",
      " - 22s - loss: 2434.3046 - val_loss: 2563.5000\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00126: loss did not improve from 2308.03546\n",
      "Epoch 127/2094\n",
      " - 23s - loss: 2360.2048 - val_loss: 2319.2820\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 2060.53052\n",
      "Epoch 128/2094\n",
      " - 22s - loss: 2397.1019 - val_loss: 3449.6423\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2060.53052\n",
      "\n",
      "Epoch 00128: loss did not improve from 2308.03546\n",
      "Epoch 129/2094\n",
      " - 22s - loss: 2401.7474 - val_loss: 2047.5823\n",
      "\n",
      "Epoch 00129: val_loss improved from 2060.53052 to 2047.58228, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 130/2094\n",
      " - 22s - loss: 2423.7313 - val_loss: 2256.0193\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2047.58228\n",
      "\n",
      "Epoch 00130: loss did not improve from 2308.03546\n",
      "Epoch 131/2094\n",
      " - 22s - loss: 2396.6892 - val_loss: 2002.8470\n",
      "\n",
      "Epoch 00131: val_loss improved from 2047.58228 to 2002.84705, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 132/2094\n",
      " - 22s - loss: 2427.3503 - val_loss: 2193.7417\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00132: loss did not improve from 2308.03546\n",
      "Epoch 133/2094\n",
      " - 22s - loss: 2472.5580 - val_loss: 3201.0352\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2002.84705\n",
      "Epoch 134/2094\n",
      " - 22s - loss: 2417.2819 - val_loss: 2917.9619\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00134: loss did not improve from 2308.03546\n",
      "Epoch 135/2094\n",
      " - 22s - loss: 2354.1932 - val_loss: 2203.5112\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2002.84705\n",
      "Epoch 136/2094\n",
      " - 22s - loss: 2387.2743 - val_loss: 2175.4578\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00136: loss did not improve from 2308.03546\n",
      "Epoch 137/2094\n",
      " - 22s - loss: 2313.6704 - val_loss: 2394.7834\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2002.84705\n",
      "Epoch 138/2094\n",
      " - 22s - loss: 2405.6472 - val_loss: 2181.5764\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00138: loss did not improve from 2308.03546\n",
      "Epoch 139/2094\n",
      " - 22s - loss: 2348.3690 - val_loss: 2956.0977\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2002.84705\n",
      "Epoch 140/2094\n",
      " - 22s - loss: 2339.8360 - val_loss: 2208.9976\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00140: loss did not improve from 2308.03546\n",
      "Epoch 141/2094\n",
      " - 23s - loss: 2414.2738 - val_loss: 2738.2288\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2002.84705\n",
      "Epoch 142/2094\n",
      " - 22s - loss: 2398.7344 - val_loss: 3100.5430\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00142: loss did not improve from 2308.03546\n",
      "Epoch 143/2094\n",
      " - 22s - loss: 2316.7829 - val_loss: 2957.6580\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 2002.84705\n",
      "Epoch 144/2094\n",
      " - 22s - loss: 2269.9033 - val_loss: 2012.5350\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00144: loss improved from 2308.03546 to 2269.90326, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 145/2094\n",
      " - 22s - loss: 2249.7396 - val_loss: 2018.9749\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2002.84705\n",
      "Epoch 146/2094\n",
      " - 22s - loss: 2298.5163 - val_loss: 2589.7896\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00146: loss did not improve from 2269.90326\n",
      "Epoch 147/2094\n",
      " - 22s - loss: 2310.0442 - val_loss: 2059.7678\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2002.84705\n",
      "Epoch 148/2094\n",
      " - 22s - loss: 2306.7742 - val_loss: 2172.2109\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00148: loss did not improve from 2269.90326\n",
      "Epoch 149/2094\n",
      "Batch 2: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2002.84705\n",
      "Learn rate decayed\n",
      "\n",
      "Time 3671.370617866516\n",
      "Super-epoch 3 - learn rate: 0.0003149802624737183\n",
      "\n",
      "Epoch 1/2094\n",
      " - 30s - loss: 2278.0329 - val_loss: 2094.0681\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2002.84705\n",
      "\n",
      "Epoch 00001: loss did not improve from 2269.90326\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2349.5018 - val_loss: 2419.9712\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2002.84705\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2327.2386 - val_loss: 1939.6024\n",
      "\n",
      "Epoch 00003: val_loss improved from 2002.84705 to 1939.60242, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00003: loss did not improve from 2269.90326\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2347.5757 - val_loss: 2130.4673\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1939.60242\n",
      "Epoch 5/2094\n",
      " - 23s - loss: 2372.7831 - val_loss: 2506.3503\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00005: loss did not improve from 2269.90326\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2288.2847 - val_loss: 2081.4182\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1939.60242\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2421.5704 - val_loss: 2241.9868\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00007: loss did not improve from 2269.90326\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2287.7360 - val_loss: 2181.2104\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1939.60242\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2350.1484 - val_loss: 2054.6418\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00009: loss did not improve from 2269.90326\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2323.9130 - val_loss: 2522.7642\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1939.60242\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2231.5336 - val_loss: 3132.7595\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00011: loss improved from 2269.90326 to 2231.53364, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2274.7838 - val_loss: 2007.7251\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1939.60242\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2282.2701 - val_loss: 2045.5371\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00013: loss did not improve from 2231.53364\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2245.2226 - val_loss: 2664.3826\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1939.60242\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2289.7413 - val_loss: 2599.0088\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00015: loss did not improve from 2231.53364\n",
      "Epoch 16/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2217.4625 - val_loss: 2032.1458\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1939.60242\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2294.9689 - val_loss: 2247.2568\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00017: loss did not improve from 2231.53364\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2235.2040 - val_loss: 3375.6033\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1939.60242\n",
      "Epoch 19/2094\n",
      " - 23s - loss: 2306.8036 - val_loss: 2617.5950\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00019: loss did not improve from 2231.53364\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2361.1084 - val_loss: 2160.3406\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1939.60242\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2316.1253 - val_loss: 1945.1648\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00021: loss did not improve from 2231.53364\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2351.0484 - val_loss: 1975.4697\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1939.60242\n",
      "Epoch 23/2094\n",
      "Batch 8: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00023: loss did not improve from 2231.53364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 4182.603794336319\n",
      "Super-epoch 4 - learn rate: 0.0003149802624737183\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2221.7237 - val_loss: 2224.7219\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1939.60242\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2226.2445 - val_loss: 2027.5253\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00002: loss improved from 2231.53364 to 2226.24447, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2304.1956 - val_loss: 2938.3501\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1939.60242\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2202.5202 - val_loss: 2165.6384\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00004: loss improved from 2226.24447 to 2202.52016, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2366.2969 - val_loss: 2694.7983\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1939.60242\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2208.5003 - val_loss: 2089.0122\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00006: loss did not improve from 2202.52016\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2305.8255 - val_loss: 2293.1863\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1939.60242\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2272.6881 - val_loss: 2751.7964\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00008: loss did not improve from 2202.52016\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2287.7065 - val_loss: 2264.5723\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1939.60242\n",
      "Epoch 10/2094\n",
      " - 23s - loss: 2238.5706 - val_loss: 2065.9883\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00010: loss did not improve from 2202.52016\n",
      "Epoch 11/2094\n",
      "Batch 52: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1939.60242\n",
      "\n",
      "Time 4440.6039390563965\n",
      "Super-epoch 5 - learn rate: 0.0003149802624737183\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2327.6914 - val_loss: 2873.8892\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00001: loss did not improve from 2202.52016\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2257.6466 - val_loss: 2602.4771\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1939.60242\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2310.3813 - val_loss: 2798.2971\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00003: loss did not improve from 2202.52016\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2282.9960 - val_loss: 3313.5684\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1939.60242\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2266.3219 - val_loss: 2065.7998\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00005: loss did not improve from 2202.52016\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2245.1681 - val_loss: 2892.9131\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1939.60242\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2226.3522 - val_loss: 2495.2656\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00007: loss did not improve from 2202.52016\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2393.6571 - val_loss: 2173.3137\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1939.60242\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2317.7599 - val_loss: 2413.0916\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00009: loss did not improve from 2202.52016\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2241.4821 - val_loss: 3149.8604\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1939.60242\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2271.1393 - val_loss: 2298.6094\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00011: loss did not improve from 2202.52016\n",
      "Epoch 12/2094\n",
      " - 23s - loss: 2321.4030 - val_loss: 2029.7759\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1939.60242\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2296.9536 - val_loss: 2341.2722\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00013: loss did not improve from 2202.52016\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2307.5492 - val_loss: 2465.3213\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1939.60242\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2303.2801 - val_loss: 2156.6838\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00015: loss did not improve from 2202.52016\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2258.6845 - val_loss: 2161.2744\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1939.60242\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2332.5433 - val_loss: 2291.0867\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00017: loss did not improve from 2202.52016\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2287.4320 - val_loss: 2175.0090\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1939.60242\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2385.7820 - val_loss: 2132.8647\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00019: loss did not improve from 2202.52016\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2382.2163 - val_loss: 2988.7227\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1939.60242\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2324.1731 - val_loss: 2015.5714\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00021: loss did not improve from 2202.52016\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2331.6260 - val_loss: 2322.3813\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1939.60242\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2311.7075 - val_loss: 2772.4978\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00023: loss did not improve from 2202.52016\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2416.1442 - val_loss: 2402.9968\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1939.60242\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2347.3529 - val_loss: 2355.3660\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00025: loss did not improve from 2202.52016\n",
      "Epoch 26/2094\n",
      " - 23s - loss: 2339.3944 - val_loss: 2127.9973\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1939.60242\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2297.2775 - val_loss: 2566.2661\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00027: loss did not improve from 2202.52016\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2273.9801 - val_loss: 2671.8591\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1939.60242\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2320.7403 - val_loss: 2289.9395\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00029: loss did not improve from 2202.52016\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2365.8589 - val_loss: 3029.2607\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1939.60242\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2320.8134 - val_loss: 2629.1033\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00031: loss did not improve from 2202.52016\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2342.2828 - val_loss: 2465.6514\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1939.60242\n",
      "Epoch 33/2094\n",
      "Batch 37: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00033: loss did not improve from 2202.52016\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 5179.1507267951965\n",
      "Super-epoch 6 - learn rate: 0.00019842513149602494\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2326.6470 - val_loss: 2206.1257\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1939.60242\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2254.8560 - val_loss: 2223.5562\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00002: loss did not improve from 2202.52016\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2255.5470 - val_loss: 2795.9355\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1939.60242\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2322.8666 - val_loss: 2240.0154\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00004: loss did not improve from 2202.52016\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2374.0438 - val_loss: 2096.7078\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1939.60242\n",
      "Epoch 6/2094\n",
      " - 23s - loss: 2324.7698 - val_loss: 2725.1338\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00006: loss did not improve from 2202.52016\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2391.7447 - val_loss: 2247.2280\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1939.60242\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2414.1636 - val_loss: 2282.5723\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00008: loss did not improve from 2202.52016\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2294.4132 - val_loss: 2465.9751\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1939.60242\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2270.2863 - val_loss: 2201.5842\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00010: loss did not improve from 2202.52016\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2258.1467 - val_loss: 2626.8054\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1939.60242\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2322.9446 - val_loss: 2840.7227\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00012: loss did not improve from 2202.52016\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2278.6686 - val_loss: 2417.7319\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1939.60242\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2281.5220 - val_loss: 2335.9536\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00014: loss did not improve from 2202.52016\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2235.3976 - val_loss: 2793.9084\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1939.60242\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2294.0035 - val_loss: 2026.6808\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00016: loss did not improve from 2202.52016\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2303.1245 - val_loss: 2147.0605\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1939.60242\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2252.8294 - val_loss: 2002.1908\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00018: loss did not improve from 2202.52016\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2308.1318 - val_loss: 2066.7883\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1939.60242\n",
      "Epoch 20/2094\n",
      " - 23s - loss: 2368.2822 - val_loss: 2478.2935\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00020: loss did not improve from 2202.52016\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2311.5218 - val_loss: 2091.3940\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1939.60242\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2364.7604 - val_loss: 2246.3914\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00022: loss did not improve from 2202.52016\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2331.1830 - val_loss: 2261.4883\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1939.60242\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2316.7412 - val_loss: 2219.6343\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00024: loss did not improve from 2202.52016\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2299.9280 - val_loss: 2186.4453\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1939.60242\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2338.9782 - val_loss: 3274.0972\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00026: loss did not improve from 2202.52016\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2280.6152 - val_loss: 2307.1350\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1939.60242\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2297.2345 - val_loss: 2233.4131\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00028: loss did not improve from 2202.52016\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2345.8130 - val_loss: 2592.2781\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1939.60242\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2291.2184 - val_loss: 2495.3372\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00030: loss did not improve from 2202.52016\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2384.7599 - val_loss: 2707.9351\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1939.60242\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2235.4958 - val_loss: 2118.9797\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00032: loss did not improve from 2202.52016\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2282.0939 - val_loss: 2136.6589\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1939.60242\n",
      "Epoch 34/2094\n",
      " - 23s - loss: 2314.1985 - val_loss: 2244.2251\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00034: loss did not improve from 2202.52016\n",
      "Epoch 35/2094\n",
      " - 22s - loss: 2255.5450 - val_loss: 2157.1101\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1939.60242\n",
      "Epoch 36/2094\n",
      " - 22s - loss: 2261.5474 - val_loss: 3119.7773\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00036: loss did not improve from 2202.52016\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2340.0877 - val_loss: 3049.0010\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1939.60242\n",
      "Epoch 38/2094\n",
      " - 22s - loss: 2295.6850 - val_loss: 2080.7349\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00038: loss did not improve from 2202.52016\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2332.2983 - val_loss: 2164.7065\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1939.60242\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2328.6445 - val_loss: 2319.9739\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00040: loss did not improve from 2202.52016\n",
      "Epoch 41/2094\n",
      " - 22s - loss: 2401.4174 - val_loss: 2273.9827\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1939.60242\n",
      "Epoch 42/2094\n",
      " - 22s - loss: 2392.1263 - val_loss: 2641.7954\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1939.60242\n",
      "\n",
      "Epoch 00042: loss did not improve from 2202.52016\n",
      "Epoch 43/2094\n",
      " - 22s - loss: 2249.1366 - val_loss: 2087.6221\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1939.60242\n",
      "Epoch 44/2094\n",
      " - 22s - loss: 2347.1055 - val_loss: 1920.4297\n",
      "\n",
      "Epoch 00044: val_loss improved from 1939.60242 to 1920.42969, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00044: loss did not improve from 2202.52016\n",
      "Epoch 45/2094\n",
      " - 22s - loss: 2303.9997 - val_loss: 2168.3125\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1920.42969\n",
      "Epoch 46/2094\n",
      " - 22s - loss: 2308.2889 - val_loss: 2177.3052\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00046: loss did not improve from 2202.52016\n",
      "Epoch 47/2094\n",
      " - 22s - loss: 2263.3516 - val_loss: 2375.1187\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1920.42969\n",
      "Epoch 48/2094\n",
      " - 23s - loss: 2246.7154 - val_loss: 3152.9126\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00048: loss did not improve from 2202.52016\n",
      "Epoch 49/2094\n",
      " - 22s - loss: 2280.7264 - val_loss: 2171.5142\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1920.42969\n",
      "Epoch 50/2094\n",
      " - 22s - loss: 2197.8822 - val_loss: 2353.6506\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00050: loss improved from 2202.52016 to 2197.88217, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 51/2094\n",
      "Batch 5: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1920.42969\n",
      "\n",
      "Time 6310.978640317917\n",
      "Super-epoch 7 - learn rate: 0.00019842513149602494\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2300.7005 - val_loss: 2029.1659\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00001: loss did not improve from 2197.88217\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2267.3998 - val_loss: 2001.7953\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1920.42969\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2323.5346 - val_loss: 2252.7346\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00003: loss did not improve from 2197.88217\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2302.6159 - val_loss: 2247.7241\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1920.42969\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2376.2786 - val_loss: 2172.1003\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00005: loss did not improve from 2197.88217\n",
      "Epoch 6/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2285.0130 - val_loss: 2926.7456\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1920.42969\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2300.3114 - val_loss: 1980.6692\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00007: loss did not improve from 2197.88217\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2275.4061 - val_loss: 2047.0902\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1920.42969\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2310.5674 - val_loss: 1972.2487\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00009: loss did not improve from 2197.88217\n",
      "Epoch 10/2094\n",
      " - 23s - loss: 2336.7645 - val_loss: 2149.5425\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1920.42969\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2289.3171 - val_loss: 2001.3987\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00011: loss did not improve from 2197.88217\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2319.4692 - val_loss: 2103.0071\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1920.42969\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2262.9307 - val_loss: 2533.8394\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00013: loss did not improve from 2197.88217\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2394.9952 - val_loss: 2873.8494\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1920.42969\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2322.0811 - val_loss: 2220.5142\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00015: loss did not improve from 2197.88217\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2289.9229 - val_loss: 2526.0938\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1920.42969\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2309.6075 - val_loss: 2431.7859\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00017: loss did not improve from 2197.88217\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2302.0967 - val_loss: 2329.4895\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1920.42969\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2266.0815 - val_loss: 2878.0710\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00019: loss did not improve from 2197.88217\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2271.6005 - val_loss: 2050.8613\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1920.42969\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2225.8380 - val_loss: 2115.9377\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00021: loss did not improve from 2197.88217\n",
      "Epoch 22/2094\n",
      "Batch 42: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1920.42969\n",
      "Learn rate decayed\n",
      "\n",
      "Time 6813.244535446167\n",
      "Super-epoch 8 - learn rate: 0.000125\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2220.8206 - val_loss: 2097.3003\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00001: loss did not improve from 2197.88217\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2310.2353 - val_loss: 3297.6025\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1920.42969\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2244.9743 - val_loss: 2222.0945\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00003: loss did not improve from 2197.88217\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2293.7450 - val_loss: 1972.6323\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1920.42969\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2252.5923 - val_loss: 1945.4501\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00005: loss did not improve from 2197.88217\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2183.9255 - val_loss: 2549.2478\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1920.42969\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2293.3991 - val_loss: 2025.2560\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00007: loss did not improve from 2197.88217\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2302.3284 - val_loss: 1971.3042\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1920.42969\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2296.5751 - val_loss: 2345.0618\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00009: loss did not improve from 2197.88217\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2365.1878 - val_loss: 1986.6710\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1920.42969\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2360.0391 - val_loss: 2496.3799\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00011: loss did not improve from 2197.88217\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2272.0270 - val_loss: 2408.1194\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1920.42969\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2199.6908 - val_loss: 1985.1895\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00013: loss did not improve from 2197.88217\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2238.5104 - val_loss: 2288.1121\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1920.42969\n",
      "Epoch 15/2094\n",
      " - 23s - loss: 2280.5026 - val_loss: 2148.5171\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00015: loss did not improve from 2197.88217\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2206.0090 - val_loss: 2416.6023\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1920.42969\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2315.1864 - val_loss: 2493.3789\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00017: loss did not improve from 2197.88217\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2284.8571 - val_loss: 2312.6445\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1920.42969\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2224.4592 - val_loss: 2092.7261\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00019: loss did not improve from 2197.88217\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2217.4041 - val_loss: 2052.4014\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1920.42969\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2250.6953 - val_loss: 2525.4758\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00021: loss did not improve from 2197.88217\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2267.9508 - val_loss: 2160.8086\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1920.42969\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2273.6351 - val_loss: 2084.4343\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00023: loss did not improve from 2197.88217\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2197.9431 - val_loss: 2351.9807\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1920.42969\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2246.0598 - val_loss: 2544.7610\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00025: loss did not improve from 2197.88217\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2201.3376 - val_loss: 1990.1698\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1920.42969\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2246.6144 - val_loss: 2525.7578\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00027: loss did not improve from 2197.88217\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2257.2801 - val_loss: 2094.6384\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1920.42969\n",
      "Epoch 29/2094\n",
      " - 23s - loss: 2269.3923 - val_loss: 2214.4402\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00029: loss did not improve from 2197.88217\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2264.0950 - val_loss: 1942.6691\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1920.42969\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2276.6624 - val_loss: 2039.2623\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00031: loss did not improve from 2197.88217\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2285.9082 - val_loss: 2019.6232\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1920.42969\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2164.5754 - val_loss: 2069.7520\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00033: loss improved from 2197.88217 to 2164.57544, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2242.0875 - val_loss: 3066.8091\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1920.42969\n",
      "Epoch 35/2094\n",
      " - 22s - loss: 2159.8662 - val_loss: 2336.0449\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00035: loss improved from 2164.57544 to 2159.86615, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Epoch 36/2094\n",
      " - 22s - loss: 2297.4059 - val_loss: 2050.5225\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1920.42969\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2302.4594 - val_loss: 2042.6106\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00037: loss did not improve from 2159.86615\n",
      "Epoch 38/2094\n",
      " - 22s - loss: 2290.5234 - val_loss: 2246.8362\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1920.42969\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2207.4528 - val_loss: 1996.7241\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00039: loss did not improve from 2159.86615\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2248.0156 - val_loss: 1988.4915\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1920.42969\n",
      "Epoch 41/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2320.7319 - val_loss: 2932.9675\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00041: loss did not improve from 2159.86615\n",
      "Epoch 42/2094\n",
      " - 23s - loss: 2336.0290 - val_loss: 2525.8691\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1920.42969\n",
      "Epoch 43/2094\n",
      " - 23s - loss: 2282.5214 - val_loss: 2003.2264\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1920.42969\n",
      "\n",
      "Epoch 00043: loss did not improve from 2159.86615\n",
      "Epoch 44/2094\n",
      " - 23s - loss: 2250.2502 - val_loss: 2045.4440\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1920.42969\n",
      "Epoch 45/2094\n",
      " - 22s - loss: 2289.6523 - val_loss: 1917.0239\n",
      "\n",
      "Epoch 00045: val_loss improved from 1920.42969 to 1917.02393, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00045: loss did not improve from 2159.86615\n",
      "Epoch 46/2094\n",
      " - 22s - loss: 2264.4937 - val_loss: 2222.3459\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1917.02393\n",
      "Epoch 47/2094\n",
      " - 22s - loss: 2245.9495 - val_loss: 2036.0291\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00047: loss did not improve from 2159.86615\n",
      "Epoch 48/2094\n",
      " - 22s - loss: 2196.7310 - val_loss: 2072.2310\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1917.02393\n",
      "Epoch 49/2094\n",
      " - 22s - loss: 2253.4039 - val_loss: 2028.4780\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00049: loss did not improve from 2159.86615\n",
      "Epoch 50/2094\n",
      " - 22s - loss: 2216.6814 - val_loss: 2042.7892\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1917.02393\n",
      "Epoch 51/2094\n",
      " - 22s - loss: 2214.3436 - val_loss: 1969.2305\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00051: loss did not improve from 2159.86615\n",
      "Epoch 52/2094\n",
      " - 22s - loss: 2313.0689 - val_loss: 2996.7698\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1917.02393\n",
      "Epoch 53/2094\n",
      " - 22s - loss: 2298.5591 - val_loss: 2099.1953\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00053: loss did not improve from 2159.86615\n",
      "Epoch 54/2094\n",
      " - 22s - loss: 2297.9228 - val_loss: 2002.8480\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1917.02393\n",
      "Epoch 55/2094\n",
      " - 22s - loss: 2272.4993 - val_loss: 2350.4360\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00055: loss did not improve from 2159.86615\n",
      "Epoch 56/2094\n",
      " - 22s - loss: 2312.4620 - val_loss: 2022.0448\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1917.02393\n",
      "Epoch 57/2094\n",
      " - 23s - loss: 2309.0471 - val_loss: 2612.0918\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00057: loss did not improve from 2159.86615\n",
      "Epoch 58/2094\n",
      " - 22s - loss: 2205.3066 - val_loss: 2282.9546\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1917.02393\n",
      "Epoch 59/2094\n",
      " - 22s - loss: 2378.9167 - val_loss: 2081.9377\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00059: loss did not improve from 2159.86615\n",
      "Epoch 60/2094\n",
      " - 22s - loss: 2274.8240 - val_loss: 2074.3591\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1917.02393\n",
      "Epoch 61/2094\n",
      " - 22s - loss: 2280.6846 - val_loss: 1978.6577\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00061: loss did not improve from 2159.86615\n",
      "Epoch 62/2094\n",
      " - 22s - loss: 2307.6815 - val_loss: 2498.4690\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1917.02393\n",
      "Epoch 63/2094\n",
      " - 22s - loss: 2274.7597 - val_loss: 2107.2993\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00063: loss did not improve from 2159.86615\n",
      "Epoch 64/2094\n",
      " - 22s - loss: 2257.6709 - val_loss: 2016.1082\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1917.02393\n",
      "Epoch 65/2094\n",
      " - 22s - loss: 2269.8809 - val_loss: 3076.3943\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00065: loss did not improve from 2159.86615\n",
      "Epoch 66/2094\n",
      " - 22s - loss: 2284.5985 - val_loss: 2765.1370\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1917.02393\n",
      "Epoch 67/2094\n",
      " - 22s - loss: 2260.1716 - val_loss: 2265.1482\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00067: loss did not improve from 2159.86615\n",
      "Epoch 68/2094\n",
      " - 22s - loss: 2264.4471 - val_loss: 2219.5984\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1917.02393\n",
      "Epoch 69/2094\n",
      " - 22s - loss: 2318.7509 - val_loss: 2141.1492\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00069: loss did not improve from 2159.86615\n",
      "Epoch 70/2094\n",
      " - 23s - loss: 2241.0339 - val_loss: 2013.1469\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1917.02393\n",
      "Epoch 71/2094\n",
      " - 22s - loss: 2280.1742 - val_loss: 1955.1520\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00071: loss did not improve from 2159.86615\n",
      "Epoch 72/2094\n",
      " - 22s - loss: 2274.2364 - val_loss: 1946.6115\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1917.02393\n",
      "Epoch 73/2094\n",
      " - 22s - loss: 2295.9027 - val_loss: 2233.3684\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00073: loss did not improve from 2159.86615\n",
      "Epoch 74/2094\n",
      " - 22s - loss: 2345.2036 - val_loss: 1980.7505\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1917.02393\n",
      "Epoch 75/2094\n",
      " - 22s - loss: 2303.0962 - val_loss: 2624.8979\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00075: loss did not improve from 2159.86615\n",
      "Epoch 76/2094\n",
      " - 22s - loss: 2261.5895 - val_loss: 2095.5198\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1917.02393\n",
      "Epoch 77/2094\n",
      " - 22s - loss: 2258.9860 - val_loss: 2062.6184\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00077: loss did not improve from 2159.86615\n",
      "Epoch 78/2094\n",
      " - 22s - loss: 2270.9761 - val_loss: 3190.0559\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1917.02393\n",
      "Epoch 79/2094\n",
      " - 22s - loss: 2241.1938 - val_loss: 2085.1143\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00079: loss did not improve from 2159.86615\n",
      "Epoch 80/2094\n",
      " - 22s - loss: 2256.1553 - val_loss: 2356.4412\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1917.02393\n",
      "Epoch 81/2094\n",
      " - 22s - loss: 2256.8499 - val_loss: 3034.0771\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00081: loss did not improve from 2159.86615\n",
      "Epoch 82/2094\n",
      " - 22s - loss: 2311.1712 - val_loss: 1994.5217\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1917.02393\n",
      "Epoch 83/2094\n",
      " - 22s - loss: 2290.6208 - val_loss: 2222.4917\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00083: loss did not improve from 2159.86615\n",
      "Epoch 84/2094\n",
      " - 23s - loss: 2239.4508 - val_loss: 2009.2646\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1917.02393\n",
      "Epoch 85/2094\n",
      " - 22s - loss: 2318.8059 - val_loss: 2221.5693\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00085: loss did not improve from 2159.86615\n",
      "Epoch 86/2094\n",
      " - 22s - loss: 2281.4545 - val_loss: 2546.9529\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1917.02393\n",
      "Epoch 87/2094\n",
      " - 22s - loss: 2320.5074 - val_loss: 2195.9751\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00087: loss did not improve from 2159.86615\n",
      "Epoch 88/2094\n",
      " - 22s - loss: 2254.0022 - val_loss: 2135.0923\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1917.02393\n",
      "Epoch 89/2094\n",
      " - 22s - loss: 2262.5849 - val_loss: 1966.5869\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00089: loss did not improve from 2159.86615\n",
      "Epoch 90/2094\n",
      " - 22s - loss: 2212.6979 - val_loss: 2112.2034\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1917.02393\n",
      "Epoch 91/2094\n",
      " - 22s - loss: 2336.9984 - val_loss: 2154.0254\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00091: loss did not improve from 2159.86615\n",
      "Epoch 92/2094\n",
      " - 22s - loss: 2341.3017 - val_loss: 2016.4086\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1917.02393\n",
      "Epoch 93/2094\n",
      " - 22s - loss: 2235.5933 - val_loss: 2049.6238\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00093: loss did not improve from 2159.86615\n",
      "Epoch 94/2094\n",
      " - 22s - loss: 2207.4261 - val_loss: 2728.6050\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1917.02393\n",
      "Epoch 95/2094\n",
      " - 22s - loss: 2268.4534 - val_loss: 2074.4011\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00095: loss did not improve from 2159.86615\n",
      "Epoch 96/2094\n",
      " - 22s - loss: 2229.5621 - val_loss: 2633.1990\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1917.02393\n",
      "Epoch 97/2094\n",
      " - 22s - loss: 2337.8312 - val_loss: 2099.0144\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00097: loss did not improve from 2159.86615\n",
      "Epoch 98/2094\n",
      " - 23s - loss: 2245.7037 - val_loss: 2048.6589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: val_loss did not improve from 1917.02393\n",
      "Epoch 99/2094\n",
      " - 22s - loss: 2207.0793 - val_loss: 2527.7214\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00099: loss did not improve from 2159.86615\n",
      "Epoch 100/2094\n",
      "Batch 30: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1917.02393\n",
      "\n",
      "Time 9043.24456501007\n",
      "Super-epoch 9 - learn rate: 0.000125\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2240.8079 - val_loss: 2256.8972\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2290.2575 - val_loss: 2031.0081\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1917.02393\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2256.6622 - val_loss: 2480.9246\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2282.9150 - val_loss: 2066.1113\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1917.02393\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2340.3071 - val_loss: 2551.4062\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2302.5124 - val_loss: 1956.8116\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1917.02393\n",
      "Epoch 7/2094\n",
      "Batch 32: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9212.033174037933\n",
      "Super-epoch 10 - learn rate: 7.874506561842957e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2274.0428 - val_loss: 1957.8796\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1917.02393\n",
      "Epoch 2/2094\n",
      "Batch 10: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9265.666200876236\n",
      "Super-epoch 11 - learn rate: 7.874506561842957e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2368.9091 - val_loss: 2155.6775\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1917.02393\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2245.1249 - val_loss: 2845.8145\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2209.3382 - val_loss: 2674.2471\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1917.02393\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2259.9269 - val_loss: 2861.5530\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2244.9969 - val_loss: 2326.4226\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1917.02393\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2298.9085 - val_loss: 2242.2334\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2292.6215 - val_loss: 2015.7244\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1917.02393\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2217.1451 - val_loss: 2175.7156\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2226.6899 - val_loss: 2041.8149\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1917.02393\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2211.4747 - val_loss: 2101.6313\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2285.3108 - val_loss: 2010.7076\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1917.02393\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2264.3057 - val_loss: 3712.8633\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2160.9844 - val_loss: 2439.7573\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1917.02393\n",
      "Epoch 14/2094\n",
      "Batch 13: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9587.10349369049\n",
      "Super-epoch 12 - learn rate: 7.874506561842957e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2267.4392 - val_loss: 2149.4600\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1917.02393\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2229.3710 - val_loss: 2299.2126\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2388.9050 - val_loss: 3261.6138\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1917.02393\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2352.8671 - val_loss: 1977.9467\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2329.5221 - val_loss: 2234.3289\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1917.02393\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2307.9049 - val_loss: 2071.5066\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2357.9584 - val_loss: 1999.8247\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1917.02393\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2330.2261 - val_loss: 2423.2844\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2400.9189 - val_loss: 2557.7566\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1917.02393\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2312.7791 - val_loss: 2054.1638\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2296.0275 - val_loss: 2104.7917\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1917.02393\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2363.4498 - val_loss: 2177.1008\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2387.0666 - val_loss: 2103.3159\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1917.02393\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2270.2499 - val_loss: 2274.7307\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2351.4926 - val_loss: 2543.4265\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1917.02393\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2394.4758 - val_loss: 2116.4873\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00016: loss did not improve from 2159.86615\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2257.3094 - val_loss: 2764.2896\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1917.02393\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2422.5895 - val_loss: 2104.4517\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00018: loss did not improve from 2159.86615\n",
      "Epoch 19/2094\n",
      "Batch 9: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1917.02393\n",
      "Learn rate decayed\n",
      "\n",
      "Time 10021.936568498611\n",
      "Super-epoch 13 - learn rate: 4.9606282874006234e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2288.8851 - val_loss: 2426.8191\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2412.1601 - val_loss: 2260.6619\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1917.02393\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2245.3252 - val_loss: 2032.5959\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2391.5010 - val_loss: 1992.8966\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1917.02393\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2331.2202 - val_loss: 3011.2607\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2362.5922 - val_loss: 1982.6906\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1917.02393\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2293.7191 - val_loss: 2206.9312\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Epoch 8/2094\n",
      " - 23s - loss: 2330.0619 - val_loss: 2197.5608\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1917.02393\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2245.8236 - val_loss: 2368.7151\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00009: loss did not improve from 2159.86615\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2311.3900 - val_loss: 2362.0623\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1917.02393\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2283.0737 - val_loss: 2390.8777\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1917.02393\n",
      "\n",
      "Epoch 00011: loss did not improve from 2159.86615\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2427.7191 - val_loss: 2092.3535\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1917.02393\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2232.6539 - val_loss: 1874.6763\n",
      "\n",
      "Epoch 00013: val_loss improved from 1917.02393 to 1874.67627, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00013: loss did not improve from 2159.86615\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2220.3587 - val_loss: 2779.1797\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1874.67627\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2298.4030 - val_loss: 2173.9878\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00015: loss did not improve from 2159.86615\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2344.8576 - val_loss: 2586.1165\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1874.67627\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2293.9579 - val_loss: 2877.5400\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00017: loss did not improve from 2159.86615\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2346.0770 - val_loss: 2354.3042\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1874.67627\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2251.3416 - val_loss: 2030.5641\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00019: loss did not improve from 2159.86615\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2204.8346 - val_loss: 1999.9303\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1874.67627\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2225.2165 - val_loss: 2002.3196\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00021: loss did not improve from 2159.86615\n",
      "Epoch 22/2094\n",
      " - 23s - loss: 2250.5737 - val_loss: 2069.9841\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1874.67627\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2234.2298 - val_loss: 2166.6865\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00023: loss did not improve from 2159.86615\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2303.0934 - val_loss: 2183.3259\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1874.67627\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2289.7094 - val_loss: 2792.1775\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00025: loss did not improve from 2159.86615\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2209.5392 - val_loss: 1971.6594\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1874.67627\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2301.7929 - val_loss: 1995.3898\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00027: loss did not improve from 2159.86615\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2286.3932 - val_loss: 1974.9858\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1874.67627\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2309.4444 - val_loss: 2224.9114\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00029: loss did not improve from 2159.86615\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2229.2294 - val_loss: 2032.7167\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1874.67627\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2364.8646 - val_loss: 2667.7686\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00031: loss did not improve from 2159.86615\n",
      "Epoch 32/2094\n",
      "Batch 44: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1874.67627\n",
      "\n",
      "Time 10753.777448654175\n",
      "Super-epoch 14 - learn rate: 4.9606282874006234e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2308.0981 - val_loss: 2148.3640\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2254.9887 - val_loss: 2973.7441\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1874.67627\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2207.2606 - val_loss: 2223.1431\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2233.9194 - val_loss: 2860.8435\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1874.67627\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2189.7753 - val_loss: 2008.9778\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2300.1470 - val_loss: 2146.7266\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1874.67627\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2219.9094 - val_loss: 2057.1287\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2263.0983 - val_loss: 2089.3733\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1874.67627\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2217.3847 - val_loss: 2067.4319\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00009: loss did not improve from 2159.86615\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2364.9433 - val_loss: 2116.1465\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1874.67627\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2316.9558 - val_loss: 2078.1086\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00011: loss did not improve from 2159.86615\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2239.5874 - val_loss: 2986.7185\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1874.67627\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2255.6504 - val_loss: 2269.3828\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00013: loss did not improve from 2159.86615\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2264.7451 - val_loss: 2033.2123\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1874.67627\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2342.3251 - val_loss: 2009.1869\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00015: loss did not improve from 2159.86615\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2263.1649 - val_loss: 2072.7598\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1874.67627\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2269.6289 - val_loss: 2264.7500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00017: loss did not improve from 2159.86615\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2327.8966 - val_loss: 2750.0076\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1874.67627\n",
      "Epoch 19/2094\n",
      " - 23s - loss: 2220.8804 - val_loss: 2273.2644\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00019: loss did not improve from 2159.86615\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2345.9193 - val_loss: 2118.9260\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1874.67627\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2240.0371 - val_loss: 1931.4404\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00021: loss did not improve from 2159.86615\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2257.2785 - val_loss: 2453.2825\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1874.67627\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2291.1621 - val_loss: 2212.0342\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00023: loss did not improve from 2159.86615\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2341.9452 - val_loss: 2958.7988\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1874.67627\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2255.6396 - val_loss: 1995.3531\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00025: loss did not improve from 2159.86615\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2253.5181 - val_loss: 2134.0955\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1874.67627\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2276.3362 - val_loss: 2033.5786\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00027: loss did not improve from 2159.86615\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2331.3665 - val_loss: 2434.0112\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1874.67627\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2300.7854 - val_loss: 1971.1495\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00029: loss did not improve from 2159.86615\n",
      "Epoch 30/2094\n",
      " - 23s - loss: 2283.4283 - val_loss: 1957.8372\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1874.67627\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2373.7209 - val_loss: 1953.8376\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00031: loss did not improve from 2159.86615\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2322.2764 - val_loss: 2640.4580\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1874.67627\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2368.5714 - val_loss: 2115.3481\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00033: loss did not improve from 2159.86615\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2276.8805 - val_loss: 2164.7178\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1874.67627\n",
      "Epoch 35/2094\n",
      " - 22s - loss: 2321.7746 - val_loss: 2160.6895\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00035: loss did not improve from 2159.86615\n",
      "Epoch 36/2094\n",
      " - 22s - loss: 2257.7162 - val_loss: 2420.4031\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1874.67627\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2333.4036 - val_loss: 2005.4048\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00037: loss did not improve from 2159.86615\n",
      "Epoch 38/2094\n",
      " - 22s - loss: 2273.3657 - val_loss: 1975.9817\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1874.67627\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2402.1709 - val_loss: 3151.7913\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00039: loss did not improve from 2159.86615\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2303.3758 - val_loss: 2032.7692\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1874.67627\n",
      "Epoch 41/2094\n",
      " - 22s - loss: 2255.0977 - val_loss: 2181.2266\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00041: loss did not improve from 2159.86615\n",
      "Epoch 42/2094\n",
      " - 22s - loss: 2323.0178 - val_loss: 2016.9398\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1874.67627\n",
      "Epoch 43/2094\n",
      " - 22s - loss: 2401.5584 - val_loss: 3549.8804\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00043: loss did not improve from 2159.86615\n",
      "Epoch 44/2094\n",
      " - 23s - loss: 2326.9288 - val_loss: 2998.0105\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1874.67627\n",
      "Epoch 45/2094\n",
      " - 22s - loss: 2360.9537 - val_loss: 2187.5112\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00045: loss did not improve from 2159.86615\n",
      "Epoch 46/2094\n",
      " - 22s - loss: 2305.9681 - val_loss: 3052.9202\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1874.67627\n",
      "Epoch 47/2094\n",
      " - 22s - loss: 2349.8938 - val_loss: 2035.4500\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00047: loss did not improve from 2159.86615\n",
      "Epoch 48/2094\n",
      " - 22s - loss: 2319.2331 - val_loss: 2106.4890\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1874.67627\n",
      "Epoch 49/2094\n",
      " - 22s - loss: 2298.7517 - val_loss: 2998.4719\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00049: loss did not improve from 2159.86615\n",
      "Epoch 50/2094\n",
      " - 22s - loss: 2310.9466 - val_loss: 1975.7968\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1874.67627\n",
      "Epoch 51/2094\n",
      " - 22s - loss: 2336.1959 - val_loss: 2398.8882\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00051: loss did not improve from 2159.86615\n",
      "Epoch 52/2094\n",
      " - 22s - loss: 2387.6529 - val_loss: 2507.8455\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1874.67627\n",
      "Epoch 53/2094\n",
      " - 22s - loss: 2344.9992 - val_loss: 2123.4858\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00053: loss did not improve from 2159.86615\n",
      "Epoch 54/2094\n",
      " - 22s - loss: 2332.5727 - val_loss: 2004.7841\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1874.67627\n",
      "Epoch 55/2094\n",
      " - 22s - loss: 2264.7591 - val_loss: 1959.3932\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00055: loss did not improve from 2159.86615\n",
      "Epoch 56/2094\n",
      " - 22s - loss: 2313.5721 - val_loss: 2223.6995\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1874.67627\n",
      "Epoch 57/2094\n",
      " - 22s - loss: 2339.5301 - val_loss: 2155.8257\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00057: loss did not improve from 2159.86615\n",
      "Epoch 58/2094\n",
      " - 23s - loss: 2418.3480 - val_loss: 2143.3652\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1874.67627\n",
      "Epoch 59/2094\n",
      " - 22s - loss: 2354.4150 - val_loss: 2020.7875\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00059: loss did not improve from 2159.86615\n",
      "Epoch 60/2094\n",
      " - 22s - loss: 2259.4427 - val_loss: 2122.2673\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1874.67627\n",
      "Epoch 61/2094\n",
      " - 22s - loss: 2316.9829 - val_loss: 2512.5378\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00061: loss did not improve from 2159.86615\n",
      "Epoch 62/2094\n",
      " - 22s - loss: 2363.5075 - val_loss: 3115.6821\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1874.67627\n",
      "Epoch 63/2094\n",
      " - 22s - loss: 2305.1319 - val_loss: 2307.9180\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00063: loss did not improve from 2159.86615\n",
      "Epoch 64/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2325.2429 - val_loss: 2050.6541\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1874.67627\n",
      "Epoch 65/2094\n",
      " - 22s - loss: 2338.6109 - val_loss: 2594.5693\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00065: loss did not improve from 2159.86615\n",
      "Epoch 66/2094\n",
      " - 22s - loss: 2287.2835 - val_loss: 2641.5554\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1874.67627\n",
      "Epoch 67/2094\n",
      " - 22s - loss: 2268.2506 - val_loss: 1954.0857\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00067: loss did not improve from 2159.86615\n",
      "Epoch 68/2094\n",
      " - 22s - loss: 2283.3727 - val_loss: 2269.5642\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1874.67627\n",
      "Epoch 69/2094\n",
      " - 22s - loss: 2263.4806 - val_loss: 2044.6333\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00069: loss did not improve from 2159.86615\n",
      "Epoch 70/2094\n",
      " - 22s - loss: 2319.6064 - val_loss: 2572.4084\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1874.67627\n",
      "Epoch 71/2094\n",
      "Batch 37: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00071: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 12341.494601726532\n",
      "Super-epoch 15 - learn rate: 4.9606282874006234e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2343.4771 - val_loss: 2247.3665\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1874.67627\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2256.2952 - val_loss: 2164.6709\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2269.1001 - val_loss: 2207.7881\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1874.67627\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2257.9236 - val_loss: 2187.3870\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1874.67627\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      "Batch 7: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1874.67627\n",
      "\n",
      "Time 12472.322889566422\n",
      "Super-epoch 16 - learn rate: 4.9606282874006234e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2293.4290 - val_loss: 1860.4299\n",
      "\n",
      "Epoch 00001: val_loss improved from 1874.67627 to 1860.42993, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2215.9514 - val_loss: 2372.8655\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1860.42993\n",
      "Epoch 3/2094\n",
      "Batch 41: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 12570.881450653076\n",
      "Super-epoch 17 - learn rate: 3.125e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2195.7902 - val_loss: 2150.5781\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1860.42993\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2273.1482 - val_loss: 1890.0879\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2211.4412 - val_loss: 1957.9774\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1860.42993\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2323.6474 - val_loss: 2057.3816\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2251.9392 - val_loss: 2179.6628\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1860.42993\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2251.9860 - val_loss: 2062.1018\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2299.6405 - val_loss: 2153.2812\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1860.42993\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2319.2830 - val_loss: 2187.3447\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2277.3231 - val_loss: 1946.5557\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1860.42993\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2164.7808 - val_loss: 2376.9343\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2292.1258 - val_loss: 2324.5178\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1860.42993\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2260.3784 - val_loss: 1960.1829\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2284.2139 - val_loss: 2172.9197\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1860.42993\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2329.2130 - val_loss: 2050.8086\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2313.5954 - val_loss: 1973.5719\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1860.42993\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2222.8502 - val_loss: 1894.8190\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00016: loss did not improve from 2159.86615\n",
      "Epoch 17/2094\n",
      "Batch 29: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1860.42993\n",
      "Learn rate decayed\n",
      "\n",
      "Time 12979.088108062744\n",
      "Super-epoch 18 - learn rate: 1.9686266404607393e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2244.7062 - val_loss: 2193.9919\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1860.42993\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      "Batch 51: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1860.42993\n",
      "Learn rate decayed\n",
      "\n",
      "Time 13062.666189432144\n",
      "Super-epoch 19 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2368.5632 - val_loss: 1859.3291\n",
      "\n",
      "Epoch 00001: val_loss improved from 1860.42993 to 1859.32910, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2357.5083 - val_loss: 2246.3999\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2279.9722 - val_loss: 2581.8430\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 24s - loss: 2255.0879 - val_loss: 2103.1536\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2277.2193 - val_loss: 2025.7643\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2219.0693 - val_loss: 1895.6139\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2194.8896 - val_loss: 1935.5408\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Epoch 8/2094\n",
      " - 23s - loss: 2284.1415 - val_loss: 2250.7595\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2308.3396 - val_loss: 2209.3118\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00009: loss did not improve from 2159.86615\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2271.2103 - val_loss: 3571.4336\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2236.1284 - val_loss: 2070.8918\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00011: loss did not improve from 2159.86615\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2275.2610 - val_loss: 1985.5254\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2210.3993 - val_loss: 2076.9912\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00013: loss did not improve from 2159.86615\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2299.8865 - val_loss: 2413.3992\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2269.4770 - val_loss: 2023.2361\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00015: loss did not improve from 2159.86615\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2317.4282 - val_loss: 2176.1460\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1859.32910\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2294.2416 - val_loss: 2106.9233\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00017: loss did not improve from 2159.86615\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2359.9616 - val_loss: 2472.0012\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1859.32910\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2340.2790 - val_loss: 2360.3979\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00019: loss did not improve from 2159.86615\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2218.6060 - val_loss: 2179.9612\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1859.32910\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2259.9341 - val_loss: 2336.0454\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00021: loss did not improve from 2159.86615\n",
      "Epoch 22/2094\n",
      " - 23s - loss: 2305.8844 - val_loss: 2014.7140\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1859.32910\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2270.8555 - val_loss: 2364.1299\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00023: loss did not improve from 2159.86615\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2252.9820 - val_loss: 2417.8096\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1859.32910\n",
      "Epoch 25/2094\n",
      " - 23s - loss: 2321.2111 - val_loss: 2181.9026\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00025: loss did not improve from 2159.86615\n",
      "Epoch 26/2094\n",
      " - 23s - loss: 2308.7603 - val_loss: 2020.7274\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1859.32910\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2266.4822 - val_loss: 1950.7115\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00027: loss did not improve from 2159.86615\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2292.3759 - val_loss: 2856.8066\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1859.32910\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2248.6433 - val_loss: 2170.6414\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00029: loss did not improve from 2159.86615\n",
      "Epoch 30/2094\n",
      " - 23s - loss: 2310.0357 - val_loss: 3099.3652\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1859.32910\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2262.8808 - val_loss: 2530.5938\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00031: loss did not improve from 2159.86615\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2248.5525 - val_loss: 1895.4064\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1859.32910\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2257.8137 - val_loss: 2207.7698\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00033: loss did not improve from 2159.86615\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2281.8443 - val_loss: 2059.1948\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1859.32910\n",
      "Epoch 35/2094\n",
      " - 23s - loss: 2274.2326 - val_loss: 2555.8184\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00035: loss did not improve from 2159.86615\n",
      "Epoch 36/2094\n",
      " - 23s - loss: 2220.8236 - val_loss: 1966.1227\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1859.32910\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2396.4812 - val_loss: 2306.0164\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00037: loss did not improve from 2159.86615\n",
      "Epoch 38/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2308.5446 - val_loss: 2205.8923\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1859.32910\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2221.5533 - val_loss: 1955.2169\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00039: loss did not improve from 2159.86615\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2339.6805 - val_loss: 2018.7987\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1859.32910\n",
      "Epoch 41/2094\n",
      " - 22s - loss: 2337.5291 - val_loss: 1963.7163\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00041: loss did not improve from 2159.86615\n",
      "Epoch 42/2094\n",
      " - 22s - loss: 2308.0505 - val_loss: 2674.3440\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1859.32910\n",
      "Epoch 43/2094\n",
      " - 22s - loss: 2229.2073 - val_loss: 2122.1406\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00043: loss did not improve from 2159.86615\n",
      "Epoch 44/2094\n",
      " - 22s - loss: 2334.6583 - val_loss: 2114.9414\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1859.32910\n",
      "Epoch 45/2094\n",
      " - 23s - loss: 2243.1145 - val_loss: 2415.5657\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00045: loss did not improve from 2159.86615\n",
      "Epoch 46/2094\n",
      " - 22s - loss: 2247.4901 - val_loss: 1982.9108\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1859.32910\n",
      "Epoch 47/2094\n",
      " - 22s - loss: 2322.5523 - val_loss: 2138.0457\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00047: loss did not improve from 2159.86615\n",
      "Epoch 48/2094\n",
      " - 22s - loss: 2268.6814 - val_loss: 2381.2996\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1859.32910\n",
      "Epoch 49/2094\n",
      " - 23s - loss: 2252.7624 - val_loss: 2249.7505\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00049: loss did not improve from 2159.86615\n",
      "Epoch 50/2094\n",
      " - 22s - loss: 2319.7814 - val_loss: 2030.1218\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1859.32910\n",
      "Epoch 51/2094\n",
      " - 23s - loss: 2317.2058 - val_loss: 2041.5593\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00051: loss did not improve from 2159.86615\n",
      "Epoch 52/2094\n",
      " - 22s - loss: 2277.0545 - val_loss: 2015.1837\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1859.32910\n",
      "Epoch 53/2094\n",
      " - 23s - loss: 2323.9764 - val_loss: 2047.6155\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00053: loss did not improve from 2159.86615\n",
      "Epoch 54/2094\n",
      " - 22s - loss: 2263.6404 - val_loss: 2275.9258\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1859.32910\n",
      "Epoch 55/2094\n",
      " - 22s - loss: 2340.4064 - val_loss: 2468.6899\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00055: loss did not improve from 2159.86615\n",
      "Epoch 56/2094\n",
      " - 22s - loss: 2276.0126 - val_loss: 2171.8657\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1859.32910\n",
      "Epoch 57/2094\n",
      " - 22s - loss: 2237.4309 - val_loss: 1981.7992\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00057: loss did not improve from 2159.86615\n",
      "Epoch 58/2094\n",
      " - 22s - loss: 2322.7547 - val_loss: 1984.9226\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1859.32910\n",
      "Epoch 59/2094\n",
      " - 22s - loss: 2245.7957 - val_loss: 2914.8525\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00059: loss did not improve from 2159.86615\n",
      "Epoch 60/2094\n",
      " - 23s - loss: 2274.2934 - val_loss: 2074.7407\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1859.32910\n",
      "Epoch 61/2094\n",
      " - 22s - loss: 2272.6741 - val_loss: 2555.9431\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00061: loss did not improve from 2159.86615\n",
      "Epoch 62/2094\n",
      " - 23s - loss: 2350.4092 - val_loss: 2086.2583\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1859.32910\n",
      "Epoch 63/2094\n",
      " - 23s - loss: 2300.3421 - val_loss: 1999.4153\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00063: loss did not improve from 2159.86615\n",
      "Epoch 64/2094\n",
      " - 22s - loss: 2228.3709 - val_loss: 2263.7478\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1859.32910\n",
      "Epoch 65/2094\n",
      " - 22s - loss: 2306.2006 - val_loss: 1994.0211\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00065: loss did not improve from 2159.86615\n",
      "Epoch 66/2094\n",
      " - 22s - loss: 2260.4244 - val_loss: 2336.4717\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1859.32910\n",
      "Epoch 67/2094\n",
      " - 22s - loss: 2211.7012 - val_loss: 2026.4218\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00067: loss did not improve from 2159.86615\n",
      "Epoch 68/2094\n",
      " - 23s - loss: 2306.5274 - val_loss: 2075.1729\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1859.32910\n",
      "Epoch 69/2094\n",
      " - 22s - loss: 2216.3467 - val_loss: 1965.0939\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00069: loss did not improve from 2159.86615\n",
      "Epoch 70/2094\n",
      " - 22s - loss: 2327.4178 - val_loss: 1969.9882\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1859.32910\n",
      "Epoch 71/2094\n",
      " - 23s - loss: 2300.2958 - val_loss: 2058.4219\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00071: loss did not improve from 2159.86615\n",
      "Epoch 72/2094\n",
      " - 22s - loss: 2228.5718 - val_loss: 2000.2902\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1859.32910\n",
      "Epoch 73/2094\n",
      " - 22s - loss: 2296.3845 - val_loss: 2259.0161\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00073: loss did not improve from 2159.86615\n",
      "Epoch 74/2094\n",
      " - 22s - loss: 2377.9969 - val_loss: 2140.2893\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1859.32910\n",
      "Epoch 75/2094\n",
      " - 22s - loss: 2169.7531 - val_loss: 2609.0974\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00075: loss did not improve from 2159.86615\n",
      "Epoch 76/2094\n",
      " - 23s - loss: 2303.7749 - val_loss: 2176.9126\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1859.32910\n",
      "Epoch 77/2094\n",
      " - 22s - loss: 2192.2553 - val_loss: 2555.7429\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00077: loss did not improve from 2159.86615\n",
      "Epoch 78/2094\n",
      " - 22s - loss: 2249.2976 - val_loss: 2242.4619\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1859.32910\n",
      "Epoch 79/2094\n",
      " - 22s - loss: 2347.7096 - val_loss: 2122.8965\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00079: loss did not improve from 2159.86615\n",
      "Epoch 80/2094\n",
      " - 23s - loss: 2204.2897 - val_loss: 2115.9624\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1859.32910\n",
      "Epoch 81/2094\n",
      " - 23s - loss: 2282.9448 - val_loss: 2082.7788\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00081: loss did not improve from 2159.86615\n",
      "Epoch 82/2094\n",
      " - 22s - loss: 2291.0045 - val_loss: 1899.6920\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1859.32910\n",
      "Epoch 83/2094\n",
      " - 22s - loss: 2309.5493 - val_loss: 2016.3010\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00083: loss did not improve from 2159.86615\n",
      "Epoch 84/2094\n",
      " - 22s - loss: 2374.4282 - val_loss: 2097.6243\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1859.32910\n",
      "Epoch 85/2094\n",
      " - 22s - loss: 2309.0450 - val_loss: 1965.6482\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00085: loss did not improve from 2159.86615\n",
      "Epoch 86/2094\n",
      " - 22s - loss: 2244.9832 - val_loss: 2165.4392\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1859.32910\n",
      "Epoch 87/2094\n",
      " - 22s - loss: 2327.3666 - val_loss: 2553.6265\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00087: loss did not improve from 2159.86615\n",
      "Epoch 88/2094\n",
      " - 22s - loss: 2300.9402 - val_loss: 1978.3643\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1859.32910\n",
      "Epoch 89/2094\n",
      " - 22s - loss: 2285.3042 - val_loss: 2082.2278\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00089: loss did not improve from 2159.86615\n",
      "Epoch 90/2094\n",
      " - 23s - loss: 2224.8302 - val_loss: 2835.6296\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1859.32910\n",
      "Epoch 91/2094\n",
      " - 22s - loss: 2327.0047 - val_loss: 2269.4666\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00091: loss did not improve from 2159.86615\n",
      "Epoch 92/2094\n",
      " - 22s - loss: 2222.8598 - val_loss: 3212.8511\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1859.32910\n",
      "Epoch 93/2094\n",
      " - 22s - loss: 2282.2971 - val_loss: 2053.9895\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00093: loss did not improve from 2159.86615\n",
      "Epoch 94/2094\n",
      " - 22s - loss: 2226.6977 - val_loss: 2390.4756\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1859.32910\n",
      "Epoch 95/2094\n",
      " - 22s - loss: 2260.9618 - val_loss: 2732.5378\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00095: loss did not improve from 2159.86615\n",
      "Epoch 96/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 22s - loss: 2316.4487 - val_loss: 2040.1622\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1859.32910\n",
      "Epoch 97/2094\n",
      " - 22s - loss: 2237.9751 - val_loss: 2244.8975\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00097: loss did not improve from 2159.86615\n",
      "Epoch 98/2094\n",
      " - 23s - loss: 2233.2696 - val_loss: 2366.4155\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1859.32910\n",
      "Epoch 99/2094\n",
      " - 22s - loss: 2261.7216 - val_loss: 1949.6470\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00099: loss did not improve from 2159.86615\n",
      "Epoch 100/2094\n",
      " - 22s - loss: 2195.5727 - val_loss: 2834.5569\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1859.32910\n",
      "Epoch 101/2094\n",
      " - 22s - loss: 2389.2546 - val_loss: 2088.8333\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00101: loss did not improve from 2159.86615\n",
      "Epoch 102/2094\n",
      " - 22s - loss: 2352.4911 - val_loss: 2078.6108\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1859.32910\n",
      "Epoch 103/2094\n",
      " - 23s - loss: 2223.4123 - val_loss: 2139.6272\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00103: loss did not improve from 2159.86615\n",
      "Epoch 104/2094\n",
      " - 23s - loss: 2216.4845 - val_loss: 2047.8685\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1859.32910\n",
      "Epoch 105/2094\n",
      " - 22s - loss: 2268.5497 - val_loss: 2012.6329\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00105: loss did not improve from 2159.86615\n",
      "Epoch 106/2094\n",
      " - 22s - loss: 2255.9231 - val_loss: 2024.9991\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1859.32910\n",
      "Epoch 107/2094\n",
      " - 22s - loss: 2291.4889 - val_loss: 2516.8413\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00107: loss did not improve from 2159.86615\n",
      "Epoch 108/2094\n",
      " - 22s - loss: 2271.0835 - val_loss: 2094.5701\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1859.32910\n",
      "Epoch 109/2094\n",
      " - 22s - loss: 2279.9569 - val_loss: 2005.0995\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00109: loss did not improve from 2159.86615\n",
      "Epoch 110/2094\n",
      " - 22s - loss: 2254.5269 - val_loss: 2392.5740\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1859.32910\n",
      "Epoch 111/2094\n",
      " - 22s - loss: 2250.7375 - val_loss: 2652.9580\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00111: loss did not improve from 2159.86615\n",
      "Epoch 112/2094\n",
      " - 22s - loss: 2305.1968 - val_loss: 2025.1193\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1859.32910\n",
      "Epoch 113/2094\n",
      " - 22s - loss: 2244.8270 - val_loss: 2778.7424\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00113: loss did not improve from 2159.86615\n",
      "Epoch 114/2094\n",
      " - 22s - loss: 2248.1197 - val_loss: 2090.9473\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1859.32910\n",
      "Epoch 115/2094\n",
      " - 22s - loss: 2304.5480 - val_loss: 2507.5649\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00115: loss did not improve from 2159.86615\n",
      "Epoch 116/2094\n",
      " - 22s - loss: 2299.4306 - val_loss: 2361.9197\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1859.32910\n",
      "Epoch 117/2094\n",
      " - 23s - loss: 2245.0810 - val_loss: 2878.0889\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00117: loss did not improve from 2159.86615\n",
      "Epoch 118/2094\n",
      " - 22s - loss: 2283.7918 - val_loss: 2073.7078\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1859.32910\n",
      "Epoch 119/2094\n",
      " - 22s - loss: 2324.4446 - val_loss: 2562.6370\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00119: loss did not improve from 2159.86615\n",
      "Epoch 120/2094\n",
      " - 22s - loss: 2212.9712 - val_loss: 3227.8501\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1859.32910\n",
      "Epoch 121/2094\n",
      " - 22s - loss: 2213.1713 - val_loss: 2394.0403\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00121: loss did not improve from 2159.86615\n",
      "Epoch 122/2094\n",
      " - 22s - loss: 2319.5042 - val_loss: 3095.4460\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1859.32910\n",
      "Epoch 123/2094\n",
      " - 22s - loss: 2314.2874 - val_loss: 2183.1851\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00123: loss did not improve from 2159.86615\n",
      "Epoch 124/2094\n",
      " - 22s - loss: 2350.5762 - val_loss: 2564.9766\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1859.32910\n",
      "Epoch 125/2094\n",
      " - 22s - loss: 2290.4488 - val_loss: 2540.6809\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00125: loss did not improve from 2159.86615\n",
      "Epoch 126/2094\n",
      " - 22s - loss: 2209.4442 - val_loss: 2156.7104\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1859.32910\n",
      "Epoch 127/2094\n",
      " - 22s - loss: 2328.3778 - val_loss: 2110.5974\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00127: loss did not improve from 2159.86615\n",
      "Epoch 128/2094\n",
      " - 22s - loss: 2347.6118 - val_loss: 2191.9607\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1859.32910\n",
      "Epoch 129/2094\n",
      " - 22s - loss: 2292.0410 - val_loss: 2104.2004\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00129: loss did not improve from 2159.86615\n",
      "Epoch 130/2094\n",
      " - 22s - loss: 2251.3502 - val_loss: 2519.8162\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1859.32910\n",
      "Epoch 131/2094\n",
      " - 23s - loss: 2266.7247 - val_loss: 2732.0791\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00131: loss did not improve from 2159.86615\n",
      "Epoch 132/2094\n",
      " - 22s - loss: 2310.7932 - val_loss: 2115.5735\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 1859.32910\n",
      "Epoch 133/2094\n",
      " - 22s - loss: 2277.2764 - val_loss: 2003.9786\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00133: loss did not improve from 2159.86615\n",
      "Epoch 134/2094\n",
      " - 22s - loss: 2263.1514 - val_loss: 2598.8652\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 1859.32910\n",
      "Epoch 135/2094\n",
      " - 22s - loss: 2321.6721 - val_loss: 2070.2183\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00135: loss did not improve from 2159.86615\n",
      "Epoch 136/2094\n",
      " - 22s - loss: 2213.2165 - val_loss: 2478.9724\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 1859.32910\n",
      "Epoch 137/2094\n",
      " - 22s - loss: 2285.1826 - val_loss: 2066.3696\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00137: loss did not improve from 2159.86615\n",
      "Epoch 138/2094\n",
      " - 22s - loss: 2309.4477 - val_loss: 2112.3438\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 1859.32910\n",
      "Epoch 139/2094\n",
      " - 22s - loss: 2331.1876 - val_loss: 1954.6899\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00139: loss did not improve from 2159.86615\n",
      "Epoch 140/2094\n",
      " - 22s - loss: 2385.8694 - val_loss: 3173.2417\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 1859.32910\n",
      "Epoch 141/2094\n",
      " - 22s - loss: 2293.5099 - val_loss: 1972.7933\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00141: loss did not improve from 2159.86615\n",
      "Epoch 142/2094\n",
      " - 22s - loss: 2256.1861 - val_loss: 2436.9297\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 1859.32910\n",
      "Epoch 143/2094\n",
      " - 22s - loss: 2278.9115 - val_loss: 2108.4375\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00143: loss did not improve from 2159.86615\n",
      "Epoch 144/2094\n",
      " - 22s - loss: 2326.7186 - val_loss: 2138.1868\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 1859.32910\n",
      "Epoch 145/2094\n",
      " - 23s - loss: 2288.3804 - val_loss: 2256.0452\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00145: loss did not improve from 2159.86615\n",
      "Epoch 146/2094\n",
      " - 22s - loss: 2252.6213 - val_loss: 2030.7705\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 1859.32910\n",
      "Epoch 147/2094\n",
      " - 22s - loss: 2332.9745 - val_loss: 2045.8864\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00147: loss did not improve from 2159.86615\n",
      "Epoch 148/2094\n",
      " - 22s - loss: 2230.7124 - val_loss: 2043.7738\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 1859.32910\n",
      "Epoch 149/2094\n",
      "Batch 35: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00149: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 16433.337880134583\n",
      "Super-epoch 20 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2293.1835 - val_loss: 2094.8474\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1859.32910\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2273.2257 - val_loss: 2026.4967\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2297.7698 - val_loss: 2156.9099\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2259.7696 - val_loss: 2014.6500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 23s - loss: 2351.7449 - val_loss: 2082.8972\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2230.9232 - val_loss: 2096.4236\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2219.0500 - val_loss: 2080.9934\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "Epoch 8/2094\n",
      " - 23s - loss: 2292.3006 - val_loss: 2621.9087\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 23s - loss: 2273.4858 - val_loss: 2862.9719\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2252.6933 - val_loss: 2482.9072\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2304.8448 - val_loss: 2116.8801\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2266.7238 - val_loss: 2064.3438\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2249.6245 - val_loss: 2245.3142\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2296.4929 - val_loss: 2582.3271\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2213.9159 - val_loss: 2196.8162\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1859.32910\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2314.9765 - val_loss: 2064.5615\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00016: loss did not improve from 2159.86615\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2310.7560 - val_loss: 2284.0933\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1859.32910\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2301.7805 - val_loss: 3598.9404\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00018: loss did not improve from 2159.86615\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2332.5721 - val_loss: 2170.8752\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1859.32910\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2312.3616 - val_loss: 2603.0046\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00020: loss did not improve from 2159.86615\n",
      "Epoch 21/2094\n",
      " - 23s - loss: 2316.8685 - val_loss: 1976.5081\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1859.32910\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2236.0699 - val_loss: 2510.5239\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00022: loss did not improve from 2159.86615\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2270.8453 - val_loss: 2073.8406\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1859.32910\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2208.1596 - val_loss: 2669.4421\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00024: loss did not improve from 2159.86615\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2266.1782 - val_loss: 2432.0464\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1859.32910\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2207.3076 - val_loss: 2169.1589\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00026: loss did not improve from 2159.86615\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2256.9246 - val_loss: 2089.4309\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1859.32910\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2213.3154 - val_loss: 2560.0425\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00028: loss did not improve from 2159.86615\n",
      "Epoch 29/2094\n",
      " - 22s - loss: 2255.9698 - val_loss: 1957.9803\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1859.32910\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2328.5796 - val_loss: 2124.3521\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00030: loss did not improve from 2159.86615\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2297.3443 - val_loss: 2077.8552\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1859.32910\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2226.1587 - val_loss: 2133.8862\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00032: loss did not improve from 2159.86615\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2218.7972 - val_loss: 2090.3894\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1859.32910\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2293.1173 - val_loss: 2593.8206\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00034: loss did not improve from 2159.86615\n",
      "Epoch 35/2094\n",
      " - 23s - loss: 2235.0141 - val_loss: 2489.9014\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1859.32910\n",
      "Epoch 36/2094\n",
      " - 22s - loss: 2213.3316 - val_loss: 2324.3574\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00036: loss did not improve from 2159.86615\n",
      "Epoch 37/2094\n",
      " - 22s - loss: 2286.6717 - val_loss: 2011.3787\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1859.32910\n",
      "Epoch 38/2094\n",
      " - 22s - loss: 2290.6714 - val_loss: 1918.0833\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00038: loss did not improve from 2159.86615\n",
      "Epoch 39/2094\n",
      " - 22s - loss: 2209.8851 - val_loss: 2473.9211\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1859.32910\n",
      "Epoch 40/2094\n",
      " - 22s - loss: 2207.7020 - val_loss: 2075.8757\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00040: loss did not improve from 2159.86615\n",
      "Epoch 41/2094\n",
      " - 22s - loss: 2319.0152 - val_loss: 2115.6841\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1859.32910\n",
      "Epoch 42/2094\n",
      " - 22s - loss: 2238.1947 - val_loss: 2126.0979\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00042: loss did not improve from 2159.86615\n",
      "Epoch 43/2094\n",
      "Batch 1: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1859.32910\n",
      "\n",
      "Time 17422.68030524254\n",
      "Super-epoch 21 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2348.8511 - val_loss: 2160.4878\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2268.3951 - val_loss: 2105.9766\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2298.8204 - val_loss: 2084.3623\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2296.7128 - val_loss: 3137.4629\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2231.8097 - val_loss: 2150.6797\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2310.7317 - val_loss: 2191.2080\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2312.1255 - val_loss: 2134.4397\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2215.4235 - val_loss: 1901.6165\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2237.2453 - val_loss: 3065.7395\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00009: loss did not improve from 2159.86615\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2228.2352 - val_loss: 1861.5552\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2295.8523 - val_loss: 2281.9436\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00011: loss did not improve from 2159.86615\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2306.1104 - val_loss: 2613.8579\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2186.0064 - val_loss: 2649.9280\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00013: loss did not improve from 2159.86615\n",
      "Epoch 14/2094\n",
      "Batch 40: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "\n",
      "Time 17778.291241168976\n",
      "Super-epoch 22 - learn rate: 1.2401570718501559e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2094\n",
      " - 32s - loss: 2301.9407 - val_loss: 2023.2935\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2232.7723 - val_loss: 2141.8823\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2307.5390 - val_loss: 2165.9219\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00003: loss did not improve from 2159.86615\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2256.1972 - val_loss: 1972.8999\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "Epoch 5/2094\n",
      " - 23s - loss: 2270.7666 - val_loss: 1938.0935\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00005: loss did not improve from 2159.86615\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2306.4334 - val_loss: 2133.0305\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2284.0413 - val_loss: 2095.1604\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00007: loss did not improve from 2159.86615\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2261.7479 - val_loss: 2354.1907\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2276.8100 - val_loss: 2133.4023\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00009: loss did not improve from 2159.86615\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2252.5656 - val_loss: 2204.3777\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2260.0526 - val_loss: 1995.0887\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00011: loss did not improve from 2159.86615\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2212.1843 - val_loss: 2348.6624\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2289.2697 - val_loss: 1952.9009\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00013: loss did not improve from 2159.86615\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2255.9660 - val_loss: 2031.7272\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "Epoch 15/2094\n",
      " - 23s - loss: 2258.3704 - val_loss: 1975.6779\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00015: loss did not improve from 2159.86615\n",
      "Epoch 16/2094\n",
      " - 23s - loss: 2272.0272 - val_loss: 2071.5220\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1859.32910\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2222.5366 - val_loss: 2081.7568\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00017: loss did not improve from 2159.86615\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2215.4082 - val_loss: 2872.6658\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1859.32910\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2259.9078 - val_loss: 2140.2571\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00019: loss did not improve from 2159.86615\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2214.9976 - val_loss: 2266.4856\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1859.32910\n",
      "Epoch 21/2094\n",
      " - 22s - loss: 2260.5270 - val_loss: 2124.2637\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00021: loss did not improve from 2159.86615\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2216.2696 - val_loss: 1988.8103\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1859.32910\n",
      "Epoch 23/2094\n",
      " - 22s - loss: 2269.8566 - val_loss: 1931.8518\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00023: loss did not improve from 2159.86615\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2260.1247 - val_loss: 2726.6770\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1859.32910\n",
      "Epoch 25/2094\n",
      " - 22s - loss: 2197.0744 - val_loss: 2541.2849\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00025: loss did not improve from 2159.86615\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2283.1871 - val_loss: 2045.4395\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1859.32910\n",
      "Epoch 27/2094\n",
      " - 22s - loss: 2278.4208 - val_loss: 1940.4791\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00027: loss did not improve from 2159.86615\n",
      "Epoch 28/2094\n",
      " - 22s - loss: 2229.9831 - val_loss: 2013.0857\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1859.32910\n",
      "Epoch 29/2094\n",
      " - 23s - loss: 2199.6309 - val_loss: 2358.0408\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00029: loss did not improve from 2159.86615\n",
      "Epoch 30/2094\n",
      " - 22s - loss: 2240.3338 - val_loss: 2072.9417\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1859.32910\n",
      "Epoch 31/2094\n",
      " - 22s - loss: 2279.6247 - val_loss: 2078.2537\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00031: loss did not improve from 2159.86615\n",
      "Epoch 32/2094\n",
      " - 22s - loss: 2223.6401 - val_loss: 2670.0684\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1859.32910\n",
      "Epoch 33/2094\n",
      " - 22s - loss: 2220.7572 - val_loss: 1955.8063\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00033: loss did not improve from 2159.86615\n",
      "Epoch 34/2094\n",
      " - 22s - loss: 2299.0635 - val_loss: 1949.1061\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1859.32910\n",
      "Epoch 35/2094\n",
      " - 22s - loss: 2294.1186 - val_loss: 3133.8804\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00035: loss did not improve from 2159.86615\n",
      "Epoch 36/2094\n",
      "Batch 40: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1859.32910\n",
      "\n",
      "Time 18634.71290755272\n",
      "Super-epoch 23 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      "Batch 24: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00001: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 18706.12945985794\n",
      "Super-epoch 24 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 33s - loss: 2337.5227 - val_loss: 2091.0808\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1859.32910\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2332.1711 - val_loss: 2116.6301\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2268.2965 - val_loss: 2297.4622\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2214.1834 - val_loss: 2098.8201\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 23s - loss: 2300.2769 - val_loss: 2683.8325\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2211.2694 - val_loss: 2914.2241\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 23s - loss: 2251.0550 - val_loss: 2709.4590\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2209.5434 - val_loss: 2009.3857\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2204.0328 - val_loss: 2325.3872\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2199.5795 - val_loss: 2042.2765\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2335.6305 - val_loss: 2716.5088\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2278.3677 - val_loss: 2158.1782\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2267.1756 - val_loss: 2048.9849\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2248.8110 - val_loss: 2370.2332\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n",
      "Epoch 15/2094\n",
      " - 23s - loss: 2295.5523 - val_loss: 2574.4492\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1859.32910\n",
      "Epoch 16/2094\n",
      "Batch 28: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00016: loss did not improve from 2159.86615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 19120.510021209717\n",
      "Super-epoch 25 - learn rate: 1.2401570718501559e-05\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2279.3515 - val_loss: 2207.0959\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1859.32910\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2247.8618 - val_loss: 2199.2246\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00002: loss did not improve from 2159.86615\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2297.0727 - val_loss: 1963.1969\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1859.32910\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2232.3542 - val_loss: 2345.7354\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00004: loss did not improve from 2159.86615\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2251.2472 - val_loss: 1922.3170\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1859.32910\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2311.6171 - val_loss: 2335.8237\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00006: loss did not improve from 2159.86615\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2332.4228 - val_loss: 2394.0774\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1859.32910\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2302.2821 - val_loss: 2271.8276\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00008: loss did not improve from 2159.86615\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2286.7037 - val_loss: 1910.8326\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1859.32910\n",
      "Epoch 10/2094\n",
      " - 23s - loss: 2225.0404 - val_loss: 2446.7449\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00010: loss did not improve from 2159.86615\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2365.6092 - val_loss: 2024.6929\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1859.32910\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2230.9611 - val_loss: 2129.6724\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00012: loss did not improve from 2159.86615\n",
      "Epoch 13/2094\n",
      " - 23s - loss: 2306.6952 - val_loss: 2296.2751\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1859.32910\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2228.1058 - val_loss: 2135.3750\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00014: loss did not improve from 2159.86615\n",
      "Epoch 15/2094\n",
      " - 23s - loss: 2325.8352 - val_loss: 2629.8760\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1859.32910\n",
      "Epoch 16/2094\n",
      " - 22s - loss: 2350.5247 - val_loss: 2567.2585\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00016: loss did not improve from 2159.86615\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2273.0511 - val_loss: 2637.4282\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1859.32910\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2283.2762 - val_loss: 2114.0039\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00018: loss did not improve from 2159.86615\n",
      "Epoch 19/2094\n",
      " - 22s - loss: 2259.3064 - val_loss: 2160.9304\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1859.32910\n",
      "Epoch 20/2094\n",
      " - 22s - loss: 2269.4470 - val_loss: 2201.4990\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00020: loss did not improve from 2159.86615\n",
      "Epoch 21/2094\n",
      " - 23s - loss: 2251.5292 - val_loss: 1942.1790\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1859.32910\n",
      "Epoch 22/2094\n",
      " - 23s - loss: 2362.3453 - val_loss: 2048.1731\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1859.32910\n",
      "\n",
      "Epoch 00022: loss did not improve from 2159.86615\n",
      "Epoch 23/2094\n",
      " - 24s - loss: 2319.1450 - val_loss: 2340.2620\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1859.32910\n",
      "Epoch 24/2094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-459f3818237d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mTerminateOnNaN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mmodel_4_checkpoint_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mmodel_4_checkpoint_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;31m#             model_4_checkpoint_force\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         ]\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print()\n",
    "# ''' // comment on this line to enable/disable this block\n",
    "model_4_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_4_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_4_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_4_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_4_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "# while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_4_learnRate)\n",
    "    print()\n",
    "    model_4_history = model_4.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_4_checkpoint_val,\n",
    "            model_4_checkpoint_loss,\n",
    "#             model_4_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_4_learnRate > minimumLR / model_4_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_4_learnRate = model_4_LRDecay * model_4_learnRate\n",
    "    model_4.load_weights(\"./saved_models/model_4_checkpoint.h5\")\n",
    "    model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_4 training done in\", str(time.time() - start_time))\n",
    "model_4.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource successfully released\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
