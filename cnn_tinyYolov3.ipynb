{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Tensorflow version 2.1.0\n",
      "Keras is running on tensorflow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "from PIL import Image\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Input, Layer, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add, Lambda\n",
    "from keras.models import Model, model_from_json, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint, Callback, EarlyStopping\n",
    "import keras.backend as K\n",
    "import os\n",
    "K.clear_session()\n",
    "K.set_floatx('float32')\n",
    "print(\"Running Tensorflow version\", tf.__version__)\n",
    "print(\"Keras is running on\", K.backend(), \"backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom layer classes successfully defined\n"
     ]
    }
   ],
   "source": [
    "# problem with model with rounding \n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # first one that works with model_1 & model_2 \n",
    "    # problem - this rounding function is slow: model_2 = 3 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # in addition, off by half with integer inputs (lower than actual value, e.g. floor(2) ≈ 1.5, floor(2.01) ≈ 2)\n",
    "    # source: https://en.wikipedia.org/wiki/Floor_and_ceiling_functions#Continuity_and_series_expansions\n",
    "    if True:\n",
    "        result = x - 0.5\n",
    "        for p in range(1, 7):\n",
    "            result = result + K.sin(x * p * 2 * math.pi) / (p * math.pi)\n",
    "    return result\n",
    "# '''\n",
    "'''     \n",
    "def roundingAlgo(x):\n",
    "    # second one that works with model_2 \n",
    "    # problem - this rounding function is slower than first working algo: model_2 = 4,2 hours / epoch\n",
    "    # comparison, model_0 = 20 mins / epoch\n",
    "    # source: self\n",
    "    return x - x % 1\n",
    "# '''\n",
    "# '''\n",
    "def roundingAlgo(x): \n",
    "    # simplification of the first algo loop by simplifying the expression for range(1,7)\n",
    "    # problem - rounding function is still slow = 2,5 hours / epoch\n",
    "    # all non-speed problem of first algo still applies\n",
    "    result = x - 0.5\n",
    "    resultCos = K.cos(2 * math.pi * x)\n",
    "    return result + K.sin(2 * math.pi * x) * (1 + resultCos) * (13 + 2 * resultCos - 18 * K.pow(resultCos, 2) - 32 * K.pow(resultCos, 3) + 80 * K.pow(resultCos, 4)) / 15\n",
    "# '''\n",
    "'''\n",
    "def roundingAlgo(x): \n",
    "    # made to fool the engine to have a gradient\n",
    "    return 0 * x + K.round(x)\n",
    "# '''\n",
    "\n",
    "\n",
    "# check https://github.com/keras-team/keras/issues/2218\n",
    "# check https://github.com/keras-team/keras/issues/2221\n",
    "# https://www.tensorflow.org/api_docs/python/tf/custom_gradient\n",
    "class RoundClampQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 4096), -524288, 524287) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ7_12(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ7_12, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ7_12, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 4096) + 524288) % 1048576) - 524288) / 4096.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ7_12, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundClampQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundClampQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundClampQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return K.clip(roundingAlgo(X * 16), -128, 127) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundClampQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class RoundOverflowQ3_4(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RoundOverflowQ3_4, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def build(self, input_shape):\n",
    "        super(RoundOverflowQ3_4, self).build(input_shape)\n",
    "    def call(self, X):\n",
    "        return (((roundingAlgo(X * 16) + 128) % 256) - 128) / 16.0\n",
    "    def get_config(self):\n",
    "        base_config = super(RoundOverflowQ3_4, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class Identity(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Identity, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(Identity, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "class IdentityFinalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IdentityFinalLayer, self).__init__(**kwargs)\n",
    "        self.trainable = False\n",
    "    def call(self, X):\n",
    "        return X\n",
    "    def get_config(self):\n",
    "        base_config = super(IdentityFinalLayer, self).get_config()\n",
    "        return dict(list(base_config.items()))\n",
    "    \n",
    "def DBL(previousLayer, layerFilter, kernelSize=(3, 3), roundingFunction=Identity, name=None):\n",
    "    placeholder = \"\"\n",
    "    if name is not None:\n",
    "        placeholder = str(name)\n",
    "    else:\n",
    "        placeholder = str(time.time_ns())\n",
    "    return roundingFunction(name=\"ThirdRound_\"+placeholder, dtype=K.floatx())(\n",
    "        LeakyReLU(alpha=0.1, dtype=K.floatx())(\n",
    "            roundingFunction(name=\"SecondRound_\"+placeholder, dtype=K.floatx())(\n",
    "                BatchNormalization(name=\"BatchNorm_\"+placeholder, dtype=K.floatx())(\n",
    "                    roundingFunction(name=\"FirstRound_\"+placeholder, dtype=K.floatx())(\n",
    "                        Conv2D(filters=layerFilter, kernel_size=kernelSize, padding='same', use_bias=False, kernel_regularizer=l2(5e-4), name=\"Conv2D_\"+placeholder, dtype=K.floatx())(\n",
    "                            previousLayer\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "print(\"Custom layer classes successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of class classification is 80\n"
     ]
    }
   ],
   "source": [
    "classificationClass = 80\n",
    "\n",
    "print(\"Number of class classification is\", classificationClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target data generator successfully defined\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "def rand(a=0, b=1):\n",
    "    return np.random.rand()*(b-a) + a\n",
    "\n",
    "def get_random_data(annotation_line, input_shape, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
    "    '''\n",
    "    random preprocessing for real-time data augmentation \n",
    "    \n",
    "    random=True induces image processing (better data accuracy with cost of cycles)\n",
    "    '''\n",
    "    line = annotation_line.split()\n",
    "    image = Image.open(line[0])\n",
    "    iw, ih = image.size\n",
    "    h, w = input_shape\n",
    "    box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if not random:\n",
    "        # resize image\n",
    "        scale = min(w/iw, h/ih)\n",
    "        nw = int(iw*scale)\n",
    "        nh = int(ih*scale)\n",
    "        dx = (w-nw)//2\n",
    "        dy = (h-nh)//2\n",
    "        image_data=0\n",
    "        if proc_img:\n",
    "            image = image.resize((nw,nh), Image.BICUBIC)\n",
    "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "            new_image.paste(image, (dx, dy))\n",
    "            image_data = np.array(new_image)/255.\n",
    "\n",
    "        # correct boxes\n",
    "        box_data = np.zeros((max_boxes,5))\n",
    "        if len(box)>0:\n",
    "            np.random.shuffle(box)\n",
    "            if len(box)>max_boxes: box = box[:max_boxes]\n",
    "            box[:, [0,2]] = box[:, [0,2]]*scale + dx\n",
    "            box[:, [1,3]] = box[:, [1,3]]*scale + dy\n",
    "            box_data[:len(box)] = box\n",
    "\n",
    "        return image_data, box_data\n",
    "\n",
    "    # resize image\n",
    "    new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
    "    scale = rand(.25, 2)\n",
    "    if new_ar < 1:\n",
    "        nh = int(scale*h)\n",
    "        nw = int(nh*new_ar)\n",
    "    else:\n",
    "        nw = int(scale*w)\n",
    "        nh = int(nw/new_ar)\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "\n",
    "    # place image\n",
    "    dx = int(rand(0, w-nw))\n",
    "    dy = int(rand(0, h-nh))\n",
    "    new_image = Image.new('RGB', (w,h), (128,128,128))\n",
    "    new_image.paste(image, (dx, dy))\n",
    "    image = new_image\n",
    "\n",
    "    # flip image or not\n",
    "    flip = rand()<.5\n",
    "    if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "    # distort image\n",
    "    hue = rand(-hue, hue)\n",
    "    sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
    "    val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
    "    x = rgb_to_hsv(np.array(image)/255.)\n",
    "    x[..., 0] += hue\n",
    "    x[..., 0][x[..., 0]>1] -= 1\n",
    "    x[..., 0][x[..., 0]<0] += 1\n",
    "    x[..., 1] *= sat\n",
    "    x[..., 2] *= val\n",
    "    x[x>1] = 1\n",
    "    x[x<0] = 0\n",
    "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
    "\n",
    "    # correct boxes\n",
    "    box_data = np.zeros((max_boxes,5))\n",
    "    if len(box)>0:\n",
    "        np.random.shuffle(box)\n",
    "        box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
    "        box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
    "        if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
    "        box[:, 0:2][box[:, 0:2]<0] = 0\n",
    "        box[:, 2][box[:, 2]>w] = w\n",
    "        box[:, 3][box[:, 3]>h] = h\n",
    "        box_w = box[:, 2] - box[:, 0]\n",
    "        box_h = box[:, 3] - box[:, 1]\n",
    "        box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
    "        if len(box)>max_boxes: box = box[:max_boxes]\n",
    "        box_data[:len(box)] = box\n",
    "\n",
    "    return image_data, box_data\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
    "    '''Preprocess true boxes to training input format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes: array, shape=(m, T, 5)\n",
    "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
    "    input_shape: array-like, hw, multiples of 32\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
    "\n",
    "    '''\n",
    "    assert (true_boxes[..., 4]<num_classes).all(), 'class id must be less than num_classes'\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "\n",
    "    true_boxes = np.array(true_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
    "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
    "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
    "\n",
    "    m = true_boxes.shape[0]\n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0\n",
    "\n",
    "    for b in range(m):\n",
    "        # Discard zero rows.\n",
    "        wh = boxes_wh[b, valid_mask[b]]\n",
    "        if len(wh)==0: continue\n",
    "        # Expand dim to apply broadcasting.\n",
    "        wh = np.expand_dims(wh, -2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "\n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "\n",
    "        # Find best anchor for each true box\n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(true_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(true_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = true_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "    return y_true\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "print(\"Target data generator successfully defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diambil dari https://github.com/qqwweee/keras-yolo3\n",
    "'''\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 qqwweee\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    "\n",
    "image_size = (448,448)\n",
    "image_height, image_width = image_size\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "tinyYolo_anchors = get_anchors(\"../CNN-VLSI/tiny_yolo_anchors.txt\")\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    grid_shape = K.shape(feats)[1:3] # height, width\n",
    "    grid_y = K.tile(K.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1]),\n",
    "        [1, grid_shape[1], 1, 1])\n",
    "    grid_x = K.tile(K.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1]),\n",
    "        [grid_shape[0], 1, 1, 1])\n",
    "    grid = K.concatenate([grid_x, grid_y])\n",
    "    grid = K.cast(grid, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # edited by instructions in https://stackoverflow.com/questions/57558476/training-a-keras-model-yields-multiple-optimizer-errors\n",
    "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[...,::-1], K.dtype(feats))\n",
    "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[...,::-1], K.dtype(feats))\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.sigmoid(feats[..., 5:])\n",
    "\n",
    "    if calc_loss == True:\n",
    "        return grid, feats, box_xy, box_wh\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "def box_iou(b1, b2):\n",
    "    '''Return iou tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
    "    b2: tensor, shape=(j, 4), xywh\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iou: tensor, shape=(i1,...,iN, j)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b1 = K.expand_dims(b1, -2)\n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4]\n",
    "    b1_wh_half = b1_wh/2.\n",
    "    b1_mins = b1_xy - b1_wh_half\n",
    "    b1_maxes = b1_xy + b1_wh_half\n",
    "\n",
    "    # Expand dim to apply broadcasting.\n",
    "    b2 = K.expand_dims(b2, 0)\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4]\n",
    "    b2_wh_half = b2_wh/2.\n",
    "    b2_mins = b2_xy - b2_wh_half\n",
    "    b2_maxes = b2_xy + b2_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5, print_loss=False):\n",
    "    '''Return yolo_loss tensor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
    "    y_true: list of array, the output of preprocess_true_boxes\n",
    "    anchors: array, shape=(N, 2), wh\n",
    "    num_classes: integer\n",
    "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss: tensor, shape=(1,)\n",
    "\n",
    "    '''\n",
    "    num_layers = len(anchors)//3 # default setting\n",
    "    yolo_outputs = args[:num_layers]\n",
    "    y_true = args[num_layers:]\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "    loss = 0\n",
    "    m = K.shape(yolo_outputs[0])[0] # batch size, tensor\n",
    "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        object_mask = y_true[l][..., 4:5]\n",
    "        true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l], anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "        # Darknet raw box to calculate loss.\n",
    "        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid\n",
    "        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1] + 1e-10)\n",
    "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf\n",
    "        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]\n",
    "\n",
    "        # Find ignore mask, iterate over each of batch.\n",
    "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "        object_mask_bool = K.cast(object_mask, 'bool')\n",
    "        def loop_body(b, ignore_mask):\n",
    "            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])\n",
    "            iou = box_iou(pred_box[b], true_box)\n",
    "            best_iou = K.max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))\n",
    "            return b+1, ignore_mask\n",
    "        _, ignore_mask = tf.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "\n",
    "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])\n",
    "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \\\n",
    "            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask\n",
    "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)\n",
    "\n",
    "        xy_loss = K.sum(xy_loss) / mf\n",
    "        wh_loss = K.sum(wh_loss) / mf\n",
    "        confidence_loss = K.sum(confidence_loss) / mf\n",
    "        class_loss = K.sum(class_loss) / mf\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training data is 117266\n",
      "# of validation data is 4952\n"
     ]
    }
   ],
   "source": [
    "with open(\"../CNN-VLSI/train.txt\") as trainText:\n",
    "    train_annotation_lines = trainText.readlines()\n",
    "with open(\"../CNN-VLSI/val.txt\") as valText:\n",
    "    val_annotation_lines = valText.readlines()\n",
    "lenTrain = len(train_annotation_lines)\n",
    "print(\"# of training data is\", lenTrain)\n",
    "lenVal = len(val_annotation_lines)\n",
    "print(\"# of validation data is\", lenVal)\n",
    "np.random.shuffle(train_annotation_lines)\n",
    "np.random.shuffle(val_annotation_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 does no rounding (float32 operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_0 = None\n",
    "'''\n",
    "model_0_input = Input(shape=(None, None, 3), name=\"model_0_inputLayer\")\n",
    "# model_0_pointer = model_0_input\n",
    "print(\"Input shape:\", model_0_input.shape) # 448 x 448 x 3\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_input, layerFilter=16, name=\"model_0_layer0_branch\") \n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 448 x 448 x 16\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 16\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=32, name=\"model_0_layer1_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 224 x 224 x 32\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 32\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=64, name=\"model_0_layer2_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 112 x 112 x 64\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 64\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=128, name=\"model_0_layer3_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 56 x 56 x 128\n",
    "model_0_startBranch = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "model_0_startBranch = DBL(roundingFunction=Identity, previousLayer=model_0_startBranch, layerFilter=256, name=\"model_0_layer4_branch\")\n",
    "# model_0_pointer = model_0_startBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_0_branch0\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2))(model_0_startBranch)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer5_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_0_branch0)\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=1024, name=\"model_0_layer6_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 1024\n",
    "model_0_branch0 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_0_layer7_branch0\")\n",
    "# model_0_pointer = model_0_branch0\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_0_branch0 (14 x 14 x 256), following model_0_branch00\n",
    "model_0_branch00 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_0_layer8_branch00\")\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 128\n",
    "model_0_branch00 = UpSampling2D()(model_0_branch00)\n",
    "# model_0_pointer = model_0_branch00\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_0_branch1 (unchanged from model_0_startBranch) and model_0_branch00\n",
    "model_0_mergedBranch = Concatenate()([model_0_startBranch, model_0_branch00])\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 384\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=256, name=\"model_0_layer9_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "# print(model_0_pointer.shape) # 28 x 28 x 256\n",
    "model_0_mergedBranch = DBL(roundingFunction=Identity, previousLayer=model_0_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layerA_branch1\")\n",
    "# model_0_pointer = model_0_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_0_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_0_mergedBranch = IdentityFinalLayer(name=\"model_0_outputLayer_1\")(model_0_mergedBranch)\n",
    "print() # OUTPUT = model_0_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_0_branch01\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch0, layerFilter=512, name=\"model_0_layer8_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "# print(model_0_pointer.shape) # 14 x 14 x 512\n",
    "model_0_branch01 = DBL(roundingFunction=Identity, previousLayer=model_0_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_0_layer9_branch01\")\n",
    "# model_0_pointer = model_0_branch01\n",
    "print(\"Model output 0 shape:\", model_0_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_0_branch01 = IdentityFinalLayer(name=\"model_0_outputLayer_0\")(model_0_branch01)\n",
    "print() # OUTPUT = model_0_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_0_actual = Model(inputs=model_0_input, outputs=[model_0_branch01, model_0_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_0_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_0_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_0_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_0_actual.load_weights(\"./saved_models/model_0_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_0\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_0:\", e)\n",
    "try:\n",
    "    model_0_actual.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_0 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_0 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_0_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_0', arguments=setArgs_model_0)([*model_0_actual.output, *y_true_model_0])\n",
    "\n",
    "model_0 = Model([model_0_actual.input, *y_true_model_0], model_0_loss)\n",
    "\n",
    "# model_0_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_0 adalah pendekatan sehingga output model_0 sedekat mungkin dengan 0 (model_0 ≈ model_0_actual - y_true)\n",
    "model_0_learnRate = 1e-2\n",
    "model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_0 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 approximates Q7.12 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_1 = None\n",
    "'''\n",
    "model_1_input = Input(shape=(None, None, 3), name=\"model_1_inputLayer\")\n",
    "# model_1_pointer = model_1_input\n",
    "print(\"Input shape:\", model_1_input.shape) # 448 x 448 x 3\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_input, layerFilter=16, name=\"model_1_layer0_branch\") \n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 448 x 448 x 16\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 16\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=32, name=\"model_1_layer1_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 224 x 224 x 32\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 32\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=64, name=\"model_1_layer2_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 112 x 112 x 64\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 64\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=128, name=\"model_1_layer3_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 56 x 56 x 128\n",
    "model_1_startBranch = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "model_1_startBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_startBranch, layerFilter=256, name=\"model_1_layer4_branch\")\n",
    "# model_1_pointer = model_1_startBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_1_branch0\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2))(model_1_startBranch)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer5_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_1_branch0)\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=1024, name=\"model_1_layer6_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 1024\n",
    "model_1_branch0 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_1_layer7_branch0\")\n",
    "# model_1_pointer = model_1_branch0\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_1_branch0 (14 x 14 x 256), following model_1_branch00\n",
    "model_1_branch00 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_1_layer8_branch00\")\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 128\n",
    "model_1_branch00 = UpSampling2D()(model_1_branch00)\n",
    "# model_1_pointer = model_1_branch00\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_1_branch1 (unchanged from model_1_startBranch) and model_1_branch00\n",
    "model_1_mergedBranch = Concatenate()([model_1_startBranch, model_1_branch00])\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 384\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=256, name=\"model_1_layer9_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "# print(model_1_pointer.shape) # 28 x 28 x 256\n",
    "model_1_mergedBranch = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layerA_branch1\")\n",
    "# model_1_pointer = model_1_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_1_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_1_mergedBranch = IdentityFinalLayer(name=\"model_1_outputLayer_1\")(model_1_mergedBranch)\n",
    "print() # OUTPUT = model_1_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_1_branch01\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch0, layerFilter=512, name=\"model_1_layer8_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "# print(model_1_pointer.shape) # 14 x 14 x 512\n",
    "model_1_branch01 = DBL(roundingFunction=RoundClampQ7_12, previousLayer=model_1_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_1_layer9_branch01\")\n",
    "# model_1_pointer = model_1_branch01\n",
    "print(\"Model output 0 shape:\", model_1_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_1_branch01 = IdentityFinalLayer(name=\"model_1_outputLayer_0\")(model_1_branch01)\n",
    "print() # OUTPUT = model_1_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_1_actual = Model(inputs=model_1_input, outputs=[model_1_branch01, model_1_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_1_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_1_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_1_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_1_actual.load_weights(\"./saved_models/model_1_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_1\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_1:\", e)\n",
    "try:\n",
    "    model_1_actual.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_1 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_1 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_1_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_1', arguments=setArgs_model_1)([*model_1_actual.output, *y_true_model_1])\n",
    "\n",
    "model_1 = Model([model_1_actual.input, *y_true_model_1], model_1_loss)\n",
    "\n",
    "# model_1_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_1 adalah pendekatan sehingga output model_1 sedekat mungkin dengan 0 (model_1 ≈ model_1_actual - y_true)\n",
    "model_1_learnRate = 1e-2\n",
    "model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_1 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 approximates Q7.12 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/4096 and capping at [-128, 128) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_2 = None\n",
    "'''\n",
    "model_2_input = Input(shape=(None, None, 3), name=\"model_2_inputLayer\")\n",
    "# model_2_pointer = model_2_input\n",
    "print(\"Input shape:\", model_2_input.shape) # 448 x 448 x 3\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_input, layerFilter=16, name=\"model_2_layer0_branch\") \n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 448 x 448 x 16\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 16\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=32, name=\"model_2_layer1_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 224 x 224 x 32\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 32\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=64, name=\"model_2_layer2_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 112 x 112 x 64\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 64\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=128, name=\"model_2_layer3_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 56 x 56 x 128\n",
    "model_2_startBranch = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "model_2_startBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_startBranch, layerFilter=256, name=\"model_2_layer4_branch\")\n",
    "# model_2_pointer = model_2_startBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_2_branch0\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2))(model_2_startBranch)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer5_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_2_branch0)\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=1024, name=\"model_2_layer6_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 1024\n",
    "model_2_branch0 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_2_layer7_branch0\")\n",
    "# model_2_pointer = model_2_branch0\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_2_branch0 (14 x 14 x 256), following model_2_branch00\n",
    "model_2_branch00 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_2_layer8_branch00\")\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 128\n",
    "model_2_branch00 = UpSampling2D()(model_2_branch00)\n",
    "# model_2_pointer = model_2_branch00\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_2_branch1 (unchanged from model_2_startBranch) and model_2_branch00\n",
    "model_2_mergedBranch = Concatenate()([model_2_startBranch, model_2_branch00])\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 384\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=256, name=\"model_2_layer9_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "# print(model_2_pointer.shape) # 28 x 28 x 256\n",
    "model_2_mergedBranch = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layerA_branch1\")\n",
    "# model_2_pointer = model_2_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_2_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_2_mergedBranch = IdentityFinalLayer(name=\"model_2_outputLayer_1\")(model_2_mergedBranch)\n",
    "print() # OUTPUT = model_2_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_2_branch01\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch0, layerFilter=512, name=\"model_2_layer8_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "# print(model_2_pointer.shape) # 14 x 14 x 512\n",
    "model_2_branch01 = DBL(roundingFunction=RoundOverflowQ7_12, previousLayer=model_2_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_2_layer9_branch01\")\n",
    "# model_2_pointer = model_2_branch01\n",
    "print(\"Model output 0 shape:\", model_2_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_2_branch01 = IdentityFinalLayer(name=\"model_2_outputLayer_0\")(model_2_branch01)\n",
    "print() # OUTPUT = model_2_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_2_actual = Model(inputs=model_2_input, outputs=[model_2_branch01, model_2_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_2_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_2_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_2_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_2_actual.load_weights(\"./saved_models/model_2_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_2\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_2:\", e)\n",
    "try:\n",
    "    model_2_actual.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_2 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_2 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_2_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_2', arguments=setArgs_model_2)([*model_2_actual.output, *y_true_model_2])\n",
    "\n",
    "model_2 = Model([model_2_actual.input, *y_true_model_2], model_2_loss)\n",
    "\n",
    "# model_2_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_2 adalah pendekatan sehingga output model_2 sedekat mungkin dengan 0 (model_2 ≈ model_2_actual - y_true)\n",
    "model_2_learnRate = 1e-2\n",
    "model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_2 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_3 approximates Q3.4 signed fixed point operations with floating point rules (overflow = maximum/minimum value) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_3 = None\n",
    "'''\n",
    "model_3_input = Input(shape=(None, None, 3), name=\"model_3_inputLayer\")\n",
    "# model_3_pointer = model_3_input\n",
    "print(\"Input shape:\", model_3_input.shape) # 448 x 448 x 3\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_input, layerFilter=16, name=\"model_3_layer0_branch\") \n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 448 x 448 x 16\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 16\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=32, name=\"model_3_layer1_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 224 x 224 x 32\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 32\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=64, name=\"model_3_layer2_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 112 x 112 x 64\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 64\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=128, name=\"model_3_layer3_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 56 x 56 x 128\n",
    "model_3_startBranch = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "model_3_startBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_startBranch, layerFilter=256, name=\"model_3_layer4_branch\")\n",
    "# model_3_pointer = model_3_startBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_3_branch0\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2))(model_3_startBranch)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer5_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_3_branch0)\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=1024, name=\"model_3_layer6_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 1024\n",
    "model_3_branch0 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_3_layer7_branch0\")\n",
    "# model_3_pointer = model_3_branch0\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_3_branch0 (14 x 14 x 256), following model_3_branch00\n",
    "model_3_branch00 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_3_layer8_branch00\")\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 128\n",
    "model_3_branch00 = UpSampling2D()(model_3_branch00)\n",
    "# model_3_pointer = model_3_branch00\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_3_branch1 (unchanged from model_3_startBranch) and model_3_branch00\n",
    "model_3_mergedBranch = Concatenate()([model_3_startBranch, model_3_branch00])\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 384\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=256, name=\"model_3_layer9_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "# print(model_3_pointer.shape) # 28 x 28 x 256\n",
    "model_3_mergedBranch = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layerA_branch1\")\n",
    "# model_3_pointer = model_3_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_3_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_3_mergedBranch = IdentityFinalLayer(name=\"model_3_outputLayer_1\")(model_3_mergedBranch)\n",
    "print() # OUTPUT = model_3_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_3_branch01\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch0, layerFilter=512, name=\"model_3_layer8_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "# print(model_3_pointer.shape) # 14 x 14 x 512\n",
    "model_3_branch01 = DBL(roundingFunction=RoundClampQ3_4, previousLayer=model_3_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_3_layer9_branch01\")\n",
    "# model_3_pointer = model_3_branch01\n",
    "print(\"Model output 0 shape:\", model_3_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_3_branch01 = IdentityFinalLayer(name=\"model_3_outputLayer_0\")(model_3_branch01)\n",
    "print() # OUTPUT = model_3_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_3_actual = Model(inputs=model_3_input, outputs=[model_3_branch01, model_3_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_3_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_3_actual.to_json())\n",
    "\n",
    "try:\n",
    "#     model_3_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "    model_3_actual.load_weights(\"./saved_models/model_3_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_3\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_3:\", e)\n",
    "try:\n",
    "    model_3_actual.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_3 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_3 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_3_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_3', arguments=setArgs_model_3)([*model_3_actual.output, *y_true_model_3])\n",
    "\n",
    "model_3 = Model([model_3_actual.input, *y_true_model_3], model_3_loss)\n",
    "\n",
    "# model_3_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_3 adalah pendekatan sehingga output model_3 sedekat mungkin dengan 0 (model_3 ≈ model_3_actual - y_true)\n",
    "model_3_learnRate = 1e-2\n",
    "model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_3 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4 approximates Q3.4 signed fixed point operations with integer rules (overflow = positive -> negative & vice versa) \n",
    "# Done by rounding to the nearest 1/16 and capping at [-8, 8) after batch normalization and activation layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, None, None, 3)\n",
      "Branch split from main branch - following branch 0\n",
      "Branch split from branch 0 - following branch 0,0\n",
      "Branch merge from branch 1 and branch 0,0\n",
      "Model output 1 shape: (None, None, None, 255)\n",
      "\n",
      "Branch split from branch 0 - following branch 0,1\n",
      "Model output 0 shape: (None, None, None, 255)\n",
      "\n",
      "Weight load attempt success for model_4\n",
      "Loaded model is successfully re-saved\n",
      "Model model_4 compilation complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4 = None\n",
    "# '''\n",
    "model_4_input = Input(shape=(None, None, 3), name=\"model_4_inputLayer\")\n",
    "# model_4_pointer = model_4_input\n",
    "print(\"Input shape:\", model_4_input.shape) # 448 x 448 x 3\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_input, layerFilter=16, name=\"model_4_layer0_branch\") \n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 448 x 448 x 16\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 16\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=32, name=\"model_4_layer1_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 224 x 224 x 32\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 32\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=64, name=\"model_4_layer2_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 112 x 112 x 64\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 64\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=128, name=\"model_4_layer3_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 56 x 56 x 128\n",
    "model_4_startBranch = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "model_4_startBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_startBranch, layerFilter=256, name=\"model_4_layer4_branch\")\n",
    "# model_4_pointer = model_4_startBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "print(\"Branch split from main branch - following branch 0\") # 2 branch split from startBranch (28 x 28 x 256), following model_4_branch0\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2))(model_4_startBranch)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer5_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = MaxPooling2D(pool_size=(2, 2), strides=1, padding='same')(model_4_branch0)\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=1024, name=\"model_4_layer6_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 1024\n",
    "model_4_branch0 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=256, kernelSize=(1, 1), name=\"model_4_layer7_branch0\")\n",
    "# model_4_pointer = model_4_branch0\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 256\n",
    "print(\"Branch split from branch 0 - following branch 0,0\") # 2 branch split from model_4_branch0 (14 x 14 x 256), following model_4_branch00\n",
    "model_4_branch00 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=128, kernelSize=(1, 1), name=\"model_4_layer8_branch00\")\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 128\n",
    "model_4_branch00 = UpSampling2D()(model_4_branch00)\n",
    "# model_4_pointer = model_4_branch00\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 128\n",
    "print(\"Branch merge from branch 1 and branch 0,0\") # 2 branch merge from model_4_branch1 (unchanged from model_4_startBranch) and model_4_branch00\n",
    "model_4_mergedBranch = Concatenate()([model_4_startBranch, model_4_branch00])\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 384\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=256, name=\"model_4_layer9_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "# print(model_4_pointer.shape) # 28 x 28 x 256\n",
    "model_4_mergedBranch = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_mergedBranch, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layerA_branch1\")\n",
    "# model_4_pointer = model_4_mergedBranch\n",
    "print(\"Model output 1 shape:\", model_4_mergedBranch.shape) # 28 x 28 x (3 * (5 + classificationClass))\n",
    "model_4_mergedBranch = IdentityFinalLayer(name=\"model_4_outputLayer_1\")(model_4_mergedBranch)\n",
    "print() # OUTPUT = model_4_mergedBranch (note: 26 x 26 grid untuk deteksi objek kecil)\n",
    "\n",
    "print(\"Branch split from branch 0 - following branch 0,1\")# following model_4_branch01\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch0, layerFilter=512, name=\"model_4_layer8_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "# print(model_4_pointer.shape) # 14 x 14 x 512\n",
    "model_4_branch01 = DBL(roundingFunction=RoundOverflowQ3_4, previousLayer=model_4_branch01, layerFilter=3 * (4 + 1 + classificationClass), name=\"model_4_layer9_branch01\")\n",
    "# model_4_pointer = model_4_branch01\n",
    "print(\"Model output 0 shape:\", model_4_branch01.shape) # 14 x 14 x (3 * (5 + classificationClass))\n",
    "model_4_branch01 = IdentityFinalLayer(name=\"model_4_outputLayer_0\")(model_4_branch01)\n",
    "print() # OUTPUT = model_4_branch01 (note: 13 x 13 grid untuk deteksi objek besar)\n",
    "\n",
    "model_4_actual = Model(inputs=model_4_input, outputs=[model_4_branch01, model_4_mergedBranch]) # mengikuti model dari https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "\n",
    "with open(\"./saved_models/model_4_inferenceModel.json\", \"wt\") as jsonFile:\n",
    "    jsonFile.write(model_4_actual.to_json())\n",
    "\n",
    "try:\n",
    "    model_4_actual.load_weights(\"../keras-yolo3/model_data/yolov3_tiny_roundOverflowQ3_4.h5\", by_name=True, skip_mismatch=True)\n",
    "#     model_4_actual.load_weights(\"./saved_models/model_4_checkpoint.h5\", by_name=True, skip_mismatch=True)\n",
    "    print(\"Weight load attempt success for model_4\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load existing model for model_4:\", e)\n",
    "try:\n",
    "    model_4_actual.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "    print(\"Loaded model is successfully re-saved\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save loaded model:\", e)\n",
    "# added code from https://github.com/awe777/keras-yolo3/blob/master/yolo3/model.py\n",
    "setArgs_model_4 = {\n",
    "    'anchors': tinyYolo_anchors, \n",
    "    'num_classes': classificationClass, \n",
    "    'ignore_thresh': 0.2\n",
    "}\n",
    "\n",
    "y_true_model_4 = [Input(shape=(image_height//{0:32, 1:16}[l], image_width//{0:32, 1:16}[l], 3, classificationClass + 5)) for l in range(2)]\n",
    "\n",
    "model_4_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss_model_4', arguments=setArgs_model_4)([*model_4_actual.output, *y_true_model_4])\n",
    "\n",
    "model_4 = Model([model_4_actual.input, *y_true_model_4], model_4_loss)\n",
    "\n",
    "# model_4_actual adalah working model yang akan dipakai untuk inference\n",
    "# y_true adalah layer input yang akan diisikan nilai sebenarnya\n",
    "# cara training model_4 adalah pendekatan sehingga output model_4 sedekat mungkin dengan 0 (model_4 ≈ model_4_actual - y_true)\n",
    "model_4_learnRate = 1e-3\n",
    "model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "# loss adalah seberapa jauh nilai perbedaan output dengan 0\n",
    "\n",
    "print(\"Model model_4 compilation complete\") # tinggal porting line 54 sampai 61 dari https://github.com/awe777/keras-yolo3/blob/master/train.py, dilakukan di cell training di bawah\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_0 is not None:\n",
    "    with open(\"./saved_models/model_0_summary.txt\", \"wt\") as textFile:\n",
    "        model_0.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_1 is not None:\n",
    "    with open(\"./saved_models/model_1_summary.txt\", \"wt\") as textFile:\n",
    "        model_1.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_2 is not None:\n",
    "    with open(\"./saved_models/model_2_summary.txt\", \"wt\") as textFile:\n",
    "        model_2.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_3 is not None:\n",
    "    with open(\"./saved_models/model_3_summary.txt\", \"wt\") as textFile:\n",
    "        model_3.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_4 is not None:\n",
    "    with open(\"./saved_models/model_4_summary.txt\", \"wt\") as textFile:\n",
    "        model_4.summary(print_fn=lambda x: textFile.write(x + '\\n'), line_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "trainingBatchSize = 1\n",
    "epochSplit = 1047 \n",
    "# because high split = more work saved; 117266 mod 499 = 1 <= less image lost for (416,416)\n",
    "# 117266 mod 1047 = 2 <= due to high loss of (448,448)\n",
    "train_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=train_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "val_data_generator = data_generator_wrapper(\n",
    "    annotation_lines=val_annotation_lines, \n",
    "    batch_size=trainingBatchSize, \n",
    "    input_shape=image_size, \n",
    "    anchors=tinyYolo_anchors, \n",
    "    num_classes=classificationClass\n",
    ")\n",
    "minimumLR = 5e-5\n",
    "decayChance = 0.50\n",
    "class BestValueRecorder(Callback):\n",
    "    def __init__(self, filepath, monitorValidation=False, mode='min', verbose=1, instanceModelCheckpointLoss=None, instanceModelCheckpointVal=None):\n",
    "        super(BestValueRecorder, self).__init__()\n",
    "        self.lookOnVal = monitorValidation\n",
    "        self.verbose = verbose\n",
    "        if mode not in ['min', 'max']:\n",
    "            mode = 'min'\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.MCLossValue = np.Inf\n",
    "            self.MCValLossValue = np.Inf\n",
    "        else:\n",
    "            self.monitor_op = np.greater\n",
    "            self.MCLossValue = -np.Inf\n",
    "            self.MCValLossValue = -np.Inf\n",
    "        self.filepath = filepath\n",
    "        try:\n",
    "            with open(self.filepath, 'rt') as jsonFile:\n",
    "                bestValueList = json.loads(jsonFile.read())\n",
    "                self.MCLossValue =  bestValueList[0]\n",
    "                if self.lookOnVal:\n",
    "                    self.MCValLossValue = bestValueList[1]\n",
    "        except Exception as e:\n",
    "            print(\"Failed to open JSON file:\", e)\n",
    "        if instanceModelCheckpointLoss is not None:\n",
    "            instanceModelCheckpointLoss.best = self.MCLossValue\n",
    "        if instanceModelCheckpointVal is not None and monitorValidation:\n",
    "            instanceModelCheckpointVal.best = self.MCValLossValue\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        currentLoss = logs.get('loss')\n",
    "        newChange = False\n",
    "        if currentLoss is not None and self.monitor_op(currentLoss, self.MCLossValue):\n",
    "            self.MCLossValue = currentLoss\n",
    "            newChange = True\n",
    "        if self.lookOnVal:\n",
    "            currentValLoss = logs.get('val_loss')\n",
    "            if currentValLoss is not None and self.monitor_op(currentValLoss, self.MCValLossValue):\n",
    "                self.MCValLossValue = currentValLoss\n",
    "                newChange = True\n",
    "        if newChange:\n",
    "            try:\n",
    "                with open(self.filepath, 'wt') as jsonFile:\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Saving best loss value:\", [self.MCLossValue, self.MCValLossValue])\n",
    "                    jsonFile.write(json.dumps([self.MCLossValue, self.MCValLossValue]))\n",
    "            except Exception as e:\n",
    "                print(\"Failed to open JSON file:\", e)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_0_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_0_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_0_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_0_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_0_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_0_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_0_learnRate)\n",
    "    print()\n",
    "    model_0_history = model_0.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_0_checkpoint_val,\n",
    "            model_0_checkpoint_loss,\n",
    "#             model_0_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_0_learnRate > minimumLR / model_0_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_0_learnRate = model_0_LRDecay * model_0_learnRate\n",
    "    model_0.load_weights(\"./saved_models/model_0_checkpoint.h5\")\n",
    "    model_0.compile(optimizer=Adam(lr=model_0_learnRate), loss={'yolo_loss_model_0': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_0 training done in\", str(time.time() - start_time))\n",
    "model_0.save_weights(\"./saved_models/model_0_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_1_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_1_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_1_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_1_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_1_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_1_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_1_learnRate)\n",
    "    print()\n",
    "    model_1_history = model_1.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_1_checkpoint_val,\n",
    "            model_1_checkpoint_loss,\n",
    "#             model_1_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_1_learnRate > minimumLR / model_1_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_1_learnRate = model_1_LRDecay * model_1_learnRate\n",
    "    model_1.load_weights(\"./saved_models/model_1_checkpoint.h5\")\n",
    "    model_1.compile(optimizer=Adam(lr=model_1_learnRate), loss={'yolo_loss_model_1': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_1 training done in\", str(time.time() - start_time))\n",
    "model_1.save_weights(\"./saved_models/model_1_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_2_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_2_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_2_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_2_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_2_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_2_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_2_learnRate)\n",
    "    print()\n",
    "    model_2_history = model_2.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_2_checkpoint_val,\n",
    "            model_2_checkpoint_loss,\n",
    "#             model_2_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_2_learnRate > minimumLR / model_2_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_2_learnRate = model_2_LRDecay * model_2_learnRate\n",
    "    model_2.load_weights(\"./saved_models/model_2_checkpoint.h5\")\n",
    "    model_2.compile(optimizer=Adam(lr=model_2_learnRate), loss={'yolo_loss_model_2': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_2 training done in\", str(time.time() - start_time))\n",
    "model_2.save_weights(\"./saved_models/model_2_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "''' // comment on this line to enable/disable this block\n",
    "model_3_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_3_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_3_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "# model_3_checkpoint_force = ModelCheckpoint(\n",
    "#     filepath='./saved_models/model_3_checkpoint.h5',\n",
    "#     verbose=1,\n",
    "#     save_weights_only=True,\n",
    "#     period=5\n",
    "# )\n",
    "model_3_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 6 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 10: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_3_learnRate)\n",
    "    print()\n",
    "    model_3_history = model_3.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_3_checkpoint_val,\n",
    "            model_3_checkpoint_loss,\n",
    "#             model_3_checkpoint_force\n",
    "        ]\n",
    "    )\n",
    "    if model_3_learnRate > minimumLR / model_3_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_3_learnRate = model_3_LRDecay * model_3_learnRate\n",
    "    model_3.load_weights(\"./saved_models/model_3_checkpoint.h5\")\n",
    "    model_3.compile(optimizer=Adam(lr=model_3_learnRate), loss={'yolo_loss_model_3': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_3 training done in\", str(time.time() - start_time))\n",
    "model_3.save_weights(\"./saved_models/model_3_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 0.0\n",
      "Super-epoch 1 - learn rate: 5e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 38s - loss: 2858.3020 - val_loss: 2421.3503\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2961.8473 - val_loss: 2505.1814\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      "Batch 25: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 78.3595380783081\n",
      "Super-epoch 2 - learn rate: 5e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 30s - loss: 2251.4673 - val_loss: 2023.8842\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2275.7099 - val_loss: 2147.9539\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2309.5539 - val_loss: 2301.2844\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2243.5327 - val_loss: 2293.6528\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2301.8315 - val_loss: 2640.1084\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2249.1001 - val_loss: 1896.8278\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2265.1580 - val_loss: 2278.0518\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2271.5721 - val_loss: 2030.7803\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2186.9394 - val_loss: 1977.4777\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2282.7163 - val_loss: 2055.1221\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2302.3916 - val_loss: 1946.7604\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2385.4707 - val_loss: 2085.4072\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2362.3922 - val_loss: 2193.4316\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2248.3937 - val_loss: 2462.1516\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2263.8216 - val_loss: 2020.3232\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2170.20072\n",
      "Epoch 00015: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 429.3124921321869\n",
      "Super-epoch 3 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2235.9947 - val_loss: 2161.0918\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2281.9630 - val_loss: 2509.2881\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2250.0293 - val_loss: 2205.1614\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2252.7726 - val_loss: 1950.5618\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2289.8355 - val_loss: 1964.1136\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2270.8005 - val_loss: 2267.8955\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2241.4239 - val_loss: 2201.7495\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2239.7672 - val_loss: 1973.2141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2242.2620 - val_loss: 2512.1260\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2322.4531 - val_loss: 2676.8586\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2170.20072\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2276.5845 - val_loss: 2027.4745\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2312.1231 - val_loss: 2108.1851\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2170.20072\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2218.7251 - val_loss: 2508.7771\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2248.5193 - val_loss: 3214.1345\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2170.20072\n",
      "Epoch 15/2094\n",
      "Batch 10: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 761.8879504203796\n",
      "Super-epoch 4 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2336.6203 - val_loss: 1863.9066\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2287.1744 - val_loss: 2562.8950\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2288.0367 - val_loss: 2042.6431\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2332.1809 - val_loss: 2598.2019\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2192.4738 - val_loss: 1987.9543\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2279.7198 - val_loss: 2327.2539\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2339.8749 - val_loss: 2446.1465\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2298.3241 - val_loss: 2695.1685\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2223.3541 - val_loss: 2657.5610\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2232.2494 - val_loss: 2753.6494\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2243.7597 - val_loss: 2565.7341\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2334.0183 - val_loss: 2043.9471\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2323.8696 - val_loss: 2129.1343\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2265.5882 - val_loss: 2128.8364\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2280.4850 - val_loss: 2134.0037\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2170.20072\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 1113.3749108314514\n",
      "Super-epoch 5 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 30s - loss: 2303.4259 - val_loss: 2056.9282\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2233.5891 - val_loss: 2081.6716\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2305.9139 - val_loss: 2186.4192\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2305.7862 - val_loss: 2126.8474\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2216.5820 - val_loss: 1896.0237\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2251.8481 - val_loss: 1982.4882\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2322.7597 - val_loss: 3130.0420\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2302.4005 - val_loss: 2347.5225\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2242.0943 - val_loss: 1871.6775\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      "Batch 1: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2170.20072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 1333.948055267334\n",
      "Super-epoch 6 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2263.6012 - val_loss: 1941.0168\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2223.4142 - val_loss: 2028.5542\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2288.0245 - val_loss: 2332.6255\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2272.1250 - val_loss: 2041.5544\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2234.7107 - val_loss: 2942.7043\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2272.3423 - val_loss: 2019.8926\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2262.7267 - val_loss: 2113.3464\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2346.9595 - val_loss: 2528.0967\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2258.5645 - val_loss: 2157.9607\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2255.6727 - val_loss: 2243.9697\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2170.20072\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2329.2870 - val_loss: 2621.6331\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2311.1797 - val_loss: 2091.1853\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2170.20072\n",
      "Epoch 13/2094\n",
      "Batch 45: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 1633.2187149524689\n",
      "Super-epoch 7 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 30s - loss: 2248.3528 - val_loss: 2064.6848\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2267.7128 - val_loss: 2260.6296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2313.5739 - val_loss: 2426.1863\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2324.9510 - val_loss: 2056.0857\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2308.6859 - val_loss: 2154.6199\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2235.8892 - val_loss: 2521.1831\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2357.1224 - val_loss: 2114.4753\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2176.1229 - val_loss: 2306.5120\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2277.8934 - val_loss: 2097.8591\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2268.4847 - val_loss: 2015.6458\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2250.4568 - val_loss: 2155.2903\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2274.7989 - val_loss: 2411.6140\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2315.8475 - val_loss: 2060.6433\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2286.9700 - val_loss: 2052.9783\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2267.2815 - val_loss: 2159.8486\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2170.20072\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 1986.1097462177277\n",
      "Super-epoch 8 - learn rate: 3.149802624737183e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2257.7113 - val_loss: 2022.6537\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2249.2952 - val_loss: 2176.3296\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2306.8129 - val_loss: 2146.4192\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2298.3080 - val_loss: 2106.3411\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2271.4292 - val_loss: 2103.2258\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      "Batch 44: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 2135.0691187381744\n",
      "Super-epoch 9 - learn rate: 1.9842513149602496e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2317.9968 - val_loss: 2490.9102\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2264.0550 - val_loss: 2055.2361\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2238.0582 - val_loss: 2428.7910\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2302.7370 - val_loss: 2015.8451\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2388.2428 - val_loss: 2624.6477\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2390.2038 - val_loss: 2298.6555\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 23s - loss: 2269.9462 - val_loss: 1905.4275\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2293.1156 - val_loss: 2261.7390\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      "Batch 24: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 2347.1793270111084\n",
      "Super-epoch 10 - learn rate: 1.2500000000000002e-05 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      "Batch 23: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 2381.278988599777\n",
      "Super-epoch 11 - learn rate: 7.87450656184296e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2247.7559 - val_loss: 2485.4219\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2274.1365 - val_loss: 2027.3021\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      "Batch 36: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 2466.4376850128174\n",
      "Super-epoch 12 - learn rate: 7.87450656184296e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2271.8588 - val_loss: 2754.1428\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2208.8936 - val_loss: 2281.1877\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2246.9390 - val_loss: 1985.4396\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2271.6657 - val_loss: 2130.2854\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2228.7036 - val_loss: 3000.0679\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 23s - loss: 2219.1165 - val_loss: 1945.0398\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2242.0536 - val_loss: 1885.3906\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2272.5440 - val_loss: 2141.1636\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2288.2872 - val_loss: 2163.5132\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2283.0362 - val_loss: 2666.2307\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2285.5091 - val_loss: 2099.8792\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2243.7281 - val_loss: 2065.6482\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2221.5804 - val_loss: 2084.9563\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2353.3231 - val_loss: 2088.1936\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2293.3997 - val_loss: 2497.6631\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2170.20072\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 2831.0002715587616\n",
      "Super-epoch 13 - learn rate: 7.87450656184296e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2311.4531 - val_loss: 2129.4358\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2224.1696 - val_loss: 1928.4238\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2295.3067 - val_loss: 3090.7815\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2331.5928 - val_loss: 2165.4973\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2223.9218 - val_loss: 2052.2573\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2233.1137 - val_loss: 2139.8386\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2311.0896 - val_loss: 2079.7700\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2274.6648 - val_loss: 1994.9634\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2230.4537 - val_loss: 2189.3721\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2275.1951 - val_loss: 1997.9344\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2170.20072\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2238.9425 - val_loss: 2532.2556\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2288.1219 - val_loss: 2372.5598\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2170.20072\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2234.0055 - val_loss: 2715.1602\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2265.2727 - val_loss: 2740.2939\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2170.20072\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2272.3277 - val_loss: 2114.8843\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 3196.281219959259\n",
      "Super-epoch 14 - learn rate: 7.87450656184296e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2219.7170 - val_loss: 2699.5439\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2315.3498 - val_loss: 2881.2869\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2313.3840 - val_loss: 3478.7290\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2339.4457 - val_loss: 2176.3193\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2252.2430 - val_loss: 2097.5508\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2177.4039 - val_loss: 2054.6880\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2288.0045 - val_loss: 1989.0024\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2170.4459 - val_loss: 2977.5540\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2238.0624 - val_loss: 1970.5997\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2285.5473 - val_loss: 1899.6731\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2254.3925 - val_loss: 3440.5723\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2315.6814 - val_loss: 2066.9783\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2265.2549 - val_loss: 2019.6251\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2262.1097 - val_loss: 2327.8235\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2292.8430 - val_loss: 2016.7218\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2170.20072\n",
      "Epoch 00015: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 3566.562425136566\n",
      "Super-epoch 15 - learn rate: 4.960628287400625e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2328.5350 - val_loss: 2051.8733\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2260.0872 - val_loss: 1953.7811\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2170.20072\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2343.9155 - val_loss: 2674.4783\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2308.0947 - val_loss: 2587.9675\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2170.20072\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2264.7520 - val_loss: 2325.1445\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 23s - loss: 2280.6520 - val_loss: 2313.7126\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2170.20072\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2269.8216 - val_loss: 3416.7798\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2280.3193 - val_loss: 2179.5857\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2170.20072\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2292.1768 - val_loss: 2082.3572\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2267.0439 - val_loss: 2328.6555\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2170.20072\n",
      "Epoch 11/2094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 2282.4596 - val_loss: 2143.2092\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2282.7765 - val_loss: 2670.5334\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2170.20072\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2264.3049 - val_loss: 2223.2632\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2295.0987 - val_loss: 1947.6434\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2170.20072\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2271.5618 - val_loss: 2217.1147\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "Epoch 00015: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 3942.141077041626\n",
      "Super-epoch 16 - learn rate: 3.125000000000001e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 34s - loss: 2323.9027 - val_loss: 3177.7327\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2170.20072\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2315.0429 - val_loss: 2129.7478\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2239.3024 - val_loss: 1960.9677\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2170.20072\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2289.0119 - val_loss: 2016.7830\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2245.5791 - val_loss: 1882.7498\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2170.20072\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2199.5684 - val_loss: 2162.6946\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 23s - loss: 2233.6603 - val_loss: 2283.6702\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2170.20072\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2259.7348 - val_loss: 3352.2429\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 25s - loss: 2233.4600 - val_loss: 2952.7656\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2170.20072\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2298.3554 - val_loss: 1994.5312\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2204.0094 - val_loss: 3125.9353\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2170.20072\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2286.7227 - val_loss: 1927.2748\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2244.0628 - val_loss: 2251.7563\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2170.20072\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2306.9872 - val_loss: 1903.0468\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2161.1524 - val_loss: 2590.8391\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss improved from 2170.20072 to 2161.15241, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Saving best loss value: [2161.1524091448105, 1856.317626953125]\n",
      "Epoch 16/2094\n",
      " - 23s - loss: 2257.4449 - val_loss: 2075.3669\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1856.31763\n",
      "Epoch 17/2094\n",
      " - 22s - loss: 2318.0295 - val_loss: 1945.2550\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00017: loss did not improve from 2161.15241\n",
      "Epoch 18/2094\n",
      " - 22s - loss: 2267.1086 - val_loss: 2593.8992\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1856.31763\n",
      "Epoch 19/2094\n",
      " - 23s - loss: 2254.5535 - val_loss: 2018.1327\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00019: loss did not improve from 2161.15241\n",
      "Epoch 20/2094\n",
      " - 23s - loss: 2307.5306 - val_loss: 2093.7017\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1856.31763\n",
      "Epoch 21/2094\n",
      " - 23s - loss: 2287.5553 - val_loss: 1877.0753\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00021: loss did not improve from 2161.15241\n",
      "Epoch 22/2094\n",
      " - 22s - loss: 2255.2933 - val_loss: 2099.9412\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1856.31763\n",
      "Epoch 23/2094\n",
      " - 23s - loss: 2283.3162 - val_loss: 2589.3611\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00023: loss did not improve from 2161.15241\n",
      "Epoch 24/2094\n",
      " - 22s - loss: 2267.0737 - val_loss: 3284.8782\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1856.31763\n",
      "Epoch 25/2094\n",
      " - 23s - loss: 2338.7918 - val_loss: 2656.2976\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00025: loss did not improve from 2161.15241\n",
      "Epoch 26/2094\n",
      " - 22s - loss: 2255.7288 - val_loss: 2002.8715\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1856.31763\n",
      "Epoch 27/2094\n",
      " - 23s - loss: 2309.9981 - val_loss: 1932.9009\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00027: loss did not improve from 2161.15241\n",
      "Epoch 28/2094\n",
      " - 23s - loss: 2264.3975 - val_loss: 2047.0081\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1856.31763\n",
      "Epoch 29/2094\n",
      " - 23s - loss: 2289.9490 - val_loss: 1927.3125\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00029: loss did not improve from 2161.15241\n",
      "Epoch 30/2094\n",
      " - 23s - loss: 2243.8245 - val_loss: 2131.3152\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1856.31763\n",
      "Epoch 00030: early stopping\n",
      "\n",
      "Time 4666.624934196472\n",
      "Super-epoch 17 - learn rate: 3.125000000000001e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 31s - loss: 2317.4554 - val_loss: 2952.9336\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.15241\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2308.3666 - val_loss: 2812.0803\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2257.0601 - val_loss: 2524.5083\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.15241\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2430.4756 - val_loss: 3177.9988\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2311.9622 - val_loss: 2319.2795\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.15241\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2247.1234 - val_loss: 2027.3450\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2272.8468 - val_loss: 1897.6106\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.15241\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2229.1351 - val_loss: 2100.1243\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2232.8187 - val_loss: 2414.8096\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2161.15241\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2432.6779 - val_loss: 2057.8567\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2257.5537 - val_loss: 2278.3035\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2161.15241\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2280.7026 - val_loss: 2280.5134\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2302.1799 - val_loss: 2130.3848\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2161.15241\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2325.0784 - val_loss: 2241.6431\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2303.4723 - val_loss: 2323.7866\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2161.15241\n",
      "Epoch 00015: early stopping\n",
      "Learn rate decayed\n",
      "\n",
      "Time 5043.988705396652\n",
      "Super-epoch 18 - learn rate: 1.96862664046074e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2232.2500 - val_loss: 2141.4385\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2211.1090 - val_loss: 2152.3284\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.15241\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2238.9939 - val_loss: 2110.2559\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2217.6537 - val_loss: 2493.3774\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.15241\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2276.1812 - val_loss: 2349.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2237.8530 - val_loss: 2227.5803\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.15241\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2329.1494 - val_loss: 2163.9624\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2220.9346 - val_loss: 2058.1611\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.15241\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2314.4873 - val_loss: 2186.7839\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2221.9128 - val_loss: 2197.0291\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2161.15241\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2258.0527 - val_loss: 2036.0463\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2357.4443 - val_loss: 2129.3152\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2161.15241\n",
      "Epoch 13/2094\n",
      " - 23s - loss: 2226.6079 - val_loss: 2618.2258\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2298.0068 - val_loss: 2229.0017\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2161.15241\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2238.1791 - val_loss: 3009.9463\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 5426.531134366989\n",
      "Super-epoch 19 - learn rate: 1.96862664046074e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2238.6776 - val_loss: 1900.3179\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.15241\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2332.6519 - val_loss: 1979.6262\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      "Batch 29: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.15241\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 5528.944653272629\n",
      "Super-epoch 20 - learn rate: 1.2401570718501562e-06 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2188.3926 - val_loss: 2013.7501\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      "Batch 46: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.15241\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 5618.984326124191\n",
      "Super-epoch 21 - learn rate: 7.812500000000002e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 34s - loss: 2248.5362 - val_loss: 2093.5100\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 23s - loss: 2184.0994 - val_loss: 3327.4863\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.15241\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2271.0236 - val_loss: 2270.4497\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2247.2173 - val_loss: 2089.7290\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.15241\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2272.3111 - val_loss: 2032.0809\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2275.8040 - val_loss: 2493.0962\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.15241\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2277.8759 - val_loss: 2109.6562\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2219.4991 - val_loss: 1905.5824\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.15241\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2267.4594 - val_loss: 2176.8513\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2333.6866 - val_loss: 2347.3303\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2161.15241\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2246.9202 - val_loss: 2298.6450\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2295.0238 - val_loss: 2167.1328\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2161.15241\n",
      "Epoch 13/2094\n",
      " - 23s - loss: 2264.4471 - val_loss: 2359.5864\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      " - 23s - loss: 2265.0207 - val_loss: 2997.6177\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2161.15241\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2301.8327 - val_loss: 2198.0742\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 6017.3909657001495\n",
      "Super-epoch 22 - learn rate: 7.812500000000002e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2323.1071 - val_loss: 3301.1345\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.15241\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2290.5839 - val_loss: 2958.7830\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2161.0326 - val_loss: 2135.9722\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss improved from 2161.15241 to 2161.03263, saving model to ./saved_models/model_4_checkpoint.h5\n",
      "Saving best loss value: [2161.0326298304967, 1856.317626953125]\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2275.2566 - val_loss: 2057.3115\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2309.1753 - val_loss: 2536.1477\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.03263\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2299.2385 - val_loss: 2072.6279\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2388.2860 - val_loss: 1981.2618\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.03263\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2298.1184 - val_loss: 2409.5371\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2288.9540 - val_loss: 2650.6465\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2161.03263\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2330.9281 - val_loss: 1978.7531\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2284.5586 - val_loss: 2739.8752\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2161.03263\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2291.6476 - val_loss: 2908.3154\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2275.9676 - val_loss: 2119.1631\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2161.03263\n",
      "Epoch 14/2094\n",
      "Batch 29: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 6379.526100635529\n",
      "Super-epoch 23 - learn rate: 7.812500000000002e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2269.6402 - val_loss: 1905.8888\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2268.6821 - val_loss: 2302.3735\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2238.9609 - val_loss: 2102.3672\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.03263\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2220.3825 - val_loss: 2180.7954\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2216.2480 - val_loss: 2565.1809\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.03263\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2313.6502 - val_loss: 2053.7683\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2253.0609 - val_loss: 2043.9960\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.03263\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2257.8316 - val_loss: 2406.1050\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      "Batch 49: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2161.03263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 6635.145357608795\n",
      "Super-epoch 24 - learn rate: 7.812500000000002e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2304.4969 - val_loss: 2914.3804\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2314.5042 - val_loss: 2709.5544\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2215.8006 - val_loss: 3250.2808\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2306.6362 - val_loss: 2903.5420\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2338.0570 - val_loss: 2149.6226\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2246.1282 - val_loss: 2212.9983\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.03263\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2349.0887 - val_loss: 2073.0188\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2322.0690 - val_loss: 2046.7412\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.03263\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2240.7951 - val_loss: 1949.5594\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2228.9703 - val_loss: 2009.6245\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2161.03263\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2301.6009 - val_loss: 2242.2114\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      "Batch 47: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2161.03263\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 6961.001587152481\n",
      "Super-epoch 25 - learn rate: 4.92156660115185e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2274.9697 - val_loss: 1925.6957\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2232.7579 - val_loss: 2172.6797\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2220.1038 - val_loss: 1994.5186\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      "Batch 6: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 7102.873113870621\n",
      "Super-epoch 26 - learn rate: 3.1003926796253905e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2204.9770 - val_loss: 2286.4468\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2346.6732 - val_loss: 2526.2852\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2194.7117 - val_loss: 2208.0776\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2404.9333 - val_loss: 2051.8794\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2291.6091 - val_loss: 2158.3982\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2252.2676 - val_loss: 2882.3975\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.03263\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2281.7100 - val_loss: 2029.0615\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2273.4723 - val_loss: 1936.4575\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.03263\n",
      "Epoch 9/2094\n",
      "Batch 46: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 7370.421537399292\n",
      "Super-epoch 27 - learn rate: 3.1003926796253905e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2357.1948 - val_loss: 3160.1965\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2240.0305 - val_loss: 2170.8506\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2226.7836 - val_loss: 2097.1262\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.03263\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2358.3363 - val_loss: 2419.3916\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2219.7904 - val_loss: 1979.2100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.03263\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2302.8121 - val_loss: 2701.0996\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2239.7494 - val_loss: 2098.9414\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.03263\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2213.2707 - val_loss: 2072.8352\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2267.1985 - val_loss: 2766.8740\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2161.03263\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2263.7946 - val_loss: 2064.9778\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2271.6812 - val_loss: 1985.9998\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2161.03263\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2331.2731 - val_loss: 2840.9321\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2273.1500 - val_loss: 2825.4243\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2161.03263\n",
      "Epoch 14/2094\n",
      " - 22s - loss: 2300.4745 - val_loss: 2205.6958\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "Epoch 15/2094\n",
      " - 22s - loss: 2197.3301 - val_loss: 2251.8108\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00015: loss did not improve from 2161.03263\n",
      "Epoch 00015: early stopping\n",
      "\n",
      "Time 7787.354026317596\n",
      "Super-epoch 28 - learn rate: 3.1003926796253905e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2256.0277 - val_loss: 2732.7808\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2309.3697 - val_loss: 2745.5706\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2310.0660 - val_loss: 1883.4423\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2283.4419 - val_loss: 2429.4795\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2346.8724 - val_loss: 2697.5845\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2183.2007 - val_loss: 2095.5728\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.03263\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2317.4957 - val_loss: 1979.8671\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2297.6780 - val_loss: 2199.2671\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.03263\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2211.9468 - val_loss: 2157.1243\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      " - 22s - loss: 2295.4209 - val_loss: 2702.8975\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2161.03263\n",
      "Epoch 11/2094\n",
      " - 22s - loss: 2179.4746 - val_loss: 2326.5996\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2335.4731 - val_loss: 2289.8652\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00012: loss did not improve from 2161.03263\n",
      "Epoch 13/2094\n",
      " - 22s - loss: 2293.8776 - val_loss: 2424.9756\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "Epoch 14/2094\n",
      "Batch 53: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00014: loss did not improve from 2161.03263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 8177.258008718491\n",
      "Super-epoch 29 - learn rate: 3.1003926796253905e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2292.7517 - val_loss: 2498.9258\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2283.9505 - val_loss: 2211.9272\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2261.5148 - val_loss: 2294.0278\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      "Batch 33: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 8344.946916818619\n",
      "Super-epoch 30 - learn rate: 1.9531250000000006e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      "Batch 40: Invalid loss, terminating training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 8451.9833381176\n",
      "Super-epoch 31 - learn rate: 1.9531250000000006e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      "Batch 26: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Learn rate decayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 8585.250326395035\n",
      "Super-epoch 32 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 33s - loss: 2352.6801 - val_loss: 2034.0989\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2253.7323 - val_loss: 2105.1331\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2225.5864 - val_loss: 2208.3474\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2274.4323 - val_loss: 2079.8362\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2389.7830 - val_loss: 2083.2410\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2301.8810 - val_loss: 2333.9387\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.03263\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2277.1233 - val_loss: 2795.6311\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 23s - loss: 2279.3618 - val_loss: 1951.7886\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.03263\n",
      "Epoch 9/2094\n",
      " - 23s - loss: 2280.2013 - val_loss: 2104.6094\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "Epoch 10/2094\n",
      "Batch 11: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00010: loss did not improve from 2161.03263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current, self.best):\n",
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 8906.137864589691\n",
      "Super-epoch 33 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2267.4699 - val_loss: 2378.2874\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2283.2542 - val_loss: 1919.4204\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00002: loss did not improve from 2161.03263\n",
      "Epoch 3/2094\n",
      " - 23s - loss: 2325.5760 - val_loss: 2218.6370\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "Epoch 4/2094\n",
      " - 23s - loss: 2328.1901 - val_loss: 2204.5986\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00004: loss did not improve from 2161.03263\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2284.2320 - val_loss: 2290.3125\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2295.0301 - val_loss: 2231.1152\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00006: loss did not improve from 2161.03263\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2246.5884 - val_loss: 2350.5347\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2322.3285 - val_loss: 1948.6173\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00008: loss did not improve from 2161.03263\n",
      "Epoch 9/2094\n",
      "Batch 3: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9203.823690652847\n",
      "Super-epoch 34 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 34s - loss: 2281.6542 - val_loss: 2031.9434\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2236.4075 - val_loss: 3445.4668\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2322.7674 - val_loss: 2078.0779\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.03263\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2290.3336 - val_loss: 1943.3120\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2242.6714 - val_loss: 2100.0703\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.03263\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2314.4177 - val_loss: 2519.8372\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 22s - loss: 2268.0661 - val_loss: 1998.5872\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.03263\n",
      "Epoch 8/2094\n",
      " - 22s - loss: 2210.4022 - val_loss: 2189.9551\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n",
      "Epoch 9/2094\n",
      " - 22s - loss: 2260.5599 - val_loss: 2441.9111\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00009: loss did not improve from 2161.03263\n",
      "Epoch 10/2094\n",
      " - 23s - loss: 2271.4328 - val_loss: 2607.5769\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1856.31763\n",
      "Epoch 11/2094\n",
      " - 23s - loss: 2297.3658 - val_loss: 2046.4861\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00011: loss did not improve from 2161.03263\n",
      "Epoch 12/2094\n",
      " - 22s - loss: 2216.3024 - val_loss: 2061.0681\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1856.31763\n",
      "Epoch 13/2094\n",
      " - 24s - loss: 2305.2941 - val_loss: 2347.2153\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00013: loss did not improve from 2161.03263\n",
      "Epoch 14/2094\n",
      "Batch 52: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9632.312808036804\n",
      "Super-epoch 35 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 32s - loss: 2254.3463 - val_loss: 2430.1460\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Epoch 2/2094\n",
      " - 22s - loss: 2308.1671 - val_loss: 2537.3110\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n",
      "Epoch 3/2094\n",
      " - 22s - loss: 2270.3630 - val_loss: 3065.7852\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00003: loss did not improve from 2161.03263\n",
      "Epoch 4/2094\n",
      " - 22s - loss: 2227.5837 - val_loss: 2327.4099\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1856.31763\n",
      "Epoch 5/2094\n",
      " - 22s - loss: 2275.6721 - val_loss: 2091.4773\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00005: loss did not improve from 2161.03263\n",
      "Epoch 6/2094\n",
      " - 22s - loss: 2275.1979 - val_loss: 2862.4158\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1856.31763\n",
      "Epoch 7/2094\n",
      " - 23s - loss: 2262.7579 - val_loss: 3103.4929\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00007: loss did not improve from 2161.03263\n",
      "Epoch 8/2094\n",
      "Batch 27: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 9923.000408887863\n",
      "Super-epoch 36 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n",
      " - 33s - loss: 2221.7475 - val_loss: 2857.7932\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1856.31763\n",
      "\n",
      "Epoch 00001: loss did not improve from 2161.03263\n",
      "Epoch 2/2094\n",
      "Batch 14: Invalid loss, terminating training\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1856.31763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\python37\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: invalid value encountered in less\n",
      "b:\\python37\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time 10079.052838087082\n",
      "Super-epoch 37 - learn rate: 1.2303916502879625e-07 - minimum LR: 1e-07\n",
      "\n",
      "Epoch 1/2094\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.53 MiB for an array with shape (448, 448) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-68e359fe30f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mmodel_4_checkpoint_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mmodel_4_recorder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mmodel_4_ER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         ]\n\u001b[0;32m     59\u001b[0m     )\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    740\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[1;32m--> 742\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m                     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \"\"\"\n\u001b[1;32m--> 650\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d752c7eb8218>\u001b[0m in \u001b[0;36mdata_generator\u001b[1;34m(annotation_lines, batch_size, input_shape, anchors, num_classes)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m             \u001b[0mimage_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbox_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d752c7eb8218>\u001b[0m in \u001b[0;36mget_random_data\u001b[1;34m(annotation_line, input_shape, random, max_boxes, jitter, hue, sat, val, proc_img)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mimage_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsv_to_rgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# numpy array, 0 to 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# correct boxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mb:\\python37\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mhsv_to_rgb\u001b[1;34m(hsv)\u001b[0m\n\u001b[0;32m   1478\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m6.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1481\u001b[0m     \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.53 MiB for an array with shape (448, 448) and data type float64"
     ]
    }
   ],
   "source": [
    "print()\n",
    "# ''' // comment on this line to enable/disable this block\n",
    "model_4_checkpoint_val = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "model_4_checkpoint_loss = ModelCheckpoint(\n",
    "    filepath='./saved_models/model_4_checkpoint.h5',\n",
    "    monitor='loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    period=2\n",
    ")\n",
    "model_4_recorder = BestValueRecorder(\n",
    "    filepath='./saved_models/model_4_bestValue.json',\n",
    "    monitorValidation=True,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    # these instances are modified by the __init__ (constructor) of this object\n",
    "    instanceModelCheckpointLoss=model_4_checkpoint_loss,\n",
    "    instanceModelCheckpointVal=model_4_checkpoint_val\n",
    ")\n",
    "model_4_ER = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=model_4_checkpoint_loss.best # this instance is not modified by the __init__ of this object\n",
    ")\n",
    "model_4_LRDecay = math.pow(1 / 4, 1 / 3) # exponentially decays to 25% in 3 super-epochs \n",
    "superEpochs = 0\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < 3 * 3600: # guarantees at least 6 hours of training, unless the kernel crashes\n",
    "# while superEpochs <= 20: # guarantees 10 super-epochs, unless the kernel crashes\n",
    "    superEpochs = superEpochs + 1\n",
    "    print('Time', str(time.time() - start_time))\n",
    "    print('Super-epoch', superEpochs, '- learn rate:', model_4_learnRate, '- minimum LR:', minimumLR)\n",
    "    print()\n",
    "    model_4_history = model_4.fit_generator(\n",
    "        generator=train_data_generator, \n",
    "        steps_per_epoch=max(1, (lenTrain // trainingBatchSize) // epochSplit), \n",
    "        epochs=1 * epochSplit,\n",
    "        verbose=2,\n",
    "        validation_data=val_data_generator,\n",
    "        validation_steps=max(1, 15 * (lenVal // trainingBatchSize) // epochSplit),\n",
    "        callbacks=[ \n",
    "            TerminateOnNaN(),\n",
    "            model_4_checkpoint_val,\n",
    "            model_4_checkpoint_loss,\n",
    "            model_4_recorder,\n",
    "            model_4_ER\n",
    "        ]\n",
    "    )\n",
    "    if np.random.rand() >= decayChance:\n",
    "        model_4_ER.patience = model_4_ER.patience * 1.15\n",
    "        print(\"Early stopping patience rate increased -\", model_4_ER.patience)\n",
    "    if model_4_learnRate > minimumLR / model_4_LRDecay and np.random.rand() < decayChance:\n",
    "        # guarantees learn rate above minimumLR\n",
    "        # randomly decays learnRate with a predetermined probability\n",
    "        print(\"Learn rate decayed\")\n",
    "        model_4_learnRate = model_4_LRDecay * model_4_learnRate\n",
    "    model_4.load_weights(\"./saved_models/model_4_checkpoint.h5\")\n",
    "    model_4.compile(optimizer=Adam(lr=model_4_learnRate), loss={'yolo_loss_model_4': lambda y_true, y_pred: y_pred})\n",
    "    print()\n",
    "print(\"model_4 training done in\", str(time.time() - start_time))\n",
    "model_4.save_weights(\"./saved_models/model_4_trainModel.h5\")\n",
    "# '''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resource successfully released\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
