{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading inference result text complete\n"
     ]
    }
   ],
   "source": [
    "# inference result texts generated by ./h5loader.ipynb\n",
    "with open(\"./model_5_inferResult_bound.txt\", \"rt\") as baseModel_inferText:\n",
    "    bm_result = list(map(lambda x: json.loads(x), baseModel_inferText.readlines()))\n",
    "with open(\"./model_3_inferResult_bound.txt\", \"rt\") as compModel_inferText:\n",
    "    cm_result = list(map(lambda x: json.loads(x), compModel_inferText.readlines()))\n",
    "print(\"Reading inference result text complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of entry processed: 2000\n",
      "# of entry processed: 4000\n",
      "# of entry processed: 6000\n",
      "# of entry processed: 8000\n",
      "# of entry processed: 10000\n",
      "# of entry processed: 12000\n",
      "# of entry processed: 14000\n",
      "# of entry processed: 16000\n",
      "# of entry processed: 18000\n",
      "# of entry processed: 20000\n",
      "# of entry processed: 22000\n",
      "# of entry processed: 24000\n",
      "# of entry processed: 26000\n",
      "# of entry processed: 28000\n",
      "# of entry processed: 30000\n",
      "# of entry processed: 32000\n",
      "# of entry processed: 34000\n",
      "# of entry processed: 36000\n",
      "# of entry processed: 38000\n",
      "# of entry processed: 40000\n",
      "# of entry processed: 42000\n",
      "# of entry processed: 44000\n",
      "# of entry processed: 46000\n",
      "# of entry processed: 48000\n",
      "# of entry processed: 50000\n",
      "# of entry processed: 52000\n",
      "# of entry processed: 54000\n",
      "# of entry processed: 56000\n",
      "# of entry processed: 58000\n",
      "# of entry processed: 60000\n",
      "# of entry processed: 62000\n",
      "# of entry processed: 64000\n",
      "# of entry processed: 66000\n",
      "# of entry processed: 68000\n",
      "# of entry processed: 70000\n",
      "# of entry processed: 72000\n",
      "# of entry processed: 74000\n",
      "# of entry processed: 76000\n",
      "# of entry processed: 78000\n",
      "# of entry processed: 80000\n",
      "# of entry processed: 82000\n",
      "# of entry processed: 84000\n",
      "# of entry processed: 86000\n",
      "# of entry processed: 88000\n",
      "# of entry processed: 90000\n",
      "# of entry processed: 92000\n",
      "# of entry processed: 94000\n",
      "# of entry processed: 96000\n",
      "# of entry processed: 98000\n",
      "# of entry processed: 100000\n",
      "# of entry processed: 102000\n",
      "# of entry processed: 104000\n",
      "# of entry processed: 106000\n",
      "# of entry processed: 108000\n",
      "# of entry processed: 110000\n",
      "# of entry processed: 112000\n",
      "# of entry processed: 114000\n",
      "# of entry processed: 116000\n",
      "# of entry processed: 118000\n",
      "# of entry processed: 120000\n",
      "# of entry processed: 122000\n",
      "# of entry processed: 124000\n",
      "# of entry processed: 126000\n",
      "# of entry processed: 128000\n",
      "# of entry processed: 130000\n",
      "# of entry processed: 132000\n",
      "# of entry processed: 134000\n",
      "# of entry processed: 136000\n",
      "# of entry processed: 138000\n",
      "# of entry processed: 140000\n",
      "# of entry processed: 142000\n",
      "# of entry processed: 144000\n",
      "# of entry processed: 146000\n",
      "# of entry processed: 148000\n",
      "# of entry processed: 150000\n",
      "# of entry processed: 152000\n",
      "# of entry processed: 154000\n",
      "# of entry processed: 156000\n",
      "# of entry processed: 158000\n",
      "Processing complete - 158957 image entries processed\n"
     ]
    }
   ],
   "source": [
    "# bm_result[a][b][c][d]\n",
    "# a = [imageEntry_index]\n",
    "# b = [{0: filepath, 1: inferenceResult}]\n",
    "# c = [{0: bbox, 1: chance, 2: class}]\n",
    "# d = [inference_detection_index]\n",
    "# ''' # toggle comment to use fresh-made/pre-made text file\n",
    "outputFile = open(\"./model_comparison.txt\", \"wt\")\n",
    "count = 0\n",
    "countNotification = 2000\n",
    "# if True, then the comparator will count inference detection made in base model and not in comparison model as a total error\n",
    "# Total error means that the data will be compared to a [0,0,0,0], confidence = 0 inference detection\n",
    "ignore_processed = False\n",
    "\n",
    "'''\n",
    "Inference Comparing Algorithm starts here\n",
    "'''\n",
    "\n",
    "# for each entry in base model result:\n",
    "for bmEntryIndex in range(len(bm_result)): # loop 0\n",
    "    # bm_resPtr takes constant of two first indexes\n",
    "    bm_resPtr = bm_result[bmEntryIndex][1] \n",
    "    entryDiff_collection = []\n",
    "    for cmEntryIndex in range(len(cm_result)): # \"loop\" 1\n",
    "        # search for corresponding image entry in comparison model result:\n",
    "        if bm_result[bmEntryIndex][0] == cm_result[(bmEntryIndex + cmEntryIndex) % len(cm_result)][0]:\n",
    "            # if entry found, then start iterating for each inference detection of base model:\n",
    "            # cm_resPtr also takes constant of two first indexes\n",
    "            cm_resPtr = cm_result[(bmEntryIndex + cmEntryIndex) % len(cm_result)][1]\n",
    "            for bm_inferIndex in range(len(bm_resPtr[0])): # loop 2\n",
    "                processed = False\n",
    "                bm_bbox_pred = bm_resPtr[0][bm_inferIndex]\n",
    "                bm_chance = bm_resPtr[1][bm_inferIndex]\n",
    "                bm_class = bm_resPtr[2][bm_inferIndex]\n",
    "                # first, set base value output taking inference at [0,0,0,0] with chance of 0: (total error prep)\n",
    "                # diff_bbox is the average of absolute differences between bounding box parameter for each detection\n",
    "                diff_bbox = sum(list(map(lambda x: abs(x), bm_bbox_pred))) / len(bm_bbox_pred)\n",
    "                # diff_chance is the absolute difference between probability of prediction\n",
    "                diff_chance = abs(bm_chance)\n",
    "                # then, search for each inference detection of comparison model \n",
    "                if True:\n",
    "                    # search criteria: bbox parameter that is closest to its base model value\n",
    "                    # complexity O(2940n^3) - worst case, expected complexity O(2940n^2) due to how data storage is structured\n",
    "                    for cm_inferIndex in range(len(cm_resPtr[0])): # loop 3\n",
    "                        # if inferred class is the same AND bbox difference is smaller (compounded for formatting):\n",
    "                        if cm_resPtr[2][cm_inferIndex] == bm_class:\n",
    "                            avg_diff = sum(list(map(lambda x, y: abs(x - y), bm_bbox_pred, cm_resPtr[0][cm_inferIndex]))) / len(bm_bbox_pred)\n",
    "                            if diff_bbox > avg_diff:\n",
    "                                processed = True\n",
    "                                diff_bbox = avg_diff\n",
    "                                diff_chance = abs(bm_chance - cm_resPtr[1][cm_inferIndex])\n",
    "                else:\n",
    "                    # assumption of each model is aligned \n",
    "                    # i.e. bm_result[a][1][b][x] and cm_result[a][1][b][x] refers to the same inference detection\n",
    "                    # this may not always be the case, e.g. ./test2017/000000001192.jpg\n",
    "                    # complexity O(2940n^2) - worst case, expected complexity O(2940n) due to how data storage is structured\n",
    "                    if bm_inferIndex < len(cm_resPtr[2]) and cm_resPtr[2][bm_inferIndex] == bm_class:\n",
    "                        processed = True\n",
    "                        diff_bbox = sum(list(map(lambda x, y: abs(x - y), bm_bbox_pred, cm_resPtr[0][bm_inferIndex]))) / len(bm_bbox_pred)\n",
    "                        diff_chance = abs(bm_chance - cm_resPtr[1][bm_inferIndex])\n",
    "                # here, diff_bbox and diff_chance has been fully established for each inference detection\n",
    "                if ignore_processed or processed:\n",
    "                    entryDiff_collection.append([diff_bbox, diff_chance])\n",
    "            # here, entryDiff_collection will be filled for each image entry\n",
    "            break # breaking loop 1\n",
    "    # write [bm_result[bmEntryIndex][0], entryDiff_collection] to file\n",
    "    outputFile.write(json.dumps([bm_result[bmEntryIndex][0], entryDiff_collection]) + \"\\n\")\n",
    "    count = count + 1\n",
    "    if (count % countNotification == 0):\n",
    "        print(\"# of entry processed:\", count)\n",
    "outputFile.close()\n",
    "# '''\n",
    "print(\"Processing complete -\", count, \"image entries processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250304\n"
     ]
    }
   ],
   "source": [
    "dataPoints = []\n",
    "with open(\"./model_comparison.txt\", \"rt\") as comparisonData:\n",
    "    for x in list(map(lambda x: json.loads(x), comparisonData.readlines())):\n",
    "        dataPoints.extend(x[1])\n",
    "print(len(dataPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box parameter absolute difference data\n",
      "Mean: 0.0014982357124932067\n",
      "Standard deviation: 0.1472459488511145\n",
      "Maximum: 24.212942123413086\n",
      "50% point (median): 0.0\n",
      "75% point: 0.0\n",
      "95% point: 0.0\n",
      "99% point: 0.0\n",
      "99,9% point: 0.0\n"
     ]
    }
   ],
   "source": [
    "bbox_diff_data = list(map(lambda x: x[0], dataPoints))\n",
    "print(\"Bounding box parameter absolute difference data\")\n",
    "print(\"Mean:\", np.mean(bbox_diff_data))\n",
    "print(\"Standard deviation:\", np.std(bbox_diff_data))\n",
    "print(\"Maximum:\", np.max(bbox_diff_data))\n",
    "print(\"50% point (median):\", np.median(bbox_diff_data))\n",
    "print(\"75% point:\", np.quantile(bbox_diff_data, 0.75))\n",
    "print(\"95% point:\", np.quantile(bbox_diff_data, 0.95))\n",
    "print(\"99% point:\", np.quantile(bbox_diff_data, 0.99))\n",
    "print(\"99,9% point:\", np.quantile(bbox_diff_data, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability parameter absolute difference data\n",
      "Mean: 1.393058948072135e-05\n",
      "Standard deviation: 0.001121883747071454\n",
      "Maximum: 0.20760494470596313\n",
      "50% point (median): 0.0\n",
      "75% point: 0.0\n",
      "95% point: 0.0\n",
      "99% point: 0.0\n",
      "99,9% point: 1.5497207641601562e-06\n"
     ]
    }
   ],
   "source": [
    "chance_diff_data = list(map(lambda x: x[1], dataPoints))\n",
    "print(\"Probability parameter absolute difference data\")\n",
    "print(\"Mean:\", np.mean(chance_diff_data))\n",
    "print(\"Standard deviation:\", np.std(chance_diff_data))\n",
    "print(\"Maximum:\", np.max(chance_diff_data))\n",
    "print(\"50% point (median):\", np.median(chance_diff_data))\n",
    "print(\"75% point:\", np.quantile(chance_diff_data, 0.75))\n",
    "print(\"95% point:\", np.quantile(chance_diff_data, 0.95))\n",
    "print(\"99% point:\", np.quantile(chance_diff_data, 0.99))\n",
    "print(\"99,9% point:\", np.quantile(chance_diff_data, 0.999))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit2209d341433e46b694c7a9ae91caa091"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
